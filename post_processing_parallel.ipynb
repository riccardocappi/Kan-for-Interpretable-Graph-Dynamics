{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics\n",
    "\n",
    "Dynamics | $\\partial_{\\tau}x_i=$ |\n",
    "| :--------: | :-------: |\n",
    "Biochemical | $F -B x_i - R \\sum_j A_{ij} x_i x_j$ |\n",
    "Epidemics | $-B x_i + R \\sum_j A_{ij} (1-x_i)x_j$ |\n",
    "Population | $-B x_i^{b} + R \\sum_j A_{ij} x_j^a$ |\n",
    "Synchronization | $\\omega_i + R \\sum_j A_{ij} \\sin(x_j-x_i)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from experiments.experiments_gkan import ExperimentsGKAN\n",
    "from experiments.experiments_mpnn import ExperimentsMPNN\n",
    "from experiments.experiments_llc import ExperimentsLLC\n",
    "from train_and_eval import eval_model\n",
    "import sympytorch\n",
    "\n",
    "storage = JournalStorage(JournalFileBackend(\"optuna_journal_storage.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def set_pytorch_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "set_pytorch_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_real_epid_mpnn.yml\")\n",
    "# config['patience'] = 450\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config,\n",
    "#     n_trials=3,\n",
    "#     study_name=\"test_mult_2\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "# # # config['t_span'] = [0, 1]\n",
    "# exp = ExperimentsGKAN(\n",
    "#     config=config,\n",
    "#     n_trials=1,\n",
    "#     study_name=\"test_mult_11\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 13:05:55,302] A new study created in Journal with name: model-population-gkan-test_mult_11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: num params: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 13:20:07,691] Trial 0 finished with value: 9.843736188486218e-05 and parameters: {'lr': 0.0028057582076672534, 'lamb': 1.0, 'batch_size': 16, 'use_orig_reg': True, 'lamb_g_net': 8.63200816860254e-06, 'lamb_h_net': 8.629132190071855e-06, 'grid_size_g_net': 5, 'spline_order_g_net': 3, 'range_limit_g_net': 7, 'mu_1_g_net': 0.8, 'mu_2_g_net': 0.1, 'hidden_dim_g_net': 6, 'grid_size_h_net': 18, 'spline_order_h_net': 1, 'range_limit_h_net': 2, 'mu_1_h_net': 0.2, 'mu_2_h_net': 0.4, 'hidden_dim_h_net': 4}. Best is trial 0 with value: 9.843736188486218e-05.\n"
     ]
    }
   ],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f13f1319940>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 30, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_pop = load_config(\"./configs/config_pred_deriv/config_ic1/config_population_mpnn.yml\")\n",
    "# # config_pop[\"t_eval_steps\"] = 1000\n",
    "# # config_pop[\"t_span\"] = [0, 10]\n",
    "\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config_pop,\n",
    "#     n_trials=1,\n",
    "#     study_name='test_mult_3'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 6, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set.raw_data_sampled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:06,795] A new study created in Journal with name: model-biochemical-llc-test_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: num params: 4644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:18,168] Trial 0 finished with value: 0.009816302917897701 and parameters: {'lr': 0.0028057582076672534, 'lamb': 0.009600000000000001, 'batch_size': 16, 'n_hidden_layers_g0': 1, 'hidden_dims_g0': 8, 'af_g0': 'relu', 'drop_p_g0': 0.00011916299962955152, 'n_hidden_layers_g1': 2, 'hidden_dims_g1': 56, 'af_g1': 'relu', 'drop_p_g1': 0.00133469775741781, 'n_hidden_layers_g2': 2, 'hidden_dims_g2': 32, 'af_g2': 'softplus', 'drop_p_g2': 0.0012040216379191721, 'n_hidden_layers_h_net': 1, 'hidden_dims_h_net': 32, 'af_h_net': 'relu', 'drop_p_h_net': 0.015535445807588463}. Best is trial 0 with value: 0.009816302917897701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: num params: 7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:22,121] Trial 1 finished with value: 0.037803955376148224 and parameters: {'lr': 0.0006192568649430464, 'lamb': 0.0061, 'batch_size': 64, 'n_hidden_layers_g0': 2, 'hidden_dims_g0': 56, 'af_g0': 'tanh', 'drop_p_g0': 0.00424727979536972, 'n_hidden_layers_g1': 1, 'hidden_dims_g1': 32, 'af_g1': 'softplus', 'drop_p_g1': 0.028226046783939623, 'n_hidden_layers_g2': 1, 'hidden_dims_g2': 40, 'af_g2': 'tanh', 'drop_p_g2': 0.0736534446668837, 'n_hidden_layers_h_net': 2, 'hidden_dims_h_net': 64, 'af_h_net': 'softplus', 'drop_p_h_net': 0.0005308046630775948}. Best is trial 0 with value: 0.009816302917897701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: num params: 7492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:26,278] Trial 2 finished with value: 0.03039173036813736 and parameters: {'lr': 0.0006157785861833009, 'lamb': 0.0032, 'batch_size': 64, 'n_hidden_layers_g0': 1, 'hidden_dims_g0': 24, 'af_g0': 'tanh', 'drop_p_g0': 0.00018869508789698286, 'n_hidden_layers_g1': 2, 'hidden_dims_g1': 56, 'af_g1': 'tanh', 'drop_p_g1': 0.04117599592262882, 'n_hidden_layers_g2': 2, 'hidden_dims_g2': 56, 'af_g2': 'softplus', 'drop_p_g2': 0.15580940996926476, 'n_hidden_layers_h_net': 2, 'hidden_dims_h_net': 24, 'af_h_net': 'tanh', 'drop_p_h_net': 0.04997943803580264}. Best is trial 0 with value: 0.009816302917897701.\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical_llc.yml\")\n",
    "\n",
    "exp = ExperimentsLLC(\n",
    "    config=config,\n",
    "    n_trials=3,\n",
    "    study_name=\"test_3\",\n",
    "    process_id=0\n",
    ")\n",
    "\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.MPNN import MPNN\n",
    "from models.baseline.MPNN_ODE import MPNN_ODE\n",
    "from train_and_eval import eval_model\n",
    "from datasets.SyntheticData import SyntheticData\n",
    "from sympy import symbols, sin, summation, simplify\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from utils.utils import integrate\n",
    "from torch_geometric.data import Data\n",
    "from models.kan.KAN import KAN\n",
    "from models.GKAN_ODE import GKAN_ODE\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sympy import latex\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_model(g, h, message_passing=True, include_time=False, atol=1e-5, rtol=1e-5, integration_method = 'scipy_solver',\n",
    "              eval=True, options = {}, all_t = False):\n",
    "    conv = MPNN(\n",
    "        g_net = g,\n",
    "        h_net = h,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "\n",
    "    symb = MPNN_ODE(\n",
    "        conv=conv,\n",
    "        model_path=\"./saved_models_optuna/tmp_symb\",\n",
    "        adjoint=True,\n",
    "        integration_method=integration_method,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        options = options,\n",
    "        all_t=all_t\n",
    "    )\n",
    "\n",
    "    if eval:\n",
    "        symb = symb.eval()\n",
    "    return symb\n",
    "\n",
    "\n",
    "def make_callable(expr):\n",
    "    free_syms = expr.free_symbols\n",
    "    if not free_syms:\n",
    "        # Expression is constant\n",
    "        const_value = float(expr)\n",
    "        return lambda x: torch.full((x.shape[0], 1), const_value, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    sym_module = sympytorch.SymPyModule(expressions=[expr])\n",
    "    syms = {str(s) for s in free_syms}\n",
    "    if {'x_i', 'x_j'} <= syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0], x_j=x[:, 1])\n",
    "    elif 'x_i' in syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0])\n",
    "    elif 'x_j' in syms:\n",
    "        return lambda x: sym_module(x_j=x[:, 1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected symbols in expression: {free_syms}\")\n",
    "\n",
    "\n",
    "def get_symb_test_error(g_symb, h_symb, test_set, message_passing=False, include_time=False, atol=1e-5, rtol=1e-5, scaler = None, inverse_scale=False, method='scipy_solver',\n",
    "                        is_symb = True):\n",
    "\n",
    "    if is_symb:\n",
    "        if isinstance(g_symb, int):\n",
    "            g_symb = sp.sympify(g_symb)\n",
    "\n",
    "        if isinstance(h_symb, int):\n",
    "            h_symb = sp.sympify(h_symb)\n",
    "\n",
    "        g_symb = make_callable(g_symb)\n",
    "        h_symb = make_callable(h_symb)\n",
    "\n",
    "    test_losses = []\n",
    "\n",
    "    for ts in test_set:\n",
    "        symb = get_model(\n",
    "            g=g_symb,\n",
    "            h=h_symb,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            integration_method=method\n",
    "        )\n",
    "\n",
    "        collate_fn = lambda samples_list: samples_list\n",
    "        test_loader = DataLoader(ts, batch_size=len(ts), shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "        test_loss = eval_model(\n",
    "            model=symb,\n",
    "            valid_loader=test_loader,\n",
    "            criterion=torch.nn.L1Loss(),\n",
    "            scaler=scaler,\n",
    "            inverse_scale=inverse_scale,\n",
    "            pred_deriv=False\n",
    "        )\n",
    "\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "\n",
    "def get_test_set(dynamics, device='cuda', input_range=(0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    seeds = [12345, 67890, 111213]\n",
    "\n",
    "    graphs = [\n",
    "        nx.barabasi_albert_graph(70, 3, seed=seeds[0]),\n",
    "        nx.watts_strogatz_graph(50, 6, 0.3, seed=seeds[1]),\n",
    "        nx.erdos_renyi_graph(100, 0.05, seed=seeds[2])\n",
    "    ]\n",
    "\n",
    "    test_set = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        snapshots = integrate_test_set(\n",
    "            graph=graph,\n",
    "            dynamics=dynamics,\n",
    "            seed=seeds[i],\n",
    "            device=device,\n",
    "            input_range=input_range,\n",
    "            t_span=t_span,\n",
    "            **integration_kwargs\n",
    "        )\n",
    "        test_set.append(snapshots)\n",
    "\n",
    "    return test_set\n",
    "\n",
    "\n",
    "\n",
    "def integrate_test_set(graph, dynamics, seed=12345, device='cuda', input_range = (0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    # graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "    edge_index = from_networkx(graph).edge_index\n",
    "    edge_index = edge_index.to(torch.device(device))\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    data, t = integrate(\n",
    "        input_range=input_range,\n",
    "        t_span = t_span,\n",
    "        t_eval_steps=1000,\n",
    "        dynamics=dynamics,\n",
    "        device=device,\n",
    "        graph=graph,\n",
    "        rng = rng,\n",
    "        **integration_kwargs\n",
    "    )\n",
    "\n",
    "    snapshot = Data(\n",
    "        x = data[0].unsqueeze(0),\n",
    "        y = data[1:],\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=None,\n",
    "        t_span = t\n",
    "    )\n",
    "\n",
    "    return [snapshot]\n",
    "\n",
    "\n",
    "def build_model_from_file(model_path, message_passing, include_time, method='dopri5', adjoint=False, atol=1e-5, rtol=1e-5,\n",
    "                          compute_mult=True):\n",
    "    best_params_file = f\"{model_path}/best_params.json\"\n",
    "    best_state_path = f\"{model_path}/gkan/state_dict.pth\"\n",
    "\n",
    "    with open(best_params_file, 'r') as f:\n",
    "        best_hyperparams = json.load(f)\n",
    "\n",
    "    # g_net\n",
    "    g_net = KAN(\n",
    "        layers_hidden=[2, best_hyperparams['hidden_dim_g_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_g_net'],\n",
    "        spline_order=best_hyperparams['spline_order_g_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_g_net'], best_hyperparams['range_limit_g_net']],\n",
    "        mu_1=best_hyperparams['mu_1_g_net'],\n",
    "        mu_2=best_hyperparams['mu_2_g_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=compute_mult,\n",
    "        store_act=True\n",
    "    )\n",
    "\n",
    "    time_dim = 1 if include_time else 0\n",
    "    in_dim_h = 2 if message_passing else 1\n",
    "    in_dim_h += time_dim\n",
    "\n",
    "    # h_net\n",
    "    h_net = KAN(\n",
    "        layers_hidden=[in_dim_h, best_hyperparams['hidden_dim_h_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_h_net'],\n",
    "        spline_order=best_hyperparams['spline_order_h_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_h_net'], best_hyperparams['range_limit_h_net']],\n",
    "        mu_1=best_hyperparams['mu_1_h_net'],\n",
    "        mu_2=best_hyperparams['mu_2_h_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=True,\n",
    "        store_act=True\n",
    "    )\n",
    "\n",
    "    gkan = MPNN(\n",
    "        h_net=h_net,\n",
    "        g_net=g_net,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "\n",
    "    model = GKAN_ODE(\n",
    "        conv=gkan,\n",
    "        model_path='./saved_models_optuna/tmp',\n",
    "        lmbd_g=best_hyperparams['lamb_g_net'],\n",
    "        lmbd_h=best_hyperparams['lamb_h_net'],\n",
    "        integration_method=method,\n",
    "        adjoint=adjoint,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    model.load_state_dict(torch.load(best_state_path, weights_only=False, map_location=torch.device('cuda')))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid_symb_model(\n",
    "    config,\n",
    "    model_path_gkan,\n",
    "    device='cuda',\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    black_box_fitting=True,\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    grid_orig = None\n",
    "):\n",
    "    \n",
    "    seed = 9999\n",
    "    graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "\n",
    "    # Prepare validation/test set\n",
    "    valid_set = integrate_test_set(\n",
    "        graph=graph,\n",
    "        dynamics=config['name'],\n",
    "        seed=seed,\n",
    "        device=device,\n",
    "        input_range=config['input_range'],\n",
    "        t_span=(0, 1),\n",
    "        **config['integration_kwargs']\n",
    "    )\n",
    "\n",
    "    # Helper to compute validation loss\n",
    "    def evaluate_model(g_symb, h_symb, is_symb=True):\n",
    "        errs = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=[valid_set],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            is_symb=is_symb\n",
    "        )\n",
    "        return errs[0]\n",
    "\n",
    "    # Helper to fit model for current config\n",
    "    def fit_single_model(param1, param2, param3=None, is_orig=False):\n",
    "        if black_box_fitting:\n",
    "            print(f\"Fitting black-box model with {param1} and {param2} iterations\")\n",
    "            pysr_model = lambda: get_pysr_model(\n",
    "                model_selection=param1, \n",
    "                n_iterations=param2,\n",
    "                # parallelism=\"serial\",\n",
    "                # random_state = seed,\n",
    "                # deterministic = True\n",
    "            )\n",
    "            _, g_symb, h_symb, _ = fit_black_box_from_kan(\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                device=device,\n",
    "                model_path=model_path_gkan,\n",
    "                pysr_model=pysr_model,\n",
    "                sample_size=sample_size,\n",
    "                theta=-np.inf,\n",
    "                message_passing=False,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            \n",
    "            if not is_orig:\n",
    "                print(f\"Fitting symbolic model with {param1}, theta {param2} and cutting threshold {param3}\")\n",
    "                _, g_symb, h_symb, _ = fit_model(\n",
    "                    n_g_hidden_layers=n_g_hidden_layers,\n",
    "                    n_h_hidden_layers=n_h_hidden_layers,\n",
    "                    model_path=model_path_gkan,\n",
    "                    theta=param2,\n",
    "                    message_passing=False,\n",
    "                    include_time=False,\n",
    "                    sample_size=sample_size,\n",
    "                    sort_by=param1,\n",
    "                    verbose=False,\n",
    "                    cut_threshold=param3\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Fitting symbolic model with {param1}, theta {param2} and ws {param3}\")\n",
    "                _, g_symb, h_symb, _ = fit_model(\n",
    "                    n_g_hidden_layers=n_g_hidden_layers,\n",
    "                    n_h_hidden_layers=n_h_hidden_layers,\n",
    "                    model_path=model_path_gkan,\n",
    "                    theta=param2,\n",
    "                    message_passing=False,\n",
    "                    include_time=False,\n",
    "                    sample_size=sample_size,\n",
    "                    verbose=False,\n",
    "                    fit_orig=True,\n",
    "                    a_range = param1,\n",
    "                    b_range = param1,\n",
    "                    weight_simple = param3\n",
    "                )\n",
    "        return g_symb, h_symb\n",
    "\n",
    "    if black_box_fitting:\n",
    "        param_grid = ([\"score\", \"accuracy\"], [50, 100, 200])\n",
    "        search_space = [(mod, val) for mod in param_grid[0] for val in param_grid[1]]\n",
    "    else:\n",
    "        if grid_orig == None:\n",
    "            param_grid = (\n",
    "                [\"score\", \"log_loss\"],       \n",
    "                [0.01, 0.05, 0.1],           \n",
    "                [0.1, 0.01, 0.001]    \n",
    "            )\n",
    "        else:\n",
    "            param_grid = grid_orig\n",
    "            \n",
    "            \n",
    "        search_space = list(itertools.product(*param_grid))\n",
    "\n",
    "    valid_losses = []\n",
    "\n",
    "    for params in search_space:\n",
    "        g_symb, h_symb = fit_single_model(*params, grid_orig != None)\n",
    "        try:\n",
    "            loss = evaluate_model(g_symb, h_symb)\n",
    "        except AssertionError:\n",
    "            loss = 1e8\n",
    "        if black_box_fitting:\n",
    "            valid_losses.append({'model_selection': params[0], 'param': params[1], 'valid_loss': loss})\n",
    "        elif grid_orig == None:\n",
    "            valid_losses.append({'sort_by': params[0], 'theta': params[1], 'cut_threshold': params[2], 'valid_loss': loss})\n",
    "        else:\n",
    "            valid_losses.append({'grid_range': params[0], 'theta': params[1], \"ws\":params[2], 'valid_loss': loss})\n",
    "\n",
    "    # Select best performing configuration\n",
    "    best = min(valid_losses, key=lambda x: x['valid_loss'])\n",
    "\n",
    "    # Final refit with best config\n",
    "    print(f\"Refitting best model with {best}\")\n",
    "    if black_box_fitting:\n",
    "        gkan_symb, symb_g, symb_h, exec_time = fit_black_box_from_kan(\n",
    "            model_path=model_path_gkan,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            device=device,\n",
    "            theta=-np.inf,\n",
    "            pysr_model=lambda: get_pysr_model(\n",
    "                model_selection=best['model_selection'],\n",
    "                n_iterations=best['param'],\n",
    "                # parallelism=\"serial\",\n",
    "                # random_state = seed,\n",
    "                # deterministic = True\n",
    "            ),\n",
    "            sample_size=sample_size,\n",
    "            message_passing=False,\n",
    "            verbose=True,\n",
    "            include_time=False\n",
    "        )\n",
    "    else:\n",
    "        if grid_orig == None:\n",
    "            gkan_symb, symb_g, symb_h, exec_time = fit_model(\n",
    "                model_path=model_path_gkan,\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                theta=best['theta'],\n",
    "                message_passing=False,\n",
    "                include_time=False,\n",
    "                sample_size=sample_size,\n",
    "                sort_by=best['sort_by'],\n",
    "                verbose=True,\n",
    "                cut_threshold=best[\"cut_threshold\"]\n",
    "            )\n",
    "        else:\n",
    "            gkan_symb, symb_g, symb_h, exec_time = fit_model(\n",
    "                model_path=model_path_gkan,\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                theta=best['theta'],\n",
    "                message_passing=False,\n",
    "                include_time=False,\n",
    "                sample_size=sample_size,\n",
    "                verbose=True,\n",
    "                fit_orig=True,\n",
    "                a_range = best['grid_range'],\n",
    "                b_range = best['grid_range'],\n",
    "                weight_simple = best['ws']\n",
    "            )\n",
    "\n",
    "    return gkan_symb, symb_g, symb_h, exec_time\n",
    "\n",
    "def post_process_gkan(\n",
    "    config,\n",
    "    model_path,\n",
    "    test_set,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    scaler=None,\n",
    "    inverse_scale=False,\n",
    "    adjoint=True,\n",
    "    eval_model=True,\n",
    "    res_file_name = 'post_process_res.json',\n",
    "    compute_mult = True,\n",
    "    grid_orig = None,\n",
    "    skip_bb = False,\n",
    "):\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    def print_symb_error(g_symb, h_symb, txt=\"symbolic formula\", is_symb=True):\n",
    "        try:\n",
    "            test_losses_symb = get_symb_test_error(\n",
    "                g_symb=g_symb,\n",
    "                h_symb=h_symb,\n",
    "                test_set=test_set,\n",
    "                message_passing=message_passing,\n",
    "                include_time=include_time,\n",
    "                atol=atol,\n",
    "                rtol=rtol,\n",
    "                method=method,\n",
    "                scaler=scaler,\n",
    "                inverse_scale=inverse_scale,\n",
    "                is_symb=is_symb\n",
    "            )\n",
    "\n",
    "            ts_mean = np.mean(test_losses_symb)\n",
    "            ts_var = np.var(test_losses_symb)\n",
    "            ts_std = np.std(test_losses_symb)\n",
    "\n",
    "            print(f\"Mean Test loss of {txt}: {ts_mean}\")\n",
    "            print(f\"Var Test loss of {txt}: {ts_var}\")\n",
    "            print(f\"Std Test loss of {txt}: {ts_std}\")\n",
    "\n",
    "            return ts_mean, ts_var, ts_std\n",
    "        except AssertionError:\n",
    "            print(\"Evaluation failed!\")\n",
    "            return np.inf, np.inf, np.inf\n",
    "\n",
    "    if not skip_bb:\n",
    "        print(\"Black-Box fitting \\n\")\n",
    "        bb_symb, bb_g_symb, bb_h_symb, exec_time = valid_symb_model(\n",
    "            config=config,\n",
    "            model_path_gkan=f\"{model_path}/gkan\",\n",
    "            device=device,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            method=method,\n",
    "            black_box_fitting=True,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            sample_size = sample_size\n",
    "        )\n",
    "\n",
    "        print(latex(quantise(bb_symb)))\n",
    "        ts_mean_bb, ts_var_bb, ts_std_bb = print_symb_error(g_symb=bb_g_symb, h_symb=bb_h_symb)\n",
    "\n",
    "        results_dict[\"black_box_symb_quant\"] = str(quantise(bb_symb))\n",
    "        results_dict[\"black_box_symb\"] = str(bb_symb)\n",
    "        results_dict[\"black_box_symb_test_MAE\"] = ts_mean_bb\n",
    "        results_dict[\"black_box_symb_test_Var\"] = ts_var_bb\n",
    "        results_dict[\"black_box_symb_test_Std\"] = ts_std_bb\n",
    "        results_dict[\"black_box_exec_time\"] = exec_time\n",
    "\n",
    "    print(\"Spline-wise fitting\\n\")\n",
    "    spline_symb, spl_g_symb, spl_h_symb, exec_time = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/gkan\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        black_box_fitting=False,\n",
    "        n_g_hidden_layers=n_g_hidden_layers,\n",
    "        n_h_hidden_layers=n_h_hidden_layers,\n",
    "        sample_size = sample_size,\n",
    "        grid_orig=grid_orig\n",
    "    )\n",
    "    print(latex(quantise(spline_symb)))\n",
    "    ts_mean_sw, ts_var_sw, ts_std_sw = print_symb_error(g_symb=spl_g_symb, h_symb=spl_h_symb)\n",
    "\n",
    "    results_dict[\"spline_wise_symb_quant\"] = str(quantise(spline_symb))\n",
    "    results_dict[\"spline_wise_symb\"] = str(spline_symb)\n",
    "    results_dict[\"spline_wise_symb_test_MAE\"] = ts_mean_sw\n",
    "    results_dict[\"spline_wise_symb_test_Var\"] = ts_var_sw\n",
    "    results_dict[\"spline_wise_symb_test_Std\"] = ts_std_sw\n",
    "    results_dict[\"spline_wise_exec_time\"] = exec_time\n",
    "\n",
    "\n",
    "    if eval_model:\n",
    "        print(\"Evaluate raw model\\n\")\n",
    "        # Loading best model\n",
    "        best_model = build_model_from_file(\n",
    "            model_path=model_path,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            method=method,\n",
    "            adjoint=adjoint,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            compute_mult=compute_mult\n",
    "        )\n",
    "\n",
    "        tot_params = sum(p.numel() for p in best_model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of model's parameters: {tot_params}\\n\")\n",
    "        results_dict[\"Number of params\"] = tot_params\n",
    "\n",
    "        best_model = best_model.eval()\n",
    "        ts_mean_model, ts_var_model, ts_std_model = print_symb_error(\n",
    "            g_symb=best_model.conv.model.g_net,\n",
    "            h_symb=best_model.conv.model.h_net,\n",
    "            txt=\"best model\",\n",
    "            is_symb=False\n",
    "        )\n",
    "\n",
    "        results_dict[\"model_test_MAE\"] = ts_mean_model\n",
    "        results_dict[\"model_test_Var\"] = ts_var_model\n",
    "        results_dict[\"model_test_Std\"] = ts_std_model\n",
    "\n",
    "    with open(f\"{model_path}/{res_file_name}\", 'w') as file:\n",
    "        json.dump(results_dict, file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, node_index = 0, save_path = None, show=True, title = None):\n",
    "    title_ = f'y_true vs y_pred for Node {node_index}' if title is None else title\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_true[:, node_index, :], label='y_true', marker='o')\n",
    "    plt.plot(y_pred[:, node_index, :], label='y_pred', marker='o')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(title_)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(f\"{save_path}/{title_}.png\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.3504788815528931e-05\n",
      "Var Test loss of symbolic formula: 1.314533673970284e-13\n",
      "Std Test loss of symbolic formula: 3.625649836884809e-07\n"
     ]
    }
   ],
   "source": [
    "kur_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_kuramoto.yml\")\n",
    "\n",
    "KUR = get_test_set(\n",
    "    dynamics=kur_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=kur_config['input_range'],\n",
    "    **kur_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: torch.sin(x[:, 1] - x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: 2.0 + 0.5 * x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=KUR,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.071706852447581e-06\n",
      "Var Test loss of symbolic formula: 8.008373820613663e-14\n",
      "Std Test loss of symbolic formula: 2.829907033917133e-07\n"
     ]
    }
   ],
   "source": [
    "epid_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_epidemics.yml\")\n",
    "\n",
    "EPID = get_test_set(\n",
    "    dynamics=epid_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=epid_config['input_range'],\n",
    "    **epid_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.5*x[:, 1].unsqueeze(-1) * (1 - x[:, 0].unsqueeze(-1))\n",
    "h_symb = lambda x: x[:, 1].unsqueeze(1) - 0.5 * x[:, 0].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=EPID,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 3.735399635237021e-06\n",
      "Var Test loss of symbolic formula: 4.746857081617248e-13\n",
      "Std Test loss of symbolic formula: 6.889743886108719e-07\n"
     ]
    }
   ],
   "source": [
    "pop_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "\n",
    "POP = get_test_set(\n",
    "    dynamics=pop_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=pop_config['input_range'],\n",
    "    **pop_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.2*torch.pow(x[:, 1].unsqueeze(-1), 3)\n",
    "h_symb = lambda x: -0.5 * x[:, 0].unsqueeze(-1) + x[:, 1].unsqueeze(1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=POP,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.2006473374034006e-06\n",
      "Var Test loss of symbolic formula: 7.184599599254429e-14\n",
      "Std Test loss of symbolic formula: 2.6804103415810103e-07\n"
     ]
    }
   ],
   "source": [
    "bio_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical.yml\")\n",
    "\n",
    "BIO = get_test_set(\n",
    "    dynamics=bio_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=bio_config['input_range'],\n",
    "    **bio_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: (-0.5*x[:, 1] * x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: (1.0 - 0.5 * x[:, 0]).unsqueeze(-1)  + x[:, 1].unsqueeze(-1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=BIO,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symb Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_candidates = [(-10, 10), (-5, 5)]\n",
    "weight_candidates = [0.0, 0.5, 1.0]\n",
    "\n",
    "grid_orig = (\n",
    "    [(-10, 10), (-5, 5)],\n",
    "    [0.01, 0.05, 0.1],\n",
    "    [0.0, 0.5, 1.0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=\"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.00014469254529103637}\n",
      "Fitting G_Net...\n",
      "Execution time: 19.499432 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 18.168052 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.00012971960192468637\n",
      "Var Test loss of symbolic formula: 1.551889595018015e-10\n",
      "Std Test loss of symbolic formula: 1.2457486082745648e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'log_loss', 'theta': 0.01, 'cut_threshold': 0.1, 'valid_loss': 0.07096663117408752}\n",
      "Fitting G_Net...\n",
      "Execution time: 104.350869 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 12.334118 seconds\n",
      "\\sum_{j}(-0.34*exp(0.37*x_i) - 0.31*sin(0.96*x_i - 0.6*x_j + 1.39) + 0.56) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.05904915059606234\n",
      "Var Test loss of symbolic formula: 0.00011741744970508111\n",
      "Std Test loss of symbolic formula: 0.010835933264148553\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 410\n",
      "\n",
      "Mean Test loss of best model: 7.585063091634463e-05\n",
      "Var Test loss of best model: 1.0755207177248116e-10\n",
      "Std Test loss of best model: 1.037073149649923e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=30000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.0015490096993744373}\n",
      "Fitting G_Net...\n",
      "Execution time: 10.882983 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.879816 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) + \\log{\\left(2.63 - x_{i} \\right)}\n",
      "Mean Test loss of symbolic formula: 0.0016061388499413927\n",
      "Var Test loss of symbolic formula: 3.1646181141304017e-09\n",
      "Std Test loss of symbolic formula: 5.6254938575474435e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'log_loss', 'theta': 0.01, 'cut_threshold': 0.01, 'valid_loss': 0.0024255430325865746}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting G_Net...\n",
      "Execution time: 19.164038 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 22.784075 seconds\n",
      "\\sum_{j}((1.53*tan(0.49*x_j - 0.61) + 1.07)*(0.12*x_i**2 - 0.62*x_i - 0.01) + 0.01) - 0.03 x_{i} - 1.59 e^{0.17 x_{i}} - 0.19 \\tan{\\left(0.99 x_{i} - 0.64 \\right)} + 2.47\n",
      "Mean Test loss of symbolic formula: 0.002546172977114717\n",
      "Var Test loss of symbolic formula: 1.375886797443832e-07\n",
      "Std Test loss of symbolic formula: 0.0003709294808240283\n",
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.006484286859631538}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.605852 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 13.135409 seconds\n",
      "\\sum_{j}(-0.49*x_i*x_j) + \\log{\\left(2.66 - x_{i} \\right)}\n",
      "Mean Test loss of symbolic formula: 0.008359562295178572\n",
      "Var Test loss of symbolic formula: 7.126211071317106e-08\n",
      "Std Test loss of symbolic formula: 0.00026694964078112385\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'log_loss', 'theta': 0.01, 'cut_threshold': 0.1, 'valid_loss': 0.008273964747786522}\n",
      "Fitting G_Net...\n",
      "Execution time: 14.990670 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 18.903697 seconds\n",
      "\\sum_{j}(-0.07*sin(2.77*x_j - 1.33) - 0.13*tan(1.34*x_i - 0.91) - 0.04*tanh((5.46*tanh(5.28*x_j - 1.36) - 2.55)*(0.98*Abs(0.91*x_i - 0.22) - 0.15)) - 0.15) + 0.41 e^{0.7 \\cos{\\left(1.83 x_{i} + 0.55 \\right)}} + 0.31\n",
      "Mean Test loss of symbolic formula: 0.0070102896230916185\n",
      "Var Test loss of symbolic formula: 5.277043828179128e-07\n",
      "Std Test loss of symbolic formula: 0.0007264326416247502\n",
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.2170238196849823}\n",
      "Fitting G_Net...\n",
      "Execution time: 19.769064 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.866020 seconds\n",
      "\\sum_{j}(-0.01*x_j**2) - \\sin{\\left(9.12 x_{i} \\right)}\n",
      "Mean Test loss of symbolic formula: 0.20246256391207376\n",
      "Var Test loss of symbolic formula: 0.001162505112732464\n",
      "Std Test loss of symbolic formula: 0.03409552921912878\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'score', 'theta': 0.01, 'cut_threshold': 0.001, 'valid_loss': 0.20578843355178833}\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 10.989042 seconds\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 20.675772 seconds\n",
      "\\sum_{j}(0.0) - 1.43 \\sin{\\left(2.55 \\sin{\\left(10.09 x_{i} - 6.79 \\right)} - 0.54 \\right)} + 0.09\n",
      "Mean Test loss of symbolic formula: 0.18829227983951569\n",
      "Var Test loss of symbolic formula: 0.00046965735916796686\n",
      "Std Test loss of symbolic formula: 0.021671579526374326\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=bio_config,\n",
    "        model_path=model_path,\n",
    "        test_set=BIO,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.0015904916217550635}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 13.648612 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 3.521600 seconds\n",
      "\\sum_{j}(-0.5*sin(-1.0*x_i + 1.0*x_j + 9.42)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0015296822724243004\n",
      "Var Test loss of symbolic formula: 5.804752006217099e-08\n",
      "Std Test loss of symbolic formula: 0.00024093052953532267\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 543\n",
      "\n",
      "Mean Test loss of best model: 0.0016122294279436271\n",
      "Var Test loss of best model: 6.193546818525011e-07\n",
      "Std Test loss of best model: 0.0007869909032844669\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=\"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 200, 'valid_loss': 0.00037592652370221913}\n",
      "Fitting G_Net...\n",
      "Execution time: 36.569105 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 39.925308 seconds\n",
      "\\sum_{j}(-0.5*sin(x_i - x_j)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0003103772275305043\n",
      "Var Test loss of symbolic formula: 1.0822150048683463e-10\n",
      "Std Test loss of symbolic formula: 1.040295633398673e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'score', 'theta': 0.01, 'cut_threshold': 0.1, 'valid_loss': 0.0028883807826787233}\n",
      "Fitting G_Net...\n",
      "Execution time: 4.323579 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.755881 seconds\n",
      "\\sum_{j}(0.5*cos(1.0*x_i - 1.0*x_j + 1.57)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0022030010974655547\n",
      "Var Test loss of symbolic formula: 2.0978495420216526e-08\n",
      "Std Test loss of symbolic formula: 0.00014483955060761727\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 221\n",
      "\n",
      "Mean Test loss of best model: 0.001870445868310829\n",
      "Var Test loss of best model: 9.885763786732787e-08\n",
      "Std Test loss of best model: 0.0003144163447839948\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.007145709823817015}\n",
      "Fitting G_Net...\n",
      "Execution time: 19.059034 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 23.521774 seconds\n",
      "\\sum_{j}(-0.49*sin(x_i - x_j)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.007131052669137716\n",
      "Var Test loss of symbolic formula: 6.036935300456649e-08\n",
      "Std Test loss of symbolic formula: 0.0002457017562097725\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.03981337323784828}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 5.850058 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.572098 seconds\n",
      "\\sum_{j}(-0.49*sin(1.0*x_i - 1.01*x_j + 0.1)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.03392164781689644\n",
      "Var Test loss of symbolic formula: 4.0513348818336605e-05\n",
      "Std Test loss of symbolic formula: 0.006365009726491909\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 200, 'valid_loss': 0.05628015473484993}\n",
      "Fitting G_Net...\n",
      "Execution time: 33.167968 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 42.545120 seconds\n",
      "\\sum_{j}(-0.4*sin(x_i - x_j)) - 0.2 \\sin{\\left(x_{i} \\right)} + 1.94\n",
      "Mean Test loss of symbolic formula: 0.10963946580886841\n",
      "Var Test loss of symbolic formula: 0.00019089434142775344\n",
      "Std Test loss of symbolic formula: 0.013816451839302066\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.08241403847932816}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 9.635976 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 22.507003 seconds\n",
      "\\sum_{j}(0.01 - 0.43*sin(-0.01*x_i**3 + 0.12*x_i**2 + 0.53*x_i + 5.72*sin(0.17*x_j + 2.53) - 2.83)) + 0.01 x_{i} + 0.03 \\left(\\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 0.66\\right)^{3} - 0.07 \\left(\\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 0.66\\right)^{2} + 0.14 \\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 2.15\n",
      "Mean Test loss of symbolic formula: 0.093520092467467\n",
      "Var Test loss of symbolic formula: 2.8339800094176776e-06\n",
      "Std Test loss of symbolic formula: 0.0016834429035217314\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 1.091734766960144}\n",
      "Fitting G_Net...\n",
      "Execution time: 16.390624 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.564453 seconds\n",
      "\\sum_{j}(-tanh(249.46/(x_i**3*x_j**3))) + e^{3 \\sin{\\left(1.74 x_{i} \\right)}}\n",
      "Mean Test loss of symbolic formula: 1.2062313159306843\n",
      "Var Test loss of symbolic formula: 2.1666894396174835e-06\n",
      "Std Test loss of symbolic formula: 0.001471967879954411\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.05, 'valid_loss': 0.943835973739624}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting G_Net...\n",
      "Execution time: 0.000438 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.622671 seconds\n",
      "\\sum_{j}(0) - 5.15 x_{i} - 0.12 \\left(x_{i} + 0.27\\right)^{3} + 1.42 \\left(x_{i} + 0.27\\right)^{2} - 7.61 \\sin{\\left(0.8 x_{i} - 2.19 \\right)} + 2.75 \\cos{\\left(0.88 x_{i} + 1.23 \\right)} - 13.32 \\cos{\\left(5.35 \\cos{\\left(1.85 x_{i} - 4.54 \\right)} - 2.88 \\right)} + 6.57\n",
      "Mean Test loss of symbolic formula: 1.010321815808614\n",
      "Var Test loss of symbolic formula: 5.027089721289081e-05\n",
      "Std Test loss of symbolic formula: 0.007090197261916682\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=kur_config,\n",
    "        model_path=model_path,\n",
    "        test_set=KUR,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.00017959623073693365}\n",
      "Fitting G_Net...\n",
      "Execution time: 33.093222 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.910269 seconds\n",
      "\\sum_{j}(0.98*(0.17*x_j + 1)**0.95*exp(0.04*sin(0.78*x_i + 2.82)) - 1.24*sin((0.01 - 0.23*x_j)*(18.29*log(8.0 - 0.76*x_i) - 36.8) + 6.59) - 0.6) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.00017571135443480065\n",
      "Var Test loss of symbolic formula: 5.10487277164613e-10\n",
      "Std Test loss of symbolic formula: 2.2593965503306694e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 264\n",
      "\n",
      "Mean Test loss of best model: 0.00019420394770956287\n",
      "Var Test loss of best model: 9.010235804097534e-11\n",
      "Std Test loss of best model: 9.492226189939605e-06\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=\"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.00013034719449933618}\n",
      "Fitting G_Net...\n",
      "Execution time: 16.949507 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.884131 seconds\n",
      "\\sum_{j}(x_j*(0.5 - 0.5*x_i)) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.00011974307077859218\n",
      "Var Test loss of symbolic formula: 1.3272674570917887e-10\n",
      "Std Test loss of symbolic formula: 1.152070942733905e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'score', 'theta': 0.1, 'cut_threshold': 0.1, 'valid_loss': 0.05961911007761955}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 15.494766 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.646192 seconds\n",
      "\\sum_{j}(0.08*x_j + 0.27*exp(-1.65*x_i + 0.69*x_j) - 0.12) - 0.49 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.06654291599988937\n",
      "Var Test loss of symbolic formula: 4.919405087770261e-06\n",
      "Std Test loss of symbolic formula: 0.002217973193654572\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 277\n",
      "\n",
      "Mean Test loss of best model: 0.00011343214767596994\n",
      "Var Test loss of best model: 2.925668873129952e-10\n",
      "Std Test loss of best model: 1.7104586733183446e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.002244098810479045}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.355172 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.227076 seconds\n",
      "\\sum_{j}(x_j*(0.51 - 0.51*x_i)) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.002354982541874051\n",
      "Var Test loss of symbolic formula: 1.0752977480680034e-07\n",
      "Std Test loss of symbolic formula: 0.0003279173292261334\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.1, 'valid_loss': 0.014380019158124924}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 31.594218 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.871257 seconds\n",
      "\\sum_{j}(-0.46*x_i*x_j + 0.47*x_j) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.01322010283668836\n",
      "Var Test loss of symbolic formula: 2.6293119423887207e-06\n",
      "Std Test loss of symbolic formula: 0.0016215153228966788\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 450\n",
      "\n",
      "Mean Test loss of best model: 0.0020562036661431193\n",
      "Var Test loss of best model: 8.05423553676876e-08\n",
      "Std Test loss of best model: 0.0002837998508944069\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.028511973097920418}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.184228 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.947385 seconds\n",
      "\\sum_{j}(-0.18*log(x_i)) - 0.14\n",
      "Mean Test loss of symbolic formula: 0.02964874605337779\n",
      "Var Test loss of symbolic formula: 6.506173588601313e-06\n",
      "Std Test loss of symbolic formula: 0.002550720209784153\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.1, 'valid_loss': 0.03664926439523697}\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.217886 seconds\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.446302 seconds\n",
      "\\sum_{j}(0.34*tanh(0.55*x_j + 0.54*cos(2.73*x_i + 0.1) - 0.99) + 0.29) - 0.13\n",
      "Mean Test loss of symbolic formula: 0.03262868461509546\n",
      "Var Test loss of symbolic formula: 1.766416481109898e-06\n",
      "Std Test loss of symbolic formula: 0.0013290660183414133\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 352\n",
      "\n",
      "Mean Test loss of best model: 0.0261530801653862\n",
      "Var Test loss of best model: 1.459289080037405e-05\n",
      "Std Test loss of best model: 0.003820064240346496\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.07408930361270905}\n",
      "Fitting G_Net...\n",
      "Execution time: 17.210457 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.634566 seconds\n",
      "\\sum_{j}(0.01 - 0.01*x_j) - x_{i} + 0.77\n",
      "Mean Test loss of symbolic formula: 0.07820665091276169\n",
      "Var Test loss of symbolic formula: 1.0264305971507959e-05\n",
      "Std Test loss of symbolic formula: 0.0032037955570710123\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.10667437314987183}\n",
      "Fitting G_Net...\n",
      "Execution time: 12.127377 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.694168 seconds\n",
      "\\sum_{j}(0.0) - 1.09 \\tanh{\\left(88.88 x_{i} - 39.68 \\right)} + 0.17 \\tanh{\\left(78.19 \\sin{\\left(10.47 x_{i} - 5.14 \\right)} - 24.73 \\right)} + 0.9 \\tanh{\\left(18.53 \\tanh{\\left(9.74 x_{i} - 4.92 \\right)} + 25.3 \\right)} + 0.09\n",
      "Mean Test loss of symbolic formula: 0.10957680145899455\n",
      "Var Test loss of symbolic formula: 1.52982685459355e-05\n",
      "Std Test loss of symbolic formula: 0.003911300109418286\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 174\n",
      "\n",
      "Mean Test loss of best model: 0.1770920753479004\n",
      "Var Test loss of best model: 9.097893966740027e-05\n",
      "Std Test loss of best model: 0.00953828808892876\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=epid_config,\n",
    "        model_path=model_path,\n",
    "        test_set=EPID,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 8.050165 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.214236 seconds\n"
     ]
    }
   ],
   "source": [
    "gkan_symb, symb_g, symb_h, _ = fit_model(\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    model_path = \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_12/0/gkan\",\n",
    "    theta = 0.01,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    sample_size=10000,\n",
    "    cut_threshold=0.1,\n",
    "    sort_by=\"score\",\n",
    "    fit_orig=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( 0.0707661767435222*x_j) - 0.50008836438213 x_{i}$"
      ],
      "text/plain": [
       "\\sum_{j}( 0.0707661767435222*x_j) - 0.50008836438213*x_i"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkan_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = get_symb_test_error(\n",
    "    g_symb=symb_g,\n",
    "    h_symb=symb_h,\n",
    "    test_set=POP,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01547161970908443\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.0001383304625051096}\n",
      "Fitting G_Net...\n",
      "Execution time: 18.222491 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.137481 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.00012729887142389393\n",
      "Var Test loss of symbolic formula: 1.3614101926894765e-10\n",
      "Std Test loss of symbolic formula: 1.1667948374455024e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'log_loss', 'theta': 0.05, 'cut_threshold': 0.1, 'valid_loss': 0.017918474972248077}\n",
      "Pruning node (0,0)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.877642 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 25.389021 seconds\n",
      "\\sum_{j}(-0.02*x_i**2 - 0.04*x_i - 0.03*exp(1.01*x_i) - 0.01*sin(2.35*x_j - 0.33) - 0.01*sin(3.06*x_j - 0.62) + 0.06*tan(1.03*x_j + 0.16) + 0.02*tan(1.22*x_j + 0.08) + 0.15*tanh(0.8*x_i - 0.79) + 0.1) - 0.05 x_{i} - 0.81 e^{0.19 x_{i}} - 0.2 e^{0.55 x_{i}} - 0.07 \\tan{\\left(0.81 x_{i} + 0.23 \\right)} - 0.15 \\tanh{\\left(0.75 x_{i} + 0.22 \\right)} + 1.06\n",
      "Mean Test loss of symbolic formula: 0.013361897940436998\n",
      "Var Test loss of symbolic formula: 2.211689633694899e-06\n",
      "Std Test loss of symbolic formula: 0.00148717505146331\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 516\n",
      "\n",
      "Mean Test loss of best model: 0.00040224265345993143\n",
      "Var Test loss of best model: 6.4747059720440794e-09\n",
      "Std Test loss of best model: 8.046555767559235e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-population-gkan/population_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=pop_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=POP,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 9.614797454560176e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.817188 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 12.326990 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 8.774545131018385e-05\n",
      "Var Test loss of symbolic formula: 1.0301099316333908e-11\n",
      "Std Test loss of symbolic formula: 3.2095325697574573e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.029043128713965416}\n",
      "Fitting G_Net...\n",
      "Execution time: 39.032847 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.293388 seconds\n",
      "\\sum_{j}(0.02*x_i + 0.02*x_j + 0.04*tan(1.09*x_j - 0.03)) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.022732293233275414\n",
      "Var Test loss of symbolic formula: 3.847226371665735e-06\n",
      "Std Test loss of symbolic formula: 0.0019614347737474565\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 200, 'valid_loss': 0.006987582426518202}\n",
      "Fitting G_Net...\n",
      "Execution time: 31.783805 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 32.497264 seconds\n",
      "\\sum_{j}(0.18*x_j**3) - 0.46 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.006857929440836112\n",
      "Var Test loss of symbolic formula: 1.6288278926204385e-08\n",
      "Std Test loss of symbolic formula: 0.0001276255418253117\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.1, 'valid_loss': 0.03565327823162079}\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.319274 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 7.642629 seconds\n",
      "\\sum_{j}(0.08*x_j**3 + 0.01*x_j + (-0.13*x_j - 0.02)*(-0.03*sin(4.06*x_i + 0.04) - 0.2) - 0.01*sin(4.61*x_j - 0.08) - 0.06*cos(1.07*x_i + 0.79) + 0.13) - 1.46 + 1.45 e^{- 0.32 x_{i}}\n",
      "Mean Test loss of symbolic formula: 0.03091899926463763\n",
      "Var Test loss of symbolic formula: 5.5005617849095895e-06\n",
      "Std Test loss of symbolic formula: 0.00234532764979855\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 200, 'valid_loss': 0.013373607769608498}\n",
      "Fitting G_Net...\n",
      "Execution time: 30.462442 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 32.738222 seconds\n",
      "\\sum_{j}(0.17*x_j**3) - 0.49 x_{i} + 0.04\n",
      "Mean Test loss of symbolic formula: 0.019687574977676075\n",
      "Var Test loss of symbolic formula: 1.8448933954055678e-06\n",
      "Std Test loss of symbolic formula: 0.0013582685284602481\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.027769051492214203}\n",
      "Fitting G_Net...\n",
      "Execution time: 40.509048 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.146392 seconds\n",
      "\\sum_{j}(0.1*x_j**3 + 0.02*x_j**2 + 0.01*x_j - (0.03 - 0.06*tanh(27.26*x_i + 5.78))*(0.2*tanh(22.95*x_j - 0.48) - 0.11) - 0.02*(-0.27*sin(11.13*x_i - 2.52) - 0.09)*tan(1.62*x_j - 0.03) - 0.01) - 0.77 e^{0.35 \\sin{\\left(1.8 x_{i} \\right)} - 0.15 \\cos{\\left(1.8 x_{i} \\right)}} - 0.19 \\tanh{\\left(55.42 x_{i}^{3} - 12.05 x_{i}^{2} - 16.17 x_{i} + 7.26 \\right)} + 0.9\n",
      "Mean Test loss of symbolic formula: 0.02136990676323573\n",
      "Var Test loss of symbolic formula: 5.238051046089426e-06\n",
      "Std Test loss of symbolic formula: 0.002288678886626393\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=pop_config,\n",
    "        model_path=model_path,\n",
    "        test_set=POP,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Epid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "\n",
    "pysr_model = lambda : get_pysr_model(\n",
    "    model_selection=\"score\",\n",
    "    n_iterations=200,\n",
    "    parallelism=\"serial\",\n",
    "    random_state = 9999,\n",
    "    deterministic = True\n",
    ")\n",
    "\n",
    "gkan_symb, symb_g, symb_h, _ = fit_black_box_from_kan(\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    device='cuda',\n",
    "    model_path=model_path_gkan,\n",
    "    pysr_model=pysr_model,\n",
    "    sample_size=10000,\n",
    "    theta=-np.inf,\n",
    "    message_passing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682064 x_{i} + 2.4648788$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682064*x_i + 2.4648788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkan_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model with model selection: score, theta: 0.01, ct:1e-05, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.04075533524155617\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "2.31595301522748*x_i + 1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) + 1.66742547802796\n",
      "Fitting model with model selection: score, theta: 0.01, ct:0.001, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.04075533524155617\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "2.31595301522748*x_i + 1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) + 1.66742547802796\n",
      "Fitting model with model selection: score, theta: 0.001, ct:1e-05, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.04075533524155617\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "2.31595301522748*x_i + 1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) + 1.66742547802796\n",
      "Fitting model with model selection: score, theta: 0.001, ct:0.001, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.04075533524155617\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "2.31595301522748*x_i + 1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) + 1.66742547802796\n",
      "Fitting model with model selection: log_loss, theta: 0.01, ct:1e-05, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.03941219672560692\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) - 2.90646585491406*tanh(0.1771112458638*x_i**3 + 0.0871818528414837*x_i**2 - 1.36529222873796*x_i - 0.587179376084621) + 1.08466950319977\n",
      "Fitting model with model selection: log_loss, theta: 0.01, ct:0.001, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.03941219672560692\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) - 2.90646585491406*tanh(0.1771112458638*x_i**3 + 0.0871818528414837*x_i**2 - 1.36529222873796*x_i - 0.587179376084621) + 1.08466950319977\n",
      "Fitting model with model selection: log_loss, theta: 0.001, ct:1e-05, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.03941219672560692\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) - 2.90646585491406*tanh(0.1771112458638*x_i**3 + 0.0871818528414837*x_i**2 - 1.36529222873796*x_i - 0.587179376084621) + 1.08466950319977\n",
      "Fitting model with model selection: log_loss, theta: 0.001, ct:0.001, alpha: [1e-08, 1e-05, 0.001, 0.1]\n",
      "0.03941219672560692\n",
      "0.00793399829034096*tanh(2.49162501367285*x_i - 4.60957300897616) - 0.0179951346099805*tanh(0.867764356138973*x_j - 1.41939897565132) - 0.0114351987094713\n",
      "1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) - 2.90646585491406*tanh(0.1771112458638*x_i**3 + 0.0871818528414837*x_i**2 - 1.36529222873796*x_i - 0.587179376084621) + 1.08466950319977\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "from datasets.RealEpidemics import RealEpidemics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "res = {}\n",
    "real_epid_data = RealEpidemics(\n",
    "    root = './data_real_epid_covid_int_scaled',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=False,\n",
    "    history=1,\n",
    "    horizon=44,\n",
    "    scale=True,\n",
    "    scale_range=(-1, 1)\n",
    ")\n",
    "\n",
    "tr_len = real_epid_data[0].y.shape[0]\n",
    "\n",
    "model_selections = [\"score\", \"log_loss\"]\n",
    "theta = [0.01, 0.001]\n",
    "cut_threshold = [1e-5, 1e-3]\n",
    "alpha = [[1e-8, 1e-5, 1e-3, 1e-1]]\n",
    "\n",
    "\n",
    "grid_sw = (\n",
    "    model_selections,\n",
    "    theta,\n",
    "    cut_threshold,\n",
    "    alpha\n",
    ")\n",
    "\n",
    "search_space = list(itertools.product(*grid_sw))\n",
    "\n",
    "for i, params in enumerate(search_space):\n",
    "    print(f\"Fitting model with model selection: {params[0]}, theta: {params[1]}, ct:{params[2]}, alpha: {params[3]}\")\n",
    "    symb_spline_wise, symb_g, symb_h, _ = fit_model(\n",
    "        n_h_hidden_layers=2,\n",
    "        n_g_hidden_layers=2,\n",
    "        model_path=model_path_gkan,\n",
    "        theta=params[1],\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        sample_size=10000,\n",
    "        sort_by=params[0],\n",
    "        cut_threshold=params[2],\n",
    "        alpha_grid=params[3],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    g_symb = make_callable(symb_g)\n",
    "    h_symb = make_callable(symb_h)\n",
    "    \n",
    "    symb_model = get_model(\n",
    "        g = g_symb,\n",
    "        h = h_symb,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        integration_method='rk4'\n",
    "    )\n",
    "    \n",
    "    data_0 = real_epid_data[0]\n",
    "    y_pred = symb_model(data_0).cpu().detach().numpy()[:int(tr_len*0.8)]\n",
    "    y_true = real_epid_data[0].y.cpu().detach().numpy()[:int(tr_len*0.8)]\n",
    "    \n",
    "    err = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "    print(err)\n",
    "    res[i] = (str(symb_spline_wise), err, str(symb_g), str(symb_h))  \n",
    "    print(str(symb_g))\n",
    "    print(str(symb_h))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = min(res.values(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19863983320216*tanh(0.573780466363341*tanh(1.29877970942686*x_i + 0.937609075806) + 0.786015724237153) - 2.90646585491406*tanh(0.1771112458638*x_i**3 + 0.0871818528414837*x_i**2 - 1.36529222873796*x_i - 0.587179376084621) + 1.08466950319977'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model with score and 50\n",
      "0.02730431593954563\n",
      "Fitting model with score and 100\n",
      "0.027311544865369797\n",
      "Fitting model with score and 200\n",
      "0.06641161441802979\n",
      "Fitting model with accuracy and 50\n",
      "0.027311544865369797\n",
      "Fitting model with accuracy and 100\n",
      "0.03936349228024483\n",
      "Fitting model with accuracy and 200\n",
      "0.027311554178595543\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "model_selections = [\"score\", \"accuracy\"]\n",
    "n_iterations = [50, 100, 200]\n",
    "\n",
    "real_epid_data = RealEpidemics(\n",
    "    root = './data_real_epid_covid_int_scaled',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=False,\n",
    "    history=1,\n",
    "    horizon=44,\n",
    "    scale=True,\n",
    "    scale_range=(-1, 1)\n",
    ")\n",
    "\n",
    "tr_len = real_epid_data[0].y.shape[0]\n",
    "\n",
    "for mod in model_selections:\n",
    "    for n_iter in n_iterations:\n",
    "        print(f\"Fitting model with {mod} and {n_iter}\")\n",
    "        model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "\n",
    "        pysr_model = lambda : get_pysr_model(\n",
    "            model_selection=mod,\n",
    "            n_iterations=n_iter,\n",
    "            # parallelism=\"serial\",\n",
    "            # random_state = 9999,\n",
    "            # deterministic = True\n",
    "        )\n",
    "\n",
    "        gkan_symb, symb_g, symb_h, _ = fit_black_box_from_kan(\n",
    "            n_g_hidden_layers=2,\n",
    "            n_h_hidden_layers=2,\n",
    "            device='cuda',\n",
    "            model_path=model_path_gkan,\n",
    "            pysr_model=pysr_model,\n",
    "            sample_size=10000,\n",
    "            theta=-np.inf,\n",
    "            message_passing=False\n",
    "        )\n",
    "        \n",
    "        g_symb = make_callable(symb_g)\n",
    "        h_symb = make_callable(symb_h)\n",
    "        \n",
    "        symb_model = get_model(\n",
    "            g = g_symb,\n",
    "            h = h_symb,\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            integration_method='rk4'\n",
    "        )\n",
    "        \n",
    "        data_0 = real_epid_data[0]\n",
    "        y_pred = symb_model(data_0).cpu().detach().numpy()[:int(tr_len*0.8)]\n",
    "        y_true = real_epid_data[0].y.cpu().detach().numpy()[:int(tr_len*0.8)]\n",
    "        \n",
    "        err = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "        print(err)\n",
    "        res[str(gkan_symb)] = err    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4681642*x_i + 2.464845': 0.02730431593954563,\n",
       " '\\\\sum_{j}( -0.0039747013*exp(x_j)) + 2.4682088*x_i + 2.4648814': 0.027311544865369797,\n",
       " '\\\\sum_{j}( -0.0039747115*exp(x_j)) + 3.3896239*tan(tanh(x_i + 0.9902851))': 0.06641161441802979,\n",
       " '\\\\sum_{j}( -0.003974712*exp(x_j)) + 2.4682086*x_i + 2.4648812': 0.027311544865369797,\n",
       " '\\\\sum_{j}( -0.0039747115*exp(x_j)) + 8.122365*tanh(exp(x_i)) - 2.8761487': 0.03936349228024483,\n",
       " '\\\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682174*x_i + 2.46489': 0.027311554178595543}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSS Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tss_test_error(\n",
    "    text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h,\n",
    "    row_means,\n",
    "    test_set,\n",
    "    result_dict,\n",
    "    suffix = '',\n",
    "    method = \"dopri5\"\n",
    "):\n",
    "    g_symb = sp.S(0)\n",
    "    h_symb = sp.S(0)\n",
    "\n",
    "    \n",
    "    for symb_g in text_sympy_mapping_g.keys():\n",
    "        g_symb += row_means[symb_g] * text_sympy_mapping_g[symb_g]\n",
    "    for symb_h in text_sympy_mapping_h.keys():\n",
    "        h_symb += row_means[symb_h] * text_sympy_mapping_h[symb_h]\n",
    "\n",
    "\n",
    "    try:\n",
    "        test_losses = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=test_set,\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=1e-5,\n",
    "            rtol=1e-5,\n",
    "            is_symb=True\n",
    "        )\n",
    "\n",
    "        ts_mean = np.mean(test_losses)\n",
    "        ts_var = np.var(test_losses)\n",
    "        ts_std = np.std(test_losses)\n",
    "\n",
    "        print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "        print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "        print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "        \n",
    "        result_dict[f'tss_test_mae_{suffix}'] = ts_mean\n",
    "        result_dict[f'tss_test_var_{suffix}'] = ts_var\n",
    "        result_dict[f'tss_test_std_{suffix}'] = ts_std\n",
    "        \n",
    "    except AssertionError:\n",
    "        print(\"Evaluation failed !\")\n",
    "        result_dict[f'error_{suffix}'] = 'Evaluation failed !'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.499529\n",
       "constant          1.999741\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1_nofrac/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0002911205034858237\n",
      "Var Test loss of symbolic formula: 2.494153071344198e-10\n",
      "Std Test loss of symbolic formula: 1.5792887865568468e-05\n"
     ]
    }
   ],
   "source": [
    "results_kur = {}\n",
    "\n",
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.484048\n",
       "constant          2.008079\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1_nofrac/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.010279357433319092\n",
      "Var Test loss of symbolic formula: 5.398350177230014e-07\n",
      "Std Test loss of symbolic formula: 0.0007347346580385339\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "tanx1            -0.018572\n",
       "sinx1jMinusx1i   -0.081116\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1_nofrac/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.0151582956314087\n",
      "Var Test loss of symbolic formula: 0.0002279870968303991\n",
      "Std Test loss of symbolic formula: 0.015099241597855141\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"tanx1\": sp.tan(x_i)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000e+00\n",
       "expx1jMinusx1i    5.402955e-03\n",
       "x1iexpx1j         1.281277e-04\n",
       "x1isinx1j        -3.959205e-16\n",
       "expx1j            2.030076e-03\n",
       "sinx1jMinusx1i    0.000000e+00\n",
       "x1x1x1            1.047551e-02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1_nofrac/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: nan\n",
      "Var Test loss of symbolic formula: nan\n",
      "Std Test loss of symbolic formula: nan\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i),\n",
    "    \"x1iexpx1j\" : x_i * sp.exp(x_j),\n",
    "    \"x1isinx1j\": x_i * sp.sin(x_j),\n",
    "    \"expx1j\": sp.exp(x_j),\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\" : x_i * x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Kuramoto-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_kur, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "constant         -0.567966\n",
       "expx1jMinusx1i    0.208438\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "results_epid = {}\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.1941202183564504\n",
      "Var Test loss of symbolic formula: 0.0005310114619173017\n",
      "Std Test loss of symbolic formula: 0.023043685944685623\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.256831\n",
       "constant          0.569542\n",
       "expx1jMinusx1i    0.013251\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.06786157687505086\n",
      "Var Test loss of symbolic formula: 5.084867689883785e-06\n",
      "Std Test loss of symbolic formula: 0.0022549651194383883\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i,\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.091028\n",
       "expx1jMinusx1i    0.111314\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.016693448647856712\n",
      "Var Test loss of symbolic formula: 8.436841921384436e-06\n",
      "Std Test loss of symbolic formula: 0.002904624230668132\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1ifracx1j        -0.019999\n",
       "fracx1ix1j         0.014712\n",
       "fracx1jMinusx1i    0.000244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.08860065788030624\n",
      "Var Test loss of symbolic formula: 4.077819097984363e-06\n",
      "Std Test loss of symbolic formula: 0.002019361061817416\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Epidemics-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_epid, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.711350\n",
       "constant    0.867073\n",
       "dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.036044025172789894\n",
      "Var Test loss of symbolic formula: 1.2206604668749429e-06\n",
      "Std Test loss of symbolic formula: 0.0011048350405716424\n"
     ]
    }
   ],
   "source": [
    "results_bio = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.740610\n",
       "constant    0.905639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03708266963561376\n",
      "Var Test loss of symbolic formula: 2.1507763171681031e-07\n",
      "Std Test loss of symbolic formula: 0.00046376462965259685\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "x1ix1j    1.077840\n",
       "x1x1     -2.325285\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: nan\n",
      "Var Test loss of symbolic formula: nan\n",
      "Std Test loss of symbolic formula: nan\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='50db',\n",
    "    method=\"euler\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1ifracx1j         0.011954\n",
       "fracx1ix1j         0.003264\n",
       "fracx1jMinusx1i    0.000703\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.18021548291047415\n",
      "Var Test loss of symbolic formula: 0.00045013090946064175\n",
      "Std Test loss of symbolic formula: 0.0212162887768017\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='20db',\n",
    "    method=\"euler\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Biochemical-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_bio, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.026403\n",
       "x1j         0.181286\n",
       "sinx1j     -0.003445\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.12766799330711365\n",
      "Var Test loss of symbolic formula: 7.629820227054533e-05\n",
      "Std Test loss of symbolic formula: 0.00873488421620718\n"
     ]
    }
   ],
   "source": [
    "results_pop = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.008463\n",
       "x1j         0.049181\n",
       "sinx1j      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0984332486987114\n",
      "Var Test loss of symbolic formula: 9.581733575569906e-06\n",
      "Std Test loss of symbolic formula: 0.0030954375418622013\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "sinx1j   -0.437936\n",
       "x1j       0.447304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.09804610659678777\n",
      "Var Test loss of symbolic formula: 6.87397651082882e-06\n",
      "Std Test loss of symbolic formula: 0.0026218269414339346\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN      0.000000\n",
       "sinx1   -0.395957\n",
       "x1x1     0.306063\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.049917796005805336\n",
      "Var Test loss of symbolic formula: 6.379734967220602e-06\n",
      "Std Test loss of symbolic formula: 0.0025258137237770726\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"sinx1\": sp.sin(x_i),\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Population-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_pop, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
