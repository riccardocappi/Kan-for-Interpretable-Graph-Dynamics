{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7c8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00a2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import load_config\n",
    "from datasets.SyntheticData import SyntheticData\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import os\n",
    "from datasets.RealEpidemics import RealEpidemics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4398ae",
   "metadata": {},
   "source": [
    "## two-step-SINDy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.baseline.TSS.NumericalDerivatives import NumericalDeriv\n",
    "from models.baseline.TSS.ElementaryFunctions_Matrix import ElementaryFunctions_Matrix\n",
    "from models.baseline.TSS.TwoPhaseInference import TwoPhaseInference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b79170",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_tss(config, snr_db = -1, real_epid=False):\n",
    "    if not real_epid:\n",
    "        dataset = SyntheticData(\n",
    "            root=config['data_folder'],\n",
    "            dynamics=config['name'],\n",
    "            t_span=config['t_span'],\n",
    "            t_max=config['t_eval_steps'],\n",
    "            num_samples=config['num_samples'],\n",
    "            seed=config['seed'],\n",
    "            n_ics=config['n_iter'],\n",
    "            input_range=config['input_range'],\n",
    "            device=config['device'],\n",
    "            horizon = config['horizon'],\n",
    "            history = config['history'],\n",
    "            stride=config.get('stride', 5),\n",
    "            predict_deriv=config.get(\"predict_deriv\", False),\n",
    "            snr_db=snr_db,\n",
    "            **config['integration_kwargs']\n",
    "        )\n",
    "    else:\n",
    "        dataset = RealEpidemics(\n",
    "            root = './data_real_epid_covid_orig',\n",
    "            name = 'RealEpid',\n",
    "            predict_deriv=True,\n",
    "            scale=False,\n",
    "        )\n",
    "    \n",
    "    raw_data = dataset.raw_data_sampled.cpu().detach().numpy() # shape: (ics, time_steps, n_nodes, 1)\n",
    "    time = dataset.t_sampled\n",
    "    \n",
    "    edge_index = dataset[0].edge_index\n",
    "    A = to_dense_adj(edge_index)[0].cpu().detach().numpy()\n",
    "    \n",
    "    return raw_data, A, time\n",
    "\n",
    "\n",
    "def get_matrix_tss(raw_data, time, A, Dim=1, selfPolyOrder = 3, act_index=False):\n",
    "    dt = time[0, 1] - time[0, 0]\n",
    "    dt = dt.item()\n",
    "    Nnodes = A.shape[0]\n",
    "    \n",
    "    data = []\n",
    "    num_deriv = []\n",
    "    Matrix = []\n",
    "    \n",
    "    for ic in range(raw_data.shape[0]):\n",
    "        data_ic = raw_data[ic].squeeze(-1)  # shape: (time_steps, n_nodes)\n",
    "        num_deriv_ic = NumericalDeriv(\n",
    "            TimeSeries=data_ic,\n",
    "            dim=1,\n",
    "            Nnodes=data_ic.shape[1],\n",
    "            deltT=dt\n",
    "        )   # pd DatafRame\n",
    "        \n",
    "        data_ic = data_ic[2:-2,:]\n",
    "        data.append(data_ic)\n",
    "        num_deriv.append(num_deriv_ic)\n",
    "        matrix_ic = ElementaryFunctions_Matrix(\n",
    "            data_ic, \n",
    "            Dim, \n",
    "            Nnodes, \n",
    "            A, \n",
    "            selfPolyOrder, \n",
    "            coupledPolyOrder = 1, \n",
    "            PolynomialIndex = True, \n",
    "            TrigonometricIndex = True, \n",
    "            ExponentialIndex = True, \n",
    "            FractionalIndex = False, \n",
    "            ActivationIndex = act_index, \n",
    "            RescalingIndex = False, \n",
    "            CoupledPolynomialIndex = True,\n",
    "            CoupledTrigonometricIndex = True, \n",
    "            CoupledExponentialIndex = True, \n",
    "            CoupledFractionalIndex = False,\n",
    "            CoupledActivationIndex = act_index, \n",
    "            CoupledRescalingIndex = False\n",
    "        )\n",
    "        \n",
    "        Matrix.append(matrix_ic)\n",
    "        \n",
    "\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    num_deriv = pd.concat(num_deriv, ignore_index=True)\n",
    "    Matrix = pd.concat(Matrix, ignore_index=True)\n",
    "    Matrix = Matrix.replace([np.inf, -np.inf], np.nan).dropna(axis=1)\n",
    "    \n",
    "    return Matrix, num_deriv, data\n",
    "\n",
    "\n",
    "def two_step_sindy(Matrix, num_deriv, Nnodes, out_path, Dim = 1, plotstart = 0.5, plotend = 0.9, Keep = 10, SampleTimes = 20, Batchsize = 1,\n",
    "                   snr_db = -1):\n",
    "    Lambda = pd.DataFrame([[0.01, 0.5, 1]])\n",
    "    os.makedirs(out_path, exist_ok=True)\n",
    "    \n",
    "    for dim in range(Dim):\n",
    "        InferredResults, _, _, _ = TwoPhaseInference(\n",
    "            Matrix, \n",
    "            num_deriv, \n",
    "            Nnodes, \n",
    "            dim, \n",
    "            Dim, \n",
    "            Keep, \n",
    "            SampleTimes,\n",
    "            Batchsize, \n",
    "            Lambda, \n",
    "            plotstart, \n",
    "            plotend\n",
    "        )\n",
    "        \n",
    "        save_file = f\"{out_path}/results_dim={dim}.csv\" if snr_db < 0 else f\"{out_path}/results_dim={dim}_{snr_db}_db.csv\"\n",
    "        InferredResults.to_csv(save_file)\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939af7de",
   "metadata": {},
   "source": [
    "## Two Phase Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56665128",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    'configs/config_pred_deriv/config_ic1/config_kuramoto.yml',\n",
    "    'configs/config_pred_deriv/config_ic1/config_biochemical.yml',\n",
    "    'configs/config_pred_deriv/config_ic1/config_epidemics.yml',\n",
    "    'configs/config_pred_deriv/config_ic1/config_population.yml'\n",
    "]\n",
    "\n",
    "for conf_path in configs:\n",
    "    conf= load_config(config_path=conf_path)\n",
    "    raw_data, A, time = load_data_tss(conf)\n",
    "    \n",
    "    Matrix, num_deriv, _ = get_matrix_tss(\n",
    "        raw_data=raw_data,\n",
    "        time = time,\n",
    "        A=A,\n",
    "        Dim=1,\n",
    "        selfPolyOrder=3\n",
    "    )\n",
    "    \n",
    "    two_step_sindy(\n",
    "        Matrix=Matrix,\n",
    "        num_deriv=num_deriv,\n",
    "        Nnodes=A.shape[0],\n",
    "        out_path=f'./saved_models_optuna/tss/{conf['name']}-{conf['n_iter']}_nofrac'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d13efe",
   "metadata": {},
   "source": [
    "### Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa69f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = [\n",
    "    'configs/config_pred_deriv/config_ic1/config_kuramoto.yml',\n",
    "    'configs/config_pred_deriv/config_ic1/config_biochemical.yml',\n",
    "    'configs/config_pred_deriv/config_ic1/config_epidemics.yml',\n",
    "    'configs/config_pred_deriv/config_ic1/config_population.yml'\n",
    "]\n",
    "\n",
    "snr_db_levels = [70, 50, 20]\n",
    "\n",
    "for conf_path in configs:\n",
    "    for snr_db in snr_db_levels:\n",
    "        \n",
    "        conf = load_config(config_path=conf_path)\n",
    "        raw_data, A, time = load_data_tss(conf, snr_db=snr_db)\n",
    "        \n",
    "        Matrix, num_deriv, _ = get_matrix_tss(\n",
    "            raw_data=raw_data,\n",
    "            time = time,\n",
    "            A=A,\n",
    "            Dim=1,\n",
    "            selfPolyOrder=3\n",
    "        )\n",
    "        \n",
    "        two_step_sindy(\n",
    "            Matrix=Matrix,\n",
    "            num_deriv=num_deriv,\n",
    "            Nnodes=A.shape[0],\n",
    "            out_path=f'./saved_models_optuna/tss/{conf['name']}-{conf['n_iter']}_nofrac',\n",
    "            snr_db=snr_db\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f079631",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30c1644a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.3504788815528931e-05\n",
      "Var Test loss of symbolic formula: 1.314533673970284e-13\n",
      "Std Test loss of symbolic formula: 3.625649836884809e-07\n",
      "Mean Test loss of symbolic formula: 1.071706852447581e-06\n",
      "Var Test loss of symbolic formula: 8.008373820613663e-14\n",
      "Std Test loss of symbolic formula: 2.829907033917133e-07\n",
      "Mean Test loss of symbolic formula: 3.735399635237021e-06\n",
      "Var Test loss of symbolic formula: 4.746857081617248e-13\n",
      "Std Test loss of symbolic formula: 6.889743886108719e-07\n",
      "Mean Test loss of symbolic formula: 1.2006473374034006e-06\n",
      "Var Test loss of symbolic formula: 7.184599599254429e-14\n",
      "Std Test loss of symbolic formula: 2.6804103415810103e-07\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "from post_processing import set_pytorch_seed, get_test_set, get_symb_test_error\n",
    "from utils.utils import load_config\n",
    "import torch\n",
    "\n",
    "\n",
    "set_pytorch_seed(0)\n",
    "\n",
    "kur_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_kuramoto.yml\")\n",
    "\n",
    "KUR = get_test_set(\n",
    "    dynamics=kur_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=kur_config['input_range'],\n",
    "    **kur_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: torch.sin(x[:, 1] - x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: 2.0 + 0.5 * x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=KUR,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n",
    "\"\"\"### Epidemics\"\"\"\n",
    "\n",
    "epid_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_epidemics.yml\")\n",
    "\n",
    "EPID = get_test_set(\n",
    "    dynamics=epid_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=epid_config['input_range'],\n",
    "    **epid_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.5*x[:, 1].unsqueeze(-1) * (1 - x[:, 0].unsqueeze(-1))\n",
    "h_symb = lambda x: x[:, 1].unsqueeze(1) - 0.5 * x[:, 0].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=EPID,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n",
    "\"\"\"### Population\"\"\"\n",
    "\n",
    "pop_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "\n",
    "POP = get_test_set(\n",
    "    dynamics=pop_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=pop_config['input_range'],\n",
    "    **pop_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.2*torch.pow(x[:, 1].unsqueeze(-1), 3)\n",
    "h_symb = lambda x: -0.5 * x[:, 0].unsqueeze(-1) + x[:, 1].unsqueeze(1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=POP,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n",
    "\"\"\"### Biochemical\"\"\"\n",
    "\n",
    "bio_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical.yml\")\n",
    "\n",
    "BIO = get_test_set(\n",
    "    dynamics=bio_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=bio_config['input_range'],\n",
    "    **bio_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: (-0.5*x[:, 1] * x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: (1.0 - 0.5 * x[:, 0]).unsqueeze(-1)  + x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=BIO,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd3d9e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import json\n",
    "\n",
    "\n",
    "def get_tss_test_error(\n",
    "    text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h,\n",
    "    row_means,\n",
    "    test_set,\n",
    "    result_dict,\n",
    "    suffix = '',\n",
    "    method = \"dopri5\"\n",
    "):\n",
    "    g_symb = sp.S(0)\n",
    "    h_symb = sp.S(0)\n",
    "\n",
    "    \n",
    "    for symb_g in text_sympy_mapping_g.keys():\n",
    "        g_symb += row_means[symb_g] * text_sympy_mapping_g[symb_g]\n",
    "    for symb_h in text_sympy_mapping_h.keys():\n",
    "        h_symb += row_means[symb_h] * text_sympy_mapping_h[symb_h]\n",
    "\n",
    "\n",
    "    try:\n",
    "        test_losses = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=test_set,\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=1e-5,\n",
    "            rtol=1e-5,\n",
    "            is_symb=True\n",
    "        )\n",
    "\n",
    "        ts_mean = np.mean(test_losses)\n",
    "        ts_var = np.var(test_losses)\n",
    "        ts_std = np.std(test_losses)\n",
    "\n",
    "        print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "        print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "        print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "        \n",
    "        result_dict[f'tss_test_mae_{suffix}'] = ts_mean\n",
    "        result_dict[f'tss_test_var_{suffix}'] = ts_var\n",
    "        result_dict[f'tss_test_std_{suffix}'] = ts_std\n",
    "        \n",
    "    except AssertionError:\n",
    "        print(\"Evaluation failed !\")\n",
    "        result_dict[f'error_{suffix}'] = 'Evaluation failed !'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0ffd81",
   "metadata": {},
   "source": [
    "### KUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3ca037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.499495\n",
       "constant          2.000012\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7efa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.00029117241501808167\n",
      "Var Test loss of symbolic formula: 4.4434753406930564e-10\n",
      "Std Test loss of symbolic formula: 2.1079552511125697e-05\n"
     ]
    }
   ],
   "source": [
    "results_kur = {}\n",
    "\n",
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1aef6b",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d292c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.496489\n",
       "constant          2.000509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7074e512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0021191818717246256\n",
      "Var Test loss of symbolic formula: 2.269309859505237e-08\n",
      "Std Test loss of symbolic formula: 0.00015064228687540682\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a6bde",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2670a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.531575\n",
       "fracx1            7.369008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc88d1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.558358391125997\n",
      "Var Test loss of symbolic formula: 0.0024888551943536502\n",
      "Std Test loss of symbolic formula: 0.049888427459217934\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"fracx1\": 1/ x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00179cdd",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "165edd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "fracx1jMinusx1i   -0.004194\n",
       "x1ifracx1j         0.087818\n",
       "x1iexpx1j          0.000292\n",
       "fracx1ix1j        -0.000736\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84adce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: nan\n",
      "Var Test loss of symbolic formula: nan\n",
      "Std Test loss of symbolic formula: nan\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1iexpx1j\": x_i * sp.exp(x_j),\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i),\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43222550",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Kuramoto-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_kur, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b07014c",
   "metadata": {},
   "source": [
    "### EPID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3b999cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "constant         -0.567966\n",
       "expx1jMinusx1i    0.208438\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "results_epid = {}\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5929d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.1941202183564504\n",
      "Var Test loss of symbolic formula: 0.0005310114619173017\n",
      "Std Test loss of symbolic formula: 0.023043685944685623\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eae4a4",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5978c9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.256831\n",
       "constant          0.569542\n",
       "expx1jMinusx1i    0.013251\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "523be7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.053738709539175034\n",
      "Var Test loss of symbolic formula: 5.180841923608607e-05\n",
      "Std Test loss of symbolic formula: 0.007197806557284384\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i,\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a6c8f",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2d2d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.091028\n",
       "expx1jMinusx1i    0.111314\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "859291d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.016693448647856712\n",
      "Var Test loss of symbolic formula: 8.436841921384436e-06\n",
      "Std Test loss of symbolic formula: 0.002904624230668132\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14e251",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc771a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1ifracx1j        -0.019999\n",
       "fracx1ix1j         0.014712\n",
       "fracx1jMinusx1i    0.000244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ffd112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.08860065788030624\n",
      "Var Test loss of symbolic formula: 4.077819097984363e-06\n",
      "Std Test loss of symbolic formula: 0.002019361061817416\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "947b393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Epidemics-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_epid, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6967546",
   "metadata": {},
   "source": [
    "### BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bd02524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.711350\n",
       "constant    0.867073\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83d394ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.036044025172789894\n",
      "Var Test loss of symbolic formula: 1.2206604668749429e-06\n",
      "Std Test loss of symbolic formula: 0.0011048350405716424\n"
     ]
    }
   ],
   "source": [
    "results_bio = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b134b234",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cee3b347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.740610\n",
       "constant    0.905639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65d53094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03708266963561376\n",
      "Var Test loss of symbolic formula: 2.1507763171681031e-07\n",
      "Std Test loss of symbolic formula: 0.00046376462965259685\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5051ca17",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b22deb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "x1ix1j    1.077840\n",
       "x1x1     -2.325285\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66f6f5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: nan\n",
      "Var Test loss of symbolic formula: nan\n",
      "Std Test loss of symbolic formula: nan\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='50db',\n",
    "    method=\"euler\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eaf2d8",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6726b8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1ifracx1j         0.011954\n",
       "fracx1ix1j         0.003264\n",
       "fracx1jMinusx1i    0.000703\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49da7d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation failed !\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e9b9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Biochemical-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_bio, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5bb772",
   "metadata": {},
   "source": [
    "### POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2fb328f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.016272\n",
       "x1j         0.040017\n",
       "sinx1j      0.003158\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a532fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0990138625105222\n",
      "Var Test loss of symbolic formula: 1.0323049151655323e-05\n",
      "Std Test loss of symbolic formula: 0.0032129502255178687\n"
     ]
    }
   ],
   "source": [
    "results_pop = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402522c8",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77005796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.000443\n",
       "x1j         0.023472\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bb51202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.09954124689102173\n",
      "Var Test loss of symbolic formula: 5.92840036887458e-06\n",
      "Std Test loss of symbolic formula: 0.0024348306653388815\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0eb289",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6767fbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "sinx1j   -1.508801\n",
       "x1j       1.489724\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7abd2e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.11308030039072037\n",
      "Var Test loss of symbolic formula: 1.7624745905830963e-05\n",
      "Std Test loss of symbolic formula: 0.00419818364365245\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638fb582",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1453afa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN      0.000000\n",
       "x1x1     0.028332\n",
       "sinx1   -0.482987\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94b50095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03507093029717604\n",
      "Var Test loss of symbolic formula: 1.4470365959317085e-05\n",
      "Std Test loss of symbolic formula: 0.0038039934226174847\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"sinx1\": sp.sin(x_i),\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bc226a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Population-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_pop, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c796e91",
   "metadata": {},
   "source": [
    "## Re-fitting coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "17022c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sympy as sp\n",
    "from post_processing import make_callable, get_model, set_pytorch_seed\n",
    "import numpy as np\n",
    "\n",
    "set_pytorch_seed(0)\n",
    "\n",
    "def build_symb_model_tss():\n",
    "    x_i, x_j = sp.symbols('x_i x_j')    \n",
    "\n",
    "    g_symb = (1 / (1 + sp.exp(- (x_j - x_i))))\n",
    "    h_symb = x_i\n",
    "    \n",
    "    g_symb = make_callable(g_symb)\n",
    "    h_symb = make_callable(h_symb)\n",
    "\n",
    "    symb_model = get_model(\n",
    "        g = g_symb,\n",
    "        h = h_symb,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        integration_method='rk4'\n",
    "    )\n",
    "    symb_model.predict_deriv = True\n",
    "    return symb_model\n",
    "\n",
    "\n",
    "def get_dxdt_pred(data, symb_model, device='cpu'):\n",
    "    self_int = []\n",
    "    pair_int = []\n",
    "    for snapshot in data:\n",
    "        snapshot = snapshot.to(device)\n",
    "        _ = symb_model(snapshot)\n",
    "        self_int.append(symb_model.conv.model.h_out)    # h_out shape = g_out shape = (N, 1)\n",
    "        pair_int.append(symb_model.conv.model.g_out)\n",
    "    \n",
    "    self_int = torch.stack(self_int, dim=1)\n",
    "    pair_int = torch.stack(pair_int, dim=1)\n",
    "    \n",
    "    return self_int.cpu().detach().numpy().flatten(), pair_int.cpu().detach().numpy().flatten()\n",
    "\n",
    "\n",
    "def sum_over_dxdt(self_int, pair_int, n_nodes, T):\n",
    "    lib_new = []\n",
    "\n",
    "    for i in range(n_nodes):\n",
    "        for t in range(T):\n",
    "            start = i * T\n",
    "            end = start + t + 1  # Python slice is exclusive at end\n",
    "            val1 = np.sum(self_int[start:end])\n",
    "            val2 = np.sum(pair_int[start:end])  # index 35 in MATLAB = 34 in Python\n",
    "            lib_new.append([val1, val2])\n",
    "\n",
    "    lib_new = np.array(lib_new)\n",
    "    return lib_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c618976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "coeffs_path = \"./inferred_coeffs/tpsindy\"\n",
    "os.makedirs(coeffs_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd3027",
   "metadata": {},
   "source": [
    "### COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7309215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.RealEpidemics import RealEpidemics\n",
    "\n",
    "\n",
    "data_real_epid_orig = RealEpidemics(\n",
    "    root = './data_real_epid_covid_orig',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=True,\n",
    "    scale=False,\n",
    ")\n",
    "\n",
    "symb_model_tss = build_symb_model_tss()\n",
    "\n",
    "self_int, pair_int = get_dxdt_pred(\n",
    "    data=data_real_epid_orig,\n",
    "    symb_model=symb_model_tss,\n",
    "    device=data_real_epid_orig.device\n",
    ")\n",
    "\n",
    "lib = sum_over_dxdt(\n",
    "    self_int=self_int,\n",
    "    pair_int=pair_int,\n",
    "    n_nodes=data_real_epid_orig[0].x.shape[0],\n",
    "    T=len(data_real_epid_orig)\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "lib_df = pd.DataFrame(lib, columns=['x', 'sigxjminusxi'])\n",
    "lib_df.to_csv(f'{coeffs_path}/lib_new_covid.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72f2118",
   "metadata": {},
   "source": [
    "### H1N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd0240ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real_epid_orig_h1n1 = RealEpidemics(\n",
    "    root = './data_real_epid_h1n1_orig',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=True,\n",
    "    scale=False,\n",
    "    infection_data=\"./data/RealEpidemics/infected_numbers_H1N1.csv\",\n",
    "    inf_threshold=100\n",
    ")\n",
    "\n",
    "symb_model_tss = build_symb_model_tss()\n",
    "\n",
    "self_int, pair_int = get_dxdt_pred(\n",
    "    data=data_real_epid_orig_h1n1,\n",
    "    symb_model=symb_model_tss,\n",
    "    device=data_real_epid_orig_h1n1.device\n",
    ")\n",
    "\n",
    "lib = sum_over_dxdt(\n",
    "    self_int=self_int,\n",
    "    pair_int=pair_int,\n",
    "    n_nodes=data_real_epid_orig_h1n1[0].x.shape[0],\n",
    "    T=len(data_real_epid_orig_h1n1)\n",
    ")\n",
    "\n",
    "lib_df = pd.DataFrame(lib, columns=['x', 'sigxjminusxi'])\n",
    "lib_df.to_csv(f'{coeffs_path}/lib_new_h1n1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea03b6bf",
   "metadata": {},
   "source": [
    "### SARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bda44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.RealEpidemics import RealEpidemics\n",
    "import pandas as pd\n",
    "\n",
    "data_real_epid_orig_sars = RealEpidemics(\n",
    "    root = './data_real_epid_sars_orig',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=True,\n",
    "    scale=False,\n",
    "    infection_data=\"./data/RealEpidemics/infected_numbers_sars.csv\",\n",
    "    inf_threshold=100\n",
    ")\n",
    "\n",
    "symb_model_tss = build_symb_model_tss()\n",
    "\n",
    "self_int, pair_int = get_dxdt_pred(\n",
    "    data=data_real_epid_orig_sars,\n",
    "    symb_model=symb_model_tss,\n",
    "    device=data_real_epid_orig_sars.device\n",
    ")\n",
    "\n",
    "lib = sum_over_dxdt(\n",
    "    self_int=self_int,\n",
    "    pair_int=pair_int,\n",
    "    n_nodes=data_real_epid_orig_sars[0].x.shape[0],\n",
    "    T=len(data_real_epid_orig_sars)\n",
    ")\n",
    "\n",
    "lib_df = pd.DataFrame(lib, columns=['x', 'sigxjminusxi'])\n",
    "lib_df.to_csv(f'{coeffs_path}/lib_new_sars.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35feb37",
   "metadata": {},
   "source": [
    "### Fair fitting of coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3275e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "righ_sides = [\n",
    "    f\"{coeffs_path}/lib_new_covid.csv\",\n",
    "    f\"{coeffs_path}/lib_new_h1n1.csv\",\n",
    "    f\"{coeffs_path}/lib_new_sars.csv\"\n",
    "]\n",
    "\n",
    "lef_sides = [\n",
    "    \"./inferred_coeffs/tpsindy/left_side_components_covid.csv\",\n",
    "    \"./inferred_coeffs/tpsindy/left_side_components_H1N1.csv\",\n",
    "    \"./inferred_coeffs/tpsindy/left_side_components_Sars.csv\"\n",
    "]\n",
    "\n",
    "n_nodes = [82, 21, 4]\n",
    "names = ['covid', 'h1n1', 'sars']\n",
    "\n",
    "\n",
    "for j, (rs, ls) in enumerate(zip(righ_sides, lef_sides)):\n",
    "    X_all = pd.read_csv(rs)\n",
    "    y_all = pd.read_csv(ls)\n",
    "    N = n_nodes[j]\n",
    "    X_mat = X_all.values\n",
    "    y_mat = y_all.values\n",
    "    num = len(X_mat[0])\n",
    "    num2 = len(y_mat[0])\n",
    "    L = int(len(X_mat)/N)\n",
    "    times = N\n",
    "    Coef = np.zeros(shape=(2,times))\n",
    "    for i in range(0,times):\n",
    "        X = X_all.iloc[i*L:(i+1)*L,:]\n",
    "        y = y_all.iloc[i*L:(i+1)*L,:]\n",
    "        \n",
    "        cutoff = int(0.9 * len(X))\n",
    "        X = X.iloc[:cutoff, :]\n",
    "        y = y.iloc[:cutoff, :]\n",
    "        \n",
    "        v1 = X['x']\n",
    "        v2 = X['sigxjminusxi']\n",
    "        y1 = y['X']\n",
    "        Xin = pd.concat([v1,v2],axis=1)\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(Xin,y1)\n",
    "        a = model.coef_\n",
    "        a = (pd.DataFrame(a)).values\n",
    "        Coef[0,i] = a[0]\n",
    "        Coef[1,i] = a[1]\n",
    "        \n",
    "    Coef = pd.DataFrame(Coef)\n",
    "    # print(Coef)\n",
    "    Coef.to_csv(f\"{coeffs_path}/inf_coeffs_test_{names[j]}.csv\", index=0)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
