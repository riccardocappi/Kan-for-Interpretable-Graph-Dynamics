{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics\n",
    "\n",
    "Dynamics | $\\partial_{\\tau}x_i=$ |\n",
    "| :--------: | :-------: |\n",
    "Biochemical | $F -B x_i - R \\sum_j A_{ij} x_i x_j$ |\n",
    "Epidemics | $-B x_i + R \\sum_j A_{ij} (1-x_i)x_j$ |\n",
    "Population | $-B x_i^{b} + R \\sum_j A_{ij} x_j^a$ |\n",
    "Synchronization | $\\omega_i + R \\sum_j A_{ij} \\sin(x_j-x_i)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from experiments.experiments_gkan import ExperimentsGKAN\n",
    "from experiments.experiments_mpnn import ExperimentsMPNN\n",
    "from experiments.experiments_llc import ExperimentsLLC\n",
    "from train_and_eval import eval_model\n",
    "import sympytorch\n",
    "\n",
    "storage = JournalStorage(JournalFileBackend(\"optuna_journal_storage.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "def set_pytorch_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "set_pytorch_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_real_epid_mpnn.yml\")\n",
    "# config['patience'] = 450\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config,\n",
    "#     n_trials=3,\n",
    "#     study_name=\"test_mult_2\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "# # # config['t_span'] = [0, 1]\n",
    "# exp = ExperimentsGKAN(\n",
    "#     config=config,\n",
    "#     n_trials=1,\n",
    "#     study_name=\"test_mult_11\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 13:05:55,302] A new study created in Journal with name: model-population-gkan-test_mult_11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: num params: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 13:20:07,691] Trial 0 finished with value: 9.843736188486218e-05 and parameters: {'lr': 0.0028057582076672534, 'lamb': 1.0, 'batch_size': 16, 'use_orig_reg': True, 'lamb_g_net': 8.63200816860254e-06, 'lamb_h_net': 8.629132190071855e-06, 'grid_size_g_net': 5, 'spline_order_g_net': 3, 'range_limit_g_net': 7, 'mu_1_g_net': 0.8, 'mu_2_g_net': 0.1, 'hidden_dim_g_net': 6, 'grid_size_h_net': 18, 'spline_order_h_net': 1, 'range_limit_h_net': 2, 'mu_1_h_net': 0.2, 'mu_2_h_net': 0.4, 'hidden_dim_h_net': 4}. Best is trial 0 with value: 9.843736188486218e-05.\n"
     ]
    }
   ],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f13f1319940>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 30, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_pop = load_config(\"./configs/config_pred_deriv/config_ic1/config_population_mpnn.yml\")\n",
    "# # config_pop[\"t_eval_steps\"] = 1000\n",
    "# # config_pop[\"t_span\"] = [0, 10]\n",
    "\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config_pop,\n",
    "#     n_trials=1,\n",
    "#     study_name='test_mult_3'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 6, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set.raw_data_sampled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:06,795] A new study created in Journal with name: model-biochemical-llc-test_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: num params: 4644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:18,168] Trial 0 finished with value: 0.009816302917897701 and parameters: {'lr': 0.0028057582076672534, 'lamb': 0.009600000000000001, 'batch_size': 16, 'n_hidden_layers_g0': 1, 'hidden_dims_g0': 8, 'af_g0': 'relu', 'drop_p_g0': 0.00011916299962955152, 'n_hidden_layers_g1': 2, 'hidden_dims_g1': 56, 'af_g1': 'relu', 'drop_p_g1': 0.00133469775741781, 'n_hidden_layers_g2': 2, 'hidden_dims_g2': 32, 'af_g2': 'softplus', 'drop_p_g2': 0.0012040216379191721, 'n_hidden_layers_h_net': 1, 'hidden_dims_h_net': 32, 'af_h_net': 'relu', 'drop_p_h_net': 0.015535445807588463}. Best is trial 0 with value: 0.009816302917897701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1: num params: 7988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:22,121] Trial 1 finished with value: 0.037803955376148224 and parameters: {'lr': 0.0006192568649430464, 'lamb': 0.0061, 'batch_size': 64, 'n_hidden_layers_g0': 2, 'hidden_dims_g0': 56, 'af_g0': 'tanh', 'drop_p_g0': 0.00424727979536972, 'n_hidden_layers_g1': 1, 'hidden_dims_g1': 32, 'af_g1': 'softplus', 'drop_p_g1': 0.028226046783939623, 'n_hidden_layers_g2': 1, 'hidden_dims_g2': 40, 'af_g2': 'tanh', 'drop_p_g2': 0.0736534446668837, 'n_hidden_layers_h_net': 2, 'hidden_dims_h_net': 64, 'af_h_net': 'softplus', 'drop_p_h_net': 0.0005308046630775948}. Best is trial 0 with value: 0.009816302917897701.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2: num params: 7492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-26 00:04:26,278] Trial 2 finished with value: 0.03039173036813736 and parameters: {'lr': 0.0006157785861833009, 'lamb': 0.0032, 'batch_size': 64, 'n_hidden_layers_g0': 1, 'hidden_dims_g0': 24, 'af_g0': 'tanh', 'drop_p_g0': 0.00018869508789698286, 'n_hidden_layers_g1': 2, 'hidden_dims_g1': 56, 'af_g1': 'tanh', 'drop_p_g1': 0.04117599592262882, 'n_hidden_layers_g2': 2, 'hidden_dims_g2': 56, 'af_g2': 'softplus', 'drop_p_g2': 0.15580940996926476, 'n_hidden_layers_h_net': 2, 'hidden_dims_h_net': 24, 'af_h_net': 'tanh', 'drop_p_h_net': 0.04997943803580264}. Best is trial 0 with value: 0.009816302917897701.\n"
     ]
    }
   ],
   "source": [
    "config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical_llc.yml\")\n",
    "\n",
    "exp = ExperimentsLLC(\n",
    "    config=config,\n",
    "    n_trials=3,\n",
    "    study_name=\"test_3\",\n",
    "    process_id=0\n",
    ")\n",
    "\n",
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.MPNN import MPNN\n",
    "from models.baseline.MPNN_ODE import MPNN_ODE\n",
    "from train_and_eval import eval_model\n",
    "from datasets.SyntheticData import SyntheticData\n",
    "from sympy import symbols, sin, summation, simplify\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from utils.utils import integrate\n",
    "from torch_geometric.data import Data\n",
    "from models.kan.KAN import KAN\n",
    "from models.GKAN_ODE import GKAN_ODE\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sympy import latex\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_model(g, h, message_passing=True, include_time=False, atol=1e-5, rtol=1e-5, integration_method = 'scipy_solver',\n",
    "              eval=True, options = {}, all_t = False):\n",
    "    conv = MPNN(\n",
    "        g_net = g,\n",
    "        h_net = h,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "\n",
    "    symb = MPNN_ODE(\n",
    "        conv=conv,\n",
    "        model_path=\"./saved_models_optuna/tmp_symb\",\n",
    "        adjoint=True,\n",
    "        integration_method=integration_method,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        options = options,\n",
    "        all_t=all_t\n",
    "    )\n",
    "\n",
    "    if eval:\n",
    "        symb = symb.eval()\n",
    "    return symb\n",
    "\n",
    "\n",
    "def make_callable(expr):\n",
    "    free_syms = expr.free_symbols\n",
    "    if not free_syms:\n",
    "        # Expression is constant\n",
    "        const_value = float(expr)\n",
    "        return lambda x: torch.full((x.shape[0], 1), const_value, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    sym_module = sympytorch.SymPyModule(expressions=[expr])\n",
    "    syms = {str(s) for s in free_syms}\n",
    "    if {'x_i', 'x_j'} <= syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0], x_j=x[:, 1])\n",
    "    elif 'x_i' in syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0])\n",
    "    elif 'x_j' in syms:\n",
    "        return lambda x: sym_module(x_j=x[:, 1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected symbols in expression: {free_syms}\")\n",
    "\n",
    "\n",
    "def get_symb_test_error(g_symb, h_symb, test_set, message_passing=False, include_time=False, atol=1e-5, rtol=1e-5, scaler = None, inverse_scale=False, method='scipy_solver',\n",
    "                        is_symb = True):\n",
    "\n",
    "    if is_symb:\n",
    "        if isinstance(g_symb, int):\n",
    "            g_symb = sp.sympify(g_symb)\n",
    "\n",
    "        if isinstance(h_symb, int):\n",
    "            h_symb = sp.sympify(h_symb)\n",
    "\n",
    "        g_symb = make_callable(g_symb)\n",
    "        h_symb = make_callable(h_symb)\n",
    "\n",
    "    test_losses = []\n",
    "\n",
    "    for ts in test_set:\n",
    "        symb = get_model(\n",
    "            g=g_symb,\n",
    "            h=h_symb,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            integration_method=method\n",
    "        )\n",
    "\n",
    "        collate_fn = lambda samples_list: samples_list\n",
    "        test_loader = DataLoader(ts, batch_size=len(ts), shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "        test_loss = eval_model(\n",
    "            model=symb,\n",
    "            valid_loader=test_loader,\n",
    "            criterion=torch.nn.L1Loss(),\n",
    "            scaler=scaler,\n",
    "            inverse_scale=inverse_scale,\n",
    "            pred_deriv=False\n",
    "        )\n",
    "\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "\n",
    "def get_test_set(dynamics, device='cuda', input_range=(0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    seeds = [12345, 67890, 111213]\n",
    "\n",
    "    graphs = [\n",
    "        nx.barabasi_albert_graph(70, 3, seed=seeds[0]),\n",
    "        nx.watts_strogatz_graph(50, 6, 0.3, seed=seeds[1]),\n",
    "        nx.erdos_renyi_graph(100, 0.05, seed=seeds[2])\n",
    "    ]\n",
    "\n",
    "    test_set = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        snapshots = integrate_test_set(\n",
    "            graph=graph,\n",
    "            dynamics=dynamics,\n",
    "            seed=seeds[i],\n",
    "            device=device,\n",
    "            input_range=input_range,\n",
    "            t_span=t_span,\n",
    "            **integration_kwargs\n",
    "        )\n",
    "        test_set.append(snapshots)\n",
    "\n",
    "    return test_set\n",
    "\n",
    "\n",
    "\n",
    "def integrate_test_set(graph, dynamics, seed=12345, device='cuda', input_range = (0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    # graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "    edge_index = from_networkx(graph).edge_index\n",
    "    edge_index = edge_index.to(torch.device(device))\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    data, t = integrate(\n",
    "        input_range=input_range,\n",
    "        t_span = t_span,\n",
    "        t_eval_steps=1000,\n",
    "        dynamics=dynamics,\n",
    "        device=device,\n",
    "        graph=graph,\n",
    "        rng = rng,\n",
    "        **integration_kwargs\n",
    "    )\n",
    "\n",
    "    snapshot = Data(\n",
    "        x = data[0].unsqueeze(0),\n",
    "        y = data[1:],\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=None,\n",
    "        t_span = t\n",
    "    )\n",
    "\n",
    "    return [snapshot]\n",
    "\n",
    "\n",
    "def build_model_from_file(model_path, message_passing, include_time, method='dopri5', adjoint=False, atol=1e-5, rtol=1e-5,\n",
    "                          compute_mult=True):\n",
    "    best_params_file = f\"{model_path}/best_params.json\"\n",
    "    best_state_path = f\"{model_path}/gkan/state_dict.pth\"\n",
    "\n",
    "    with open(best_params_file, 'r') as f:\n",
    "        best_hyperparams = json.load(f)\n",
    "\n",
    "    # g_net\n",
    "    g_net = KAN(\n",
    "        layers_hidden=[2, best_hyperparams['hidden_dim_g_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_g_net'],\n",
    "        spline_order=best_hyperparams['spline_order_g_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_g_net'], best_hyperparams['range_limit_g_net']],\n",
    "        mu_1=best_hyperparams['mu_1_g_net'],\n",
    "        mu_2=best_hyperparams['mu_2_g_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=compute_mult,\n",
    "        store_act=True\n",
    "    )\n",
    "\n",
    "    time_dim = 1 if include_time else 0\n",
    "    in_dim_h = 2 if message_passing else 1\n",
    "    in_dim_h += time_dim\n",
    "\n",
    "    # h_net\n",
    "    h_net = KAN(\n",
    "        layers_hidden=[in_dim_h, best_hyperparams['hidden_dim_h_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_h_net'],\n",
    "        spline_order=best_hyperparams['spline_order_h_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_h_net'], best_hyperparams['range_limit_h_net']],\n",
    "        mu_1=best_hyperparams['mu_1_h_net'],\n",
    "        mu_2=best_hyperparams['mu_2_h_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=True,\n",
    "        store_act=True\n",
    "    )\n",
    "\n",
    "    gkan = MPNN(\n",
    "        h_net=h_net,\n",
    "        g_net=g_net,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "\n",
    "    model = GKAN_ODE(\n",
    "        conv=gkan,\n",
    "        model_path='./saved_models_optuna/tmp',\n",
    "        lmbd_g=best_hyperparams['lamb_g_net'],\n",
    "        lmbd_h=best_hyperparams['lamb_h_net'],\n",
    "        integration_method=method,\n",
    "        adjoint=adjoint,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    model.load_state_dict(torch.load(best_state_path, weights_only=False, map_location=torch.device('cuda')))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid_symb_model(\n",
    "    config,\n",
    "    model_path_gkan,\n",
    "    device='cuda',\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    black_box_fitting=True,\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    grid_orig = None\n",
    "):\n",
    "    \n",
    "    seed = 9999\n",
    "    graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "\n",
    "    # Prepare validation/test set\n",
    "    valid_set = integrate_test_set(\n",
    "        graph=graph,\n",
    "        dynamics=config['name'],\n",
    "        seed=seed,\n",
    "        device=device,\n",
    "        input_range=config['input_range'],\n",
    "        t_span=(0, 1),\n",
    "        **config['integration_kwargs']\n",
    "    )\n",
    "\n",
    "    # Helper to compute validation loss\n",
    "    def evaluate_model(g_symb, h_symb, is_symb=True):\n",
    "        errs = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=[valid_set],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            is_symb=is_symb\n",
    "        )\n",
    "        return errs[0]\n",
    "\n",
    "    # Helper to fit model for current config\n",
    "    def fit_single_model(param1, param2, param3=None, is_orig=False):\n",
    "        if black_box_fitting:\n",
    "            print(f\"Fitting black-box model with {param1} and {param2} iterations\")\n",
    "            pysr_model = lambda: get_pysr_model(\n",
    "                model_selection=param1, \n",
    "                n_iterations=param2,\n",
    "                # parallelism=\"serial\",\n",
    "                # random_state = seed,\n",
    "                # deterministic = True\n",
    "            )\n",
    "            _, g_symb, h_symb, _ = fit_black_box_from_kan(\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                device=device,\n",
    "                model_path=model_path_gkan,\n",
    "                pysr_model=pysr_model,\n",
    "                sample_size=sample_size,\n",
    "                theta=-np.inf,\n",
    "                message_passing=False,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            \n",
    "            if not is_orig:\n",
    "                print(f\"Fitting symbolic model with {param1}, theta {param2} and cutting threshold {param3}\")\n",
    "                _, g_symb, h_symb, _ = fit_model(\n",
    "                    n_g_hidden_layers=n_g_hidden_layers,\n",
    "                    n_h_hidden_layers=n_h_hidden_layers,\n",
    "                    model_path=model_path_gkan,\n",
    "                    theta=param2,\n",
    "                    message_passing=False,\n",
    "                    include_time=False,\n",
    "                    sample_size=sample_size,\n",
    "                    sort_by=param1,\n",
    "                    verbose=False,\n",
    "                    cut_threshold=param3\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Fitting symbolic model with {param1}, theta {param2} and ws {param3}\")\n",
    "                _, g_symb, h_symb, _ = fit_model(\n",
    "                    n_g_hidden_layers=n_g_hidden_layers,\n",
    "                    n_h_hidden_layers=n_h_hidden_layers,\n",
    "                    model_path=model_path_gkan,\n",
    "                    theta=param2,\n",
    "                    message_passing=False,\n",
    "                    include_time=False,\n",
    "                    sample_size=sample_size,\n",
    "                    verbose=False,\n",
    "                    fit_orig=True,\n",
    "                    a_range = param1,\n",
    "                    b_range = param1,\n",
    "                    weight_simple = param3\n",
    "                )\n",
    "        return g_symb, h_symb\n",
    "\n",
    "    if black_box_fitting:\n",
    "        param_grid = ([\"score\", \"accuracy\"], [50, 100, 200])\n",
    "        search_space = [(mod, val) for mod in param_grid[0] for val in param_grid[1]]\n",
    "    else:\n",
    "        if grid_orig == None:\n",
    "            param_grid = (\n",
    "                [\"score\", \"log_loss\"],       \n",
    "                [0.01, 0.05, 0.1],           \n",
    "                [0.1, 0.01, 0.001]    \n",
    "            )\n",
    "        else:\n",
    "            param_grid = grid_orig\n",
    "            \n",
    "            \n",
    "        search_space = list(itertools.product(*param_grid))\n",
    "\n",
    "    valid_losses = []\n",
    "\n",
    "    for params in search_space:\n",
    "        g_symb, h_symb = fit_single_model(*params, grid_orig != None)\n",
    "        try:\n",
    "            loss = evaluate_model(g_symb, h_symb)\n",
    "        except AssertionError:\n",
    "            loss = 1e8\n",
    "        if black_box_fitting:\n",
    "            valid_losses.append({'model_selection': params[0], 'param': params[1], 'valid_loss': loss})\n",
    "        elif grid_orig == None:\n",
    "            valid_losses.append({'sort_by': params[0], 'theta': params[1], 'cut_threshold': params[2], 'valid_loss': loss})\n",
    "        else:\n",
    "            valid_losses.append({'grid_range': params[0], 'theta': params[1], \"ws\":params[2], 'valid_loss': loss})\n",
    "\n",
    "    # Select best performing configuration\n",
    "    best = min(valid_losses, key=lambda x: x['valid_loss'])\n",
    "\n",
    "    # Final refit with best config\n",
    "    print(f\"Refitting best model with {best}\")\n",
    "    if black_box_fitting:\n",
    "        gkan_symb, symb_g, symb_h, exec_time = fit_black_box_from_kan(\n",
    "            model_path=model_path_gkan,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            device=device,\n",
    "            theta=-np.inf,\n",
    "            pysr_model=lambda: get_pysr_model(\n",
    "                model_selection=best['model_selection'],\n",
    "                n_iterations=best['param'],\n",
    "                # parallelism=\"serial\",\n",
    "                # random_state = seed,\n",
    "                # deterministic = True\n",
    "            ),\n",
    "            sample_size=sample_size,\n",
    "            message_passing=False,\n",
    "            verbose=True,\n",
    "            include_time=False\n",
    "        )\n",
    "    else:\n",
    "        if grid_orig == None:\n",
    "            gkan_symb, symb_g, symb_h, exec_time = fit_model(\n",
    "                model_path=model_path_gkan,\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                theta=best['theta'],\n",
    "                message_passing=False,\n",
    "                include_time=False,\n",
    "                sample_size=sample_size,\n",
    "                sort_by=best['sort_by'],\n",
    "                verbose=True,\n",
    "                cut_threshold=best[\"cut_threshold\"]\n",
    "            )\n",
    "        else:\n",
    "            gkan_symb, symb_g, symb_h, exec_time = fit_model(\n",
    "                model_path=model_path_gkan,\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                theta=best['theta'],\n",
    "                message_passing=False,\n",
    "                include_time=False,\n",
    "                sample_size=sample_size,\n",
    "                verbose=True,\n",
    "                fit_orig=True,\n",
    "                a_range = best['grid_range'],\n",
    "                b_range = best['grid_range'],\n",
    "                weight_simple = best['ws']\n",
    "            )\n",
    "\n",
    "    return gkan_symb, symb_g, symb_h, exec_time\n",
    "\n",
    "def post_process_gkan(\n",
    "    config,\n",
    "    model_path,\n",
    "    test_set,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    scaler=None,\n",
    "    inverse_scale=False,\n",
    "    adjoint=True,\n",
    "    eval_model=True,\n",
    "    res_file_name = 'post_process_res.json',\n",
    "    compute_mult = True,\n",
    "    grid_orig = None,\n",
    "    skip_bb = False,\n",
    "):\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    def print_symb_error(g_symb, h_symb, txt=\"symbolic formula\", is_symb=True):\n",
    "        try:\n",
    "            test_losses_symb = get_symb_test_error(\n",
    "                g_symb=g_symb,\n",
    "                h_symb=h_symb,\n",
    "                test_set=test_set,\n",
    "                message_passing=message_passing,\n",
    "                include_time=include_time,\n",
    "                atol=atol,\n",
    "                rtol=rtol,\n",
    "                method=method,\n",
    "                scaler=scaler,\n",
    "                inverse_scale=inverse_scale,\n",
    "                is_symb=is_symb\n",
    "            )\n",
    "\n",
    "            ts_mean = np.mean(test_losses_symb)\n",
    "            ts_var = np.var(test_losses_symb)\n",
    "            ts_std = np.std(test_losses_symb)\n",
    "\n",
    "            print(f\"Mean Test loss of {txt}: {ts_mean}\")\n",
    "            print(f\"Var Test loss of {txt}: {ts_var}\")\n",
    "            print(f\"Std Test loss of {txt}: {ts_std}\")\n",
    "\n",
    "            return ts_mean, ts_var, ts_std\n",
    "        except AssertionError:\n",
    "            print(\"Evaluation failed!\")\n",
    "            return np.inf, np.inf, np.inf\n",
    "\n",
    "    if not skip_bb:\n",
    "        print(\"Black-Box fitting \\n\")\n",
    "        bb_symb, bb_g_symb, bb_h_symb, exec_time = valid_symb_model(\n",
    "            config=config,\n",
    "            model_path_gkan=f\"{model_path}/gkan\",\n",
    "            device=device,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            method=method,\n",
    "            black_box_fitting=True,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            sample_size = sample_size\n",
    "        )\n",
    "\n",
    "        print(latex(quantise(bb_symb)))\n",
    "        ts_mean_bb, ts_var_bb, ts_std_bb = print_symb_error(g_symb=bb_g_symb, h_symb=bb_h_symb)\n",
    "\n",
    "        results_dict[\"black_box_symb_quant\"] = str(quantise(bb_symb))\n",
    "        results_dict[\"black_box_symb\"] = str(bb_symb)\n",
    "        results_dict[\"black_box_symb_test_MAE\"] = ts_mean_bb\n",
    "        results_dict[\"black_box_symb_test_Var\"] = ts_var_bb\n",
    "        results_dict[\"black_box_symb_test_Std\"] = ts_std_bb\n",
    "        results_dict[\"black_box_exec_time\"] = exec_time\n",
    "\n",
    "    print(\"Spline-wise fitting\\n\")\n",
    "    spline_symb, spl_g_symb, spl_h_symb, exec_time = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/gkan\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        black_box_fitting=False,\n",
    "        n_g_hidden_layers=n_g_hidden_layers,\n",
    "        n_h_hidden_layers=n_h_hidden_layers,\n",
    "        sample_size = sample_size,\n",
    "        grid_orig=grid_orig\n",
    "    )\n",
    "    print(latex(quantise(spline_symb)))\n",
    "    ts_mean_sw, ts_var_sw, ts_std_sw = print_symb_error(g_symb=spl_g_symb, h_symb=spl_h_symb)\n",
    "\n",
    "    results_dict[\"spline_wise_symb_quant\"] = str(quantise(spline_symb))\n",
    "    results_dict[\"spline_wise_symb\"] = str(spline_symb)\n",
    "    results_dict[\"spline_wise_symb_test_MAE\"] = ts_mean_sw\n",
    "    results_dict[\"spline_wise_symb_test_Var\"] = ts_var_sw\n",
    "    results_dict[\"spline_wise_symb_test_Std\"] = ts_std_sw\n",
    "    results_dict[\"spline_wise_exec_time\"] = exec_time\n",
    "\n",
    "\n",
    "    if eval_model:\n",
    "        print(\"Evaluate raw model\\n\")\n",
    "        # Loading best model\n",
    "        best_model = build_model_from_file(\n",
    "            model_path=model_path,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            method=method,\n",
    "            adjoint=adjoint,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            compute_mult=compute_mult\n",
    "        )\n",
    "\n",
    "        tot_params = sum(p.numel() for p in best_model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of model's parameters: {tot_params}\\n\")\n",
    "        results_dict[\"Number of params\"] = tot_params\n",
    "\n",
    "        best_model = best_model.eval()\n",
    "        ts_mean_model, ts_var_model, ts_std_model = print_symb_error(\n",
    "            g_symb=best_model.conv.model.g_net,\n",
    "            h_symb=best_model.conv.model.h_net,\n",
    "            txt=\"best model\",\n",
    "            is_symb=False\n",
    "        )\n",
    "\n",
    "        results_dict[\"model_test_MAE\"] = ts_mean_model\n",
    "        results_dict[\"model_test_Var\"] = ts_var_model\n",
    "        results_dict[\"model_test_Std\"] = ts_std_model\n",
    "\n",
    "    with open(f\"{model_path}/{res_file_name}\", 'w') as file:\n",
    "        json.dump(results_dict, file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, node_index = 0, save_path = None, show=True, title = None):\n",
    "    title_ = f'y_true vs y_pred for Node {node_index}' if title is None else title\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_true[:, node_index, :], label='y_true', marker='o')\n",
    "    plt.plot(y_pred[:, node_index, :], label='y_pred', marker='o')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(title_)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(f\"{save_path}/{title_}.png\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.3504788815528931e-05\n",
      "Var Test loss of symbolic formula: 1.314533673970284e-13\n",
      "Std Test loss of symbolic formula: 3.625649836884809e-07\n"
     ]
    }
   ],
   "source": [
    "kur_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_kuramoto.yml\")\n",
    "\n",
    "KUR = get_test_set(\n",
    "    dynamics=kur_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=kur_config['input_range'],\n",
    "    **kur_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: torch.sin(x[:, 1] - x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: 2.0 + 0.5 * x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=KUR,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.071706852447581e-06\n",
      "Var Test loss of symbolic formula: 8.008373820613663e-14\n",
      "Std Test loss of symbolic formula: 2.829907033917133e-07\n"
     ]
    }
   ],
   "source": [
    "epid_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_epidemics.yml\")\n",
    "\n",
    "EPID = get_test_set(\n",
    "    dynamics=epid_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=epid_config['input_range'],\n",
    "    **epid_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.5*x[:, 1].unsqueeze(-1) * (1 - x[:, 0].unsqueeze(-1))\n",
    "h_symb = lambda x: x[:, 1].unsqueeze(1) - 0.5 * x[:, 0].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=EPID,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 3.735399635237021e-06\n",
      "Var Test loss of symbolic formula: 4.746857081617248e-13\n",
      "Std Test loss of symbolic formula: 6.889743886108719e-07\n"
     ]
    }
   ],
   "source": [
    "pop_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "\n",
    "POP = get_test_set(\n",
    "    dynamics=pop_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=pop_config['input_range'],\n",
    "    **pop_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.2*torch.pow(x[:, 1].unsqueeze(-1), 3)\n",
    "h_symb = lambda x: -0.5 * x[:, 0].unsqueeze(-1) + x[:, 1].unsqueeze(1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=POP,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.2006473374034006e-06\n",
      "Var Test loss of symbolic formula: 7.184599599254429e-14\n",
      "Std Test loss of symbolic formula: 2.6804103415810103e-07\n"
     ]
    }
   ],
   "source": [
    "bio_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical.yml\")\n",
    "\n",
    "BIO = get_test_set(\n",
    "    dynamics=bio_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=bio_config['input_range'],\n",
    "    **bio_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: (-0.5*x[:, 1] * x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: (1.0 - 0.5 * x[:, 0]).unsqueeze(-1)  + x[:, 1].unsqueeze(-1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=BIO,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symb Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_candidates = [(-10, 10), (-5, 5)]\n",
    "weight_candidates = [0.0, 0.5, 1.0]\n",
    "\n",
    "grid_orig = (\n",
    "    [(-5, 5)],\n",
    "    [0.01, 0.05, 0.1],\n",
    "    [1e-5, 0.3, 0.7, 0.9]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1e-05\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.3\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.76\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.9\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1e-05\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.3\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.76\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.9\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1e-05\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.3\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.76\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.9\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.1, 'ws': 1e-05, 'valid_loss': 8.099287515506148e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 39.298094 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 27.336989 seconds\n",
      "\\sum_{j}(-1.8*((-0.32*tan(0.3*x_i - 3.5) - 0.12)*(-3.6*tan(0.35*x_j - 0.39) - 1.23) + 1)**2 - 0.01*tan(0.9*tan(0.72*x_j - 0.01) + 0.38*tanh(1.75*x_i - 0.96) - 3.18) - 0.18*tan(0.73*tanh(0.63*x_i - 0.46) + 0.01*tanh(5.0*x_j - 3.0) + 3.13) + 1.73) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 6.471075660859545e-05\n",
      "Var Test loss of symbolic formula: 2.556335405845739e-11\n",
      "Std Test loss of symbolic formula: 5.056021564279309e-06\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 280\n",
      "\n",
      "Mean Test loss of best model: 3.524918853751539e-05\n",
      "Var Test loss of best model: 1.9364785946079674e-11\n",
      "Std Test loss of best model: 4.400543823901732e-06\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=\"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.00014469254529103637}\n",
      "Fitting G_Net...\n",
      "Execution time: 19.499432 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 18.168052 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.00012971960192468637\n",
      "Var Test loss of symbolic formula: 1.551889595018015e-10\n",
      "Std Test loss of symbolic formula: 1.2457486082745648e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'log_loss', 'theta': 0.01, 'cut_threshold': 0.1, 'valid_loss': 0.07096663117408752}\n",
      "Fitting G_Net...\n",
      "Execution time: 104.350869 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 12.334118 seconds\n",
      "\\sum_{j}(-0.34*exp(0.37*x_i) - 0.31*sin(0.96*x_i - 0.6*x_j + 1.39) + 0.56) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.05904915059606234\n",
      "Var Test loss of symbolic formula: 0.00011741744970508111\n",
      "Std Test loss of symbolic formula: 0.010835933264148553\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 410\n",
      "\n",
      "Mean Test loss of best model: 7.585063091634463e-05\n",
      "Var Test loss of best model: 1.0755207177248116e-10\n",
      "Std Test loss of best model: 1.037073149649923e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=30000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.00165196240413934}\n",
      "Pruning node (0,0)\n",
      "Fitting G_Net...\n",
      "Execution time: 22.175564 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.853203 seconds\n",
      "\\sum_{j}(0.26*tan((0.13 - 1.01*sin(1.59*x_j + 2.73))*(-0.7*sin(1.5*x_i - 0.38) - 0.14) + 3.2) - 0.07*tan(-0.07*sin(1.76*x_j - 3.93) + 0.19*tan(0.69*x_i + 2.41) + 4.46) + 0.14) - 0.51 x_{i} + 1.01\n",
      "Mean Test loss of symbolic formula: 0.0017636449774727225\n",
      "Var Test loss of symbolic formula: 1.0041795717905035e-08\n",
      "Std Test loss of symbolic formula: 0.00010020876068440841\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 287\n",
      "\n",
      "Mean Test loss of best model: 0.0009019768719250957\n",
      "Var Test loss of best model: 1.1058958327873277e-08\n",
      "Std Test loss of best model: 0.00010516158199586614\n",
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.005463437642902136}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.076181 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 6.215494 seconds\n",
      "\\sum_{j}(0.03 - 0.12*tan(0.65*tanh(1.93*x_i - 0.18) + 1.62*tanh(1.44*x_j + 0.53) + 8.58)) - 0.52 x_{i} + 1.03\n",
      "Mean Test loss of symbolic formula: 0.0046593511166671915\n",
      "Var Test loss of symbolic formula: 3.5492602483441617e-07\n",
      "Std Test loss of symbolic formula: 0.0005957566825763822\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 88\n",
      "\n",
      "Mean Test loss of best model: 0.007494914500663678\n",
      "Var Test loss of best model: 1.6741281413871372e-06\n",
      "Std Test loss of best model: 0.0012938810383443823\n",
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.01, 'ws': 0.5, 'valid_loss': 0.054467469453811646}\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Fitting G_Net...\n",
      "Execution time: 22.307149 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 6.788248 seconds\n",
      "\\sum_{j}(0.07*((1.13 - 0.22*sin(1.24*x_i + 1.99))*(3.9*sin(0.55*x_j + 5.18) + 3.47) - 1)**2 - 0.08) - 1.12 x_{i} + 4.46 \\left(0.34 - x_{i}\\right)^{3} + 4.53 \\left(0.34 - x_{i}\\right)^{2} - 0.08 e^{3.16 \\sin{\\left(4.1 x_{i} - 2.63 \\right)}} + 1.48 \\tanh{\\left(79.61 x_{i}^{3} - 129.38 x_{i}^{2} + 75.37 x_{i} - 25.89 \\right)} + 2.51\n",
      "Mean Test loss of symbolic formula: 0.0555174412826697\n",
      "Var Test loss of symbolic formula: 6.762881574368416e-05\n",
      "Std Test loss of symbolic formula: 0.008223674102472942\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 408\n",
      "\n",
      "Mean Test loss of best model: 0.12453502664963405\n",
      "Var Test loss of best model: 9.519241864750259e-05\n",
      "Std Test loss of best model: 0.009756660219947325\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db_2/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=bio_config,\n",
    "        model_path=model_path,\n",
    "        test_set=BIO,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=True,\n",
    "        compute_mult=True,\n",
    "        grid_orig=grid_orig,\n",
    "        skip_bb=True,\n",
    "        res_file_name=\"sw_orig_kan.json\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.0015498856082558632}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 12.433132 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 3.497558 seconds\n",
      "\\sum_{j}(-0.5*sin(-1.0*x_i + 1.0*x_j + 3.14)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0014806334317351382\n",
      "Var Test loss of symbolic formula: 5.648642413415252e-08\n",
      "Std Test loss of symbolic formula: 0.00023766872771602182\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 543\n",
      "\n",
      "Mean Test loss of best model: 0.0016122294279436271\n",
      "Var Test loss of best model: 6.193546818525011e-07\n",
      "Std Test loss of best model: 0.0007869909032844669\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=\"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 200, 'valid_loss': 0.00037592652370221913}\n",
      "Fitting G_Net...\n",
      "Execution time: 36.569105 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 39.925308 seconds\n",
      "\\sum_{j}(-0.5*sin(x_i - x_j)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0003103772275305043\n",
      "Var Test loss of symbolic formula: 1.0822150048683463e-10\n",
      "Std Test loss of symbolic formula: 1.040295633398673e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'score', 'theta': 0.01, 'cut_threshold': 0.1, 'valid_loss': 0.0028883807826787233}\n",
      "Fitting G_Net...\n",
      "Execution time: 4.323579 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.755881 seconds\n",
      "\\sum_{j}(0.5*cos(1.0*x_i - 1.0*x_j + 1.57)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0022030010974655547\n",
      "Var Test loss of symbolic formula: 2.0978495420216526e-08\n",
      "Std Test loss of symbolic formula: 0.00014483955060761727\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 221\n",
      "\n",
      "Mean Test loss of best model: 0.001870445868310829\n",
      "Var Test loss of best model: 9.885763786732787e-08\n",
      "Std Test loss of best model: 0.0003144163447839948\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 0.5, 'valid_loss': 0.05868314206600189}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 11.965608 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.530244 seconds\n",
      "\\sum_{j}(0.49*sin(-1.0*x_i + 8.81*cos(0.12*x_j + 4.23) + 4.05)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.04665224875013033\n",
      "Var Test loss of symbolic formula: 6.611553683154149e-05\n",
      "Std Test loss of symbolic formula: 0.008131146095818319\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 138\n",
      "\n",
      "Mean Test loss of best model: 0.03685015129546324\n",
      "Var Test loss of best model: 7.464270905152173e-05\n",
      "Std Test loss of best model: 0.00863960120905599\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.05, 'ws': 0.5, 'valid_loss': 0.08293505012989044}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 22.813863 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 11.871675 seconds\n",
      "\\sum_{j}(0.43*cos(-0.89*x_i + 0.95*x_j + 4.37) + 0.01) + 0.01 x_{i} + 0.21 \\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 2.08\n",
      "Mean Test loss of symbolic formula: 0.09400896479686101\n",
      "Var Test loss of symbolic formula: 9.130723745100055e-06\n",
      "Std Test loss of symbolic formula: 0.0030217087459085226\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 485\n",
      "\n",
      "Mean Test loss of best model: 0.15763703485329947\n",
      "Var Test loss of best model: 0.0005103655496785128\n",
      "Std Test loss of best model: 0.022591271537443676\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.05, 'ws': 0.0, 'valid_loss': 0.9436018466949463}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting G_Net...\n",
      "Execution time: 0.000455 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.684838 seconds\n",
      "\\sum_{j}(0) - 5.15 x_{i} - 0.12 \\left(x_{i} + 0.27\\right)^{3} + 1.42 \\left(x_{i} + 0.27\\right)^{2} - 7.61 \\sin{\\left(0.8 x_{i} - 2.19 \\right)} + 2.75 \\cos{\\left(0.89 x_{i} + 1.23 \\right)} - 13.32 \\cos{\\left(5.35 \\cos{\\left(1.85 x_{i} - 4.54 \\right)} - 2.87 \\right)} + 6.57\n",
      "Mean Test loss of symbolic formula: 1.0101089080174763\n",
      "Var Test loss of symbolic formula: 5.021635763884862e-05\n",
      "Std Test loss of symbolic formula: 0.00708635009287917\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 348\n",
      "\n",
      "Mean Test loss of best model: 0.9981474081675211\n",
      "Var Test loss of best model: 0.0014790565950646183\n",
      "Std Test loss of best model: 0.03845850484697264\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=kur_config,\n",
    "        model_path=model_path,\n",
    "        test_set=KUR,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=True,\n",
    "        compute_mult=True,\n",
    "        grid_orig=grid_orig,\n",
    "        skip_bb=True,\n",
    "        res_file_name=\"sw_orig_kan.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1e-05\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.3\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.7\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.9\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1e-05\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.3\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.7\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.9\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1e-05\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.3\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.7\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.9\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 1e-05, 'valid_loss': 0.00016007157682906836}\n",
      "Fitting G_Net...\n",
      "Execution time: 62.244252 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 13.634253 seconds\n",
      "\\sum_{j}(2.14*exp(0.89*tan(0.1*x_j - 0.71) - 0.05*tanh(0.56*x_i - 0.24)) + 1.23*sin((0.73 - 3.2*tan(0.24*x_i - 3.08))*(-1.45*tan(0.36*x_j - 3.34) - 0.26) + 3.44) - 0.63) + 0.98 \\sin{\\left(1.06 \\sin{\\left(0.5 x_{i} - 0.43 \\right)} + 3.46 \\right)} - 0.12\n",
      "Mean Test loss of symbolic formula: 0.00014402520415994027\n",
      "Var Test loss of symbolic formula: 1.3435901014583254e-10\n",
      "Std Test loss of symbolic formula: 1.1591333406723858e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 264\n",
      "\n",
      "Mean Test loss of best model: 0.00019420394770956287\n",
      "Var Test loss of best model: 9.010235804097534e-11\n",
      "Std Test loss of best model: 9.492226189939605e-06\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=\"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.00013034719449933618}\n",
      "Fitting G_Net...\n",
      "Execution time: 16.949507 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.884131 seconds\n",
      "\\sum_{j}(x_j*(0.5 - 0.5*x_i)) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.00011974307077859218\n",
      "Var Test loss of symbolic formula: 1.3272674570917887e-10\n",
      "Std Test loss of symbolic formula: 1.152070942733905e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'score', 'theta': 0.1, 'cut_threshold': 0.1, 'valid_loss': 0.05961911007761955}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 15.494766 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.646192 seconds\n",
      "\\sum_{j}(0.08*x_j + 0.27*exp(-1.65*x_i + 0.69*x_j) - 0.12) - 0.49 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.06654291599988937\n",
      "Var Test loss of symbolic formula: 4.919405087770261e-06\n",
      "Std Test loss of symbolic formula: 0.002217973193654572\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 277\n",
      "\n",
      "Mean Test loss of best model: 0.00011343214767596994\n",
      "Var Test loss of best model: 2.925668873129952e-10\n",
      "Std Test loss of best model: 1.7104586733183446e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.05, 'ws': 0.5, 'valid_loss': 0.001933976192958653}\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 55.842746 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.867319 seconds\n",
      "\\sum_{j}(-0.01*(0.68*sin(3.15*x_i + 0.77) - 0.06*sin(3.97*x_j + 2.97) - 1)**2 - 1.75*sin((0.59*sin(0.72*x_i - 0.41) - 0.19)*(-1.47*tan(0.75*x_j - 3.78) - 0.97) - 4.25) + 1.59) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.0020541123813018203\n",
      "Var Test loss of symbolic formula: 9.139135130568758e-08\n",
      "Std Test loss of symbolic formula: 0.000302310025149163\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 0.5, 'valid_loss': 0.023685945197939873}\n",
      "Fitting G_Net...\n",
      "Execution time: 44.178671 seconds\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 13.815365 seconds\n",
      "\\sum_{j}(-0.140420343965845*(1 - 0.257703081232493*x_j)**0.35 + 0.19*(-log(1.98*x_j + 3.26) - 0.42*sin(2.73*x_i + 1.67) + 0.75)**2 + 0.06*cos(1.01*sin(3.0*x_j - 2.42) + 1.05*tanh(3.12*x_i - 1.82) + 1.19) + 0.27 - 0.163857711274658*exp(-0.046*tan(1.11*x_j + 2.31))) - 0.13\n",
      "Mean Test loss of symbolic formula: 0.025522695233424503\n",
      "Var Test loss of symbolic formula: 1.393366820601745e-05\n",
      "Std Test loss of symbolic formula: 0.003732782903681575\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.10597091168165207}\n",
      "Fitting G_Net...\n",
      "Execution time: 22.129434 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.613759 seconds\n",
      "\\sum_{j}(0.05*(0.2*sin(0.54*x_j + 2.22) - 1)**3 + 0.04) - 1.09 \\tanh{\\left(88.87 x_{i} - 39.69 \\right)} + 0.17 \\tanh{\\left(78.18 \\sin{\\left(10.47 x_{i} - 5.14 \\right)} - 24.74 \\right)} + 0.9 \\tanh{\\left(18.54 \\tanh{\\left(9.74 x_{i} - 4.92 \\right)} + 25.3 \\right)} + 0.09\n",
      "Mean Test loss of symbolic formula: 0.10883854577938716\n",
      "Var Test loss of symbolic formula: 1.4602215926541443e-05\n",
      "Std Test loss of symbolic formula: 0.0038212845911475167\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=epid_config,\n",
    "        model_path=model_path,\n",
    "        test_set=EPID,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False,\n",
    "        compute_mult=True,\n",
    "        grid_orig=grid_orig,\n",
    "        skip_bb=True,\n",
    "        res_file_name=\"sw_orig_kan.json\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.01, 'ws': 0.5, 'valid_loss': 0.008912813849747181}\n",
      "Fitting G_Net...\n",
      "Execution time: 13.477983 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.301956 seconds\n",
      "\\sum_{j}(0.18*(x_j + 0.02)**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.006267187030365069\n",
      "Var Test loss of symbolic formula: 6.031203840113186e-07\n",
      "Std Test loss of symbolic formula: 0.0007766082564661019\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 294\n",
      "\n",
      "Mean Test loss of best model: 0.00026198988295315456\n",
      "Var Test loss of best model: 2.1526992571854367e-09\n",
      "Std Test loss of best model: 4.639719018631879e-05\n"
     ]
    }
   ],
   "source": [
    "post_process_gkan(\n",
    "    config=pop_config,\n",
    "    model_path=\"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_12/0\",\n",
    "    test_set=POP,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=True,\n",
    "    grid_orig=grid_orig,\n",
    "    skip_bb=True,\n",
    "    res_file_name=\"sw_orig_kan.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.0001383304625051096}\n",
      "Fitting G_Net...\n",
      "Execution time: 18.222491 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.137481 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.00012729887142389393\n",
      "Var Test loss of symbolic formula: 1.3614101926894765e-10\n",
      "Std Test loss of symbolic formula: 1.1667948374455024e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with score, theta 0.1 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.01 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.05 and cutting threshold 0.001\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.1\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.01\n",
      "Fitting symbolic model with log_loss, theta 0.1 and cutting threshold 0.001\n",
      "Refitting best model with {'sort_by': 'log_loss', 'theta': 0.05, 'cut_threshold': 0.1, 'valid_loss': 0.017918474972248077}\n",
      "Pruning node (0,0)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.877642 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 25.389021 seconds\n",
      "\\sum_{j}(-0.02*x_i**2 - 0.04*x_i - 0.03*exp(1.01*x_i) - 0.01*sin(2.35*x_j - 0.33) - 0.01*sin(3.06*x_j - 0.62) + 0.06*tan(1.03*x_j + 0.16) + 0.02*tan(1.22*x_j + 0.08) + 0.15*tanh(0.8*x_i - 0.79) + 0.1) - 0.05 x_{i} - 0.81 e^{0.19 x_{i}} - 0.2 e^{0.55 x_{i}} - 0.07 \\tan{\\left(0.81 x_{i} + 0.23 \\right)} - 0.15 \\tanh{\\left(0.75 x_{i} + 0.22 \\right)} + 1.06\n",
      "Mean Test loss of symbolic formula: 0.013361897940436998\n",
      "Var Test loss of symbolic formula: 2.211689633694899e-06\n",
      "Std Test loss of symbolic formula: 0.00148717505146331\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 516\n",
      "\n",
      "Mean Test loss of best model: 0.00040224265345993143\n",
      "Var Test loss of best model: 6.4747059720440794e-09\n",
      "Std Test loss of best model: 8.046555767559235e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-population-gkan/population_gkan_no_mult/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=pop_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=POP,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\",\n",
    "    compute_mult=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-5, 5), 'theta': 0.05, 'ws': 0.0, 'valid_loss': 0.03003748506307602}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,5)\n",
      "Fitting G_Net...\n",
      "Execution time: 72.655953 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.915971 seconds\n",
      "\\sum_{j}(0.04*(0.08*(-x_i - 0.97)**2 - 0.02*sin(3.23*x_j + 2.51) - 1)**2 + 0.06*(-0.35*sin(0.66*x_i - 0.86) - 0.11*tan(1.25*x_j + 0.07) - 1)**2 - 0.09) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.02890730897585551\n",
      "Var Test loss of symbolic formula: 9.327000624895529e-06\n",
      "Std Test loss of symbolic formula: 0.003054013854732085\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.011385745368897915}\n",
      "Fitting G_Net...\n",
      "Execution time: 56.855053 seconds\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.182778 seconds\n",
      "\\sum_{j}(-0.21*(0.02*sin(4.61*x_j + 6.2) + 0.07*tan(0.12*x_i - 5.01) - 1)**3 - 0.12*exp(-0.71*(x_j + 0.01)**3 - 0.46*cos(1.07*x_i - 2.35)) - 0.05*tan(0.3*(-x_j - 0.01)**3 + 1.1*tanh(0.61*x_i - 1.03) - 9.14) - 0.28 + 0.3*exp(-0.27*(0.03*sin(4.07*x_i + 3.19) - 0.22)*tan(1.05*x_j - 9.23))) - 1.45 + 1.45 e^{- 0.32 x_{i}}\n",
      "Mean Test loss of symbolic formula: 0.01057090579221646\n",
      "Var Test loss of symbolic formula: 6.017989246996955e-08\n",
      "Std Test loss of symbolic formula: 0.000245315903418367\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-10, 10), theta 0.1 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.01 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.05 and ws 1.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.0\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 0.5\n",
      "Fitting symbolic model with (-5, 5), theta 0.1 and ws 1.0\n",
      "Refitting best model with {'grid_range': (-10, 10), 'theta': 0.01, 'ws': 0.0, 'valid_loss': 0.02071448415517807}\n",
      "Fitting G_Net...\n",
      "Execution time: 66.890799 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.281633 seconds\n",
      "\\sum_{j}(-0.06*tan((0.4 - 0.82*tanh(10.0*x_i + 2.4))*(-0.27*sin(7.17*x_j - 3.59) - 0.05) + 6.2) + 0.04*tan((-0.58*sin(10.0*x_i - 2.4) - 0.22)*(-0.17*cos(10.0*x_j + 9.2) - 0.1) + 7.15) - 0.12*tan(0.76*(-x_j - 0.07)**3 + 0.56) + 0.02*tan(0.12*tan(1.43*x_j + 9.56) + 0.57*tanh(0.86*x_i - 0.8) - 6.45) + 0.03) - 0.52 x_{i}^{3} + 0.11 x_{i}^{2} + 0.15 x_{i} - 0.67 e^{0.57 x_{i}} + 0.71\n",
      "Mean Test loss of symbolic formula: 0.023961279541254044\n",
      "Var Test loss of symbolic formula: 4.783578631609164e-07\n",
      "Std Test loss of symbolic formula: 0.0006916341975068298\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=pop_config,\n",
    "        model_path=model_path,\n",
    "        test_set=POP,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False,\n",
    "        compute_mult=True,\n",
    "        grid_orig=grid_orig,\n",
    "        skip_bb=True,\n",
    "        res_file_name=\"sw_orig_kan.json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Epid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "\n",
    "pysr_model = lambda : get_pysr_model(\n",
    "    model_selection=\"score\",\n",
    "    n_iterations=200,\n",
    "    parallelism=\"serial\",\n",
    "    random_state = 9999,\n",
    "    deterministic = True\n",
    ")\n",
    "\n",
    "gkan_symb, symb_g, symb_h, _ = fit_black_box_from_kan(\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    device='cuda',\n",
    "    model_path=model_path_gkan,\n",
    "    pysr_model=pysr_model,\n",
    "    sample_size=10000,\n",
    "    theta=-np.inf,\n",
    "    message_passing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682064 x_{i} + 2.4648788$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682064*x_i + 2.4648788"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkan_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 20.673625 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 3.790720 seconds\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "\n",
    "symb_spline_wise, symb_g, symb_h, _ = fit_model(\n",
    "    n_h_hidden_layers=2,\n",
    "    n_g_hidden_layers=2,\n",
    "    model_path=model_path_gkan,\n",
    "    theta=0.01,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    sample_size=10000,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.00189043097977177) + 2.31595301522748 x_{i} + 1.19863983320216 \\tanh{\\left(4.67585338279873 \\sin{\\left(0.292742920345445 x_{i} + 1.25967610031539 \\right)} - 3.26317693762952 \\right)} + 1.66742547802796$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.00189043097977177) + 2.31595301522748*x_i + 1.19863983320216*tanh(4.67585338279873*sin(0.292742920345445*x_i + 1.25967610031539) - 3.26317693762952) + 1.66742547802796"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symb_spline_wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model with score and 50\n",
      "0.02730431593954563\n",
      "Fitting model with score and 100\n",
      "0.027311544865369797\n",
      "Fitting model with score and 200\n",
      "0.06641161441802979\n",
      "Fitting model with accuracy and 50\n",
      "0.027311544865369797\n",
      "Fitting model with accuracy and 100\n",
      "0.03936349228024483\n",
      "Fitting model with accuracy and 200\n",
      "0.027311554178595543\n"
     ]
    }
   ],
   "source": [
    "from datasets.RealEpidemics import RealEpidemics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "res = {}\n",
    "model_selections = [\"score\", \"accuracy\"]\n",
    "n_iterations = [50, 100, 200]\n",
    "\n",
    "real_epid_data = RealEpidemics(\n",
    "    root = './data_real_epid_covid_int_scaled',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=False,\n",
    "    history=1,\n",
    "    horizon=44,\n",
    "    scale=True,\n",
    "    scale_range=(-1, 1)\n",
    ")\n",
    "\n",
    "tr_len = real_epid_data[0].y.shape[0]\n",
    "\n",
    "for mod in model_selections:\n",
    "    for n_iter in n_iterations:\n",
    "        print(f\"Fitting model with {mod} and {n_iter}\")\n",
    "        model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "\n",
    "        pysr_model = lambda : get_pysr_model(\n",
    "            model_selection=mod,\n",
    "            n_iterations=n_iter,\n",
    "            # parallelism=\"serial\",\n",
    "            # random_state = 9999,\n",
    "            # deterministic = True\n",
    "        )\n",
    "\n",
    "        gkan_symb, symb_g, symb_h, _ = fit_black_box_from_kan(\n",
    "            n_g_hidden_layers=2,\n",
    "            n_h_hidden_layers=2,\n",
    "            device='cuda',\n",
    "            model_path=model_path_gkan,\n",
    "            pysr_model=pysr_model,\n",
    "            sample_size=10000,\n",
    "            theta=-np.inf,\n",
    "            message_passing=False\n",
    "        )\n",
    "        \n",
    "        g_symb = make_callable(symb_g)\n",
    "        h_symb = make_callable(symb_h)\n",
    "        \n",
    "        symb_model = get_model(\n",
    "            g = g_symb,\n",
    "            h = h_symb,\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            integration_method='rk4'\n",
    "        )\n",
    "        \n",
    "        data_0 = real_epid_data[0]\n",
    "        y_pred = symb_model(data_0).cpu().detach().numpy()[:int(tr_len*0.8)]\n",
    "        y_true = real_epid_data[0].y.cpu().detach().numpy()[:int(tr_len*0.8)]\n",
    "        \n",
    "        err = mean_absolute_error(y_true.flatten(), y_pred.flatten())\n",
    "        print(err)\n",
    "        res[str(gkan_symb)] = err    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4681642*x_i + 2.464845': 0.02730431593954563,\n",
       " '\\\\sum_{j}( -0.0039747013*exp(x_j)) + 2.4682088*x_i + 2.4648814': 0.027311544865369797,\n",
       " '\\\\sum_{j}( -0.0039747115*exp(x_j)) + 3.3896239*tan(tanh(x_i + 0.9902851))': 0.06641161441802979,\n",
       " '\\\\sum_{j}( -0.003974712*exp(x_j)) + 2.4682086*x_i + 2.4648812': 0.027311544865369797,\n",
       " '\\\\sum_{j}( -0.0039747115*exp(x_j)) + 8.122365*tanh(exp(x_i)) - 2.8761487': 0.03936349228024483,\n",
       " '\\\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682174*x_i + 2.46489': 0.027311554178595543}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSS Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tss_test_error(\n",
    "    text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h,\n",
    "    row_means,\n",
    "    test_set,\n",
    "    result_dict,\n",
    "    suffix = '',\n",
    "    method = \"dopri5\"\n",
    "):\n",
    "    g_symb = sp.S(0)\n",
    "    h_symb = sp.S(0)\n",
    "\n",
    "    \n",
    "    for symb_g in text_sympy_mapping_g.keys():\n",
    "        g_symb += row_means[symb_g] * text_sympy_mapping_g[symb_g]\n",
    "    for symb_h in text_sympy_mapping_h.keys():\n",
    "        h_symb += row_means[symb_h] * text_sympy_mapping_h[symb_h]\n",
    "\n",
    "\n",
    "    try:\n",
    "        test_losses = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=test_set,\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=1e-5,\n",
    "            rtol=1e-5,\n",
    "            is_symb=True\n",
    "        )\n",
    "\n",
    "        ts_mean = np.mean(test_losses)\n",
    "        ts_var = np.var(test_losses)\n",
    "        ts_std = np.std(test_losses)\n",
    "\n",
    "        print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "        print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "        print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "        \n",
    "        result_dict[f'tss_test_mae_{suffix}'] = ts_mean\n",
    "        result_dict[f'tss_test_var_{suffix}'] = ts_var\n",
    "        result_dict[f'tss_test_std_{suffix}'] = ts_std\n",
    "        \n",
    "    except AssertionError:\n",
    "        print(\"Evaluation failed !\")\n",
    "        result_dict[f'error_{suffix}'] = 'Evaluation failed !'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.499495\n",
       "constant          2.000012\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.00029117241501808167\n",
      "Var Test loss of symbolic formula: 4.4434753406930564e-10\n",
      "Std Test loss of symbolic formula: 2.1079552511125697e-05\n"
     ]
    }
   ],
   "source": [
    "results_kur = {}\n",
    "\n",
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.496489\n",
       "constant          2.000509\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0021191818717246256\n",
      "Var Test loss of symbolic formula: 2.269309859505237e-08\n",
      "Std Test loss of symbolic formula: 0.00015064228687540682\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.531575\n",
       "fracx1            7.369008\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.558358391125997\n",
      "Var Test loss of symbolic formula: 0.0024888551943536502\n",
      "Std Test loss of symbolic formula: 0.049888427459217934\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"fracx1\": 1/ x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "fracx1jMinusx1i   -0.004194\n",
       "x1ifracx1j         0.087818\n",
       "x1iexpx1j          0.000292\n",
       "fracx1ix1j        -0.000736\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: nan\n",
      "Var Test loss of symbolic formula: nan\n",
      "Std Test loss of symbolic formula: nan\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1iexpx1j\": x_i * sp.exp(x_j),\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i),\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Kuramoto-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_kur, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "constant         -0.567966\n",
       "expx1jMinusx1i    0.208438\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "results_epid = {}\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.1941202183564504\n",
      "Var Test loss of symbolic formula: 0.0005310114619173017\n",
      "Std Test loss of symbolic formula: 0.023043685944685623\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.256831\n",
       "constant          0.569542\n",
       "expx1jMinusx1i    0.013251\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.053738709539175034\n",
      "Var Test loss of symbolic formula: 5.180841923608607e-05\n",
      "Std Test loss of symbolic formula: 0.007197806557284384\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i,\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.091028\n",
       "expx1jMinusx1i    0.111314\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.016693448647856712\n",
      "Var Test loss of symbolic formula: 8.436841921384436e-06\n",
      "Std Test loss of symbolic formula: 0.002904624230668132\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1ifracx1j        -0.019999\n",
       "fracx1ix1j         0.014712\n",
       "fracx1jMinusx1i    0.000244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.08860065788030624\n",
      "Var Test loss of symbolic formula: 4.077819097984363e-06\n",
      "Std Test loss of symbolic formula: 0.002019361061817416\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Epidemics-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_epid, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.711350\n",
       "constant    0.867073\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.036044025172789894\n",
      "Var Test loss of symbolic formula: 1.2206604668749429e-06\n",
      "Std Test loss of symbolic formula: 0.0011048350405716424\n"
     ]
    }
   ],
   "source": [
    "results_bio = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.740610\n",
       "constant    0.905639\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03708266963561376\n",
      "Var Test loss of symbolic formula: 2.1507763171681031e-07\n",
      "Std Test loss of symbolic formula: 0.00046376462965259685\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "x1ix1j    1.077840\n",
       "x1x1     -2.325285\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: nan\n",
      "Var Test loss of symbolic formula: nan\n",
      "Std Test loss of symbolic formula: nan\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='50db',\n",
    "    method=\"euler\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1ifracx1j         0.011954\n",
       "fracx1ix1j         0.003264\n",
       "fracx1jMinusx1i    0.000703\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation failed !\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Biochemical-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_bio, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.016272\n",
       "x1j         0.040017\n",
       "sinx1j      0.003158\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0990138625105222\n",
      "Var Test loss of symbolic formula: 1.0323049151655323e-05\n",
      "Std Test loss of symbolic formula: 0.0032129502255178687\n"
     ]
    }
   ],
   "source": [
    "results_pop = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.000443\n",
       "x1j         0.023472\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.09954124689102173\n",
      "Var Test loss of symbolic formula: 5.92840036887458e-06\n",
      "Std Test loss of symbolic formula: 0.0024348306653388815\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "sinx1j   -1.508801\n",
       "x1j       1.489724\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.11308030039072037\n",
      "Var Test loss of symbolic formula: 1.7624745905830963e-05\n",
      "Std Test loss of symbolic formula: 0.00419818364365245\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN      0.000000\n",
       "x1x1     0.028332\n",
       "sinx1   -0.482987\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03507093029717604\n",
      "Var Test loss of symbolic formula: 1.4470365959317085e-05\n",
      "Std Test loss of symbolic formula: 0.0038039934226174847\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"sinx1\": sp.sin(x_i),\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Population-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_pop, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
