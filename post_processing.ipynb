{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics\n",
    "\n",
    "Dynamics | $\\partial_{\\tau}x_i=$ |\n",
    "| :--------: | :-------: |\n",
    "Biochemical | $F -B x_i - R \\sum_j A_{ij} x_i x_j$ |\n",
    "Epidemics | $-B x_i + R \\sum_j A_{ij} (1-x_i)x_j$ |\n",
    "Population | $-B x_i^{b} + R \\sum_j A_{ij} x_j^a$ |\n",
    "Synchronization | $\\omega_i + R \\sum_j A_{ij} \\sin(x_j-x_i)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from experiments.experiments_gkan import ExperimentsGKAN\n",
    "from experiments.experiments_mpnn import ExperimentsMPNN\n",
    "from train_and_eval import eval_model\n",
    "import sympytorch\n",
    "\n",
    "storage = JournalStorage(JournalFileBackend(\"optuna_journal_storage.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def set_pytorch_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "set_pytorch_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_real_epid_mpnn.yml\")\n",
    "# config['patience'] = 450\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config,\n",
    "#     n_trials=3,\n",
    "#     study_name=\"test_mult_2\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "# # # config['t_span'] = [0, 1]\n",
    "# exp = ExperimentsGKAN(\n",
    "#     config=config,\n",
    "#     n_trials=1,\n",
    "#     study_name=\"test_mult_11\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 13:05:55,302] A new study created in Journal with name: model-population-gkan-test_mult_11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: num params: 348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-22 13:20:07,691] Trial 0 finished with value: 9.843736188486218e-05 and parameters: {'lr': 0.0028057582076672534, 'lamb': 1.0, 'batch_size': 16, 'use_orig_reg': True, 'lamb_g_net': 8.63200816860254e-06, 'lamb_h_net': 8.629132190071855e-06, 'grid_size_g_net': 5, 'spline_order_g_net': 3, 'range_limit_g_net': 7, 'mu_1_g_net': 0.8, 'mu_2_g_net': 0.1, 'hidden_dim_g_net': 6, 'grid_size_h_net': 18, 'spline_order_h_net': 1, 'range_limit_h_net': 2, 'mu_1_h_net': 0.2, 'mu_2_h_net': 0.4, 'hidden_dim_h_net': 4}. Best is trial 0 with value: 9.843736188486218e-05.\n"
     ]
    }
   ],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f13f1319940>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 30, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_pop = load_config(\"./configs/config_pred_deriv/config_ic1/config_population_mpnn.yml\")\n",
    "# # config_pop[\"t_eval_steps\"] = 1000\n",
    "# # config_pop[\"t_span\"] = [0, 10]\n",
    "\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config_pop,\n",
    "#     n_trials=1,\n",
    "#     study_name='test_mult_3'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 6, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set.raw_data_sampled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.MPNN import MPNN\n",
    "from models.baseline.MPNN_ODE import MPNN_ODE\n",
    "from train_and_eval import eval_model\n",
    "from datasets.SyntheticData import SyntheticData\n",
    "from sympy import symbols, sin, summation, simplify\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from utils.utils import integrate\n",
    "from torch_geometric.data import Data\n",
    "from models.kan.KAN import KAN\n",
    "from models.GKAN_ODE import GKAN_ODE\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sympy import latex\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_model(g, h, message_passing=True, include_time=False, atol=1e-5, rtol=1e-5, integration_method = 'scipy_solver',\n",
    "              eval=True, options = {}, all_t = False):\n",
    "    conv = MPNN(\n",
    "        g_net = g,\n",
    "        h_net = h,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "\n",
    "    symb = MPNN_ODE(\n",
    "        conv=conv,\n",
    "        model_path=\"./saved_models_optuna/tmp_symb\",\n",
    "        adjoint=True,\n",
    "        integration_method=integration_method,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        options = options,\n",
    "        all_t=all_t\n",
    "    )\n",
    "\n",
    "    if eval:\n",
    "        symb = symb.eval()\n",
    "    return symb\n",
    "\n",
    "\n",
    "def make_callable(expr):\n",
    "    free_syms = expr.free_symbols\n",
    "    if not free_syms:\n",
    "        # Expression is constant\n",
    "        const_value = float(expr)\n",
    "        return lambda x: torch.full((x.shape[0], 1), const_value, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    sym_module = sympytorch.SymPyModule(expressions=[expr])\n",
    "    syms = {str(s) for s in free_syms}\n",
    "    if {'x_i', 'x_j'} <= syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0], x_j=x[:, 1])\n",
    "    elif 'x_i' in syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0])\n",
    "    elif 'x_j' in syms:\n",
    "        return lambda x: sym_module(x_j=x[:, 1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected symbols in expression: {free_syms}\")\n",
    "\n",
    "\n",
    "def get_symb_test_error(g_symb, h_symb, test_set, message_passing=False, include_time=False, atol=1e-5, rtol=1e-5, scaler = None, inverse_scale=False, method='scipy_solver',\n",
    "                        is_symb = True):\n",
    "\n",
    "    if is_symb:\n",
    "        if isinstance(g_symb, int):\n",
    "            g_symb = sp.sympify(g_symb)\n",
    "\n",
    "        if isinstance(h_symb, int):\n",
    "            h_symb = sp.sympify(h_symb)\n",
    "\n",
    "        g_symb = make_callable(g_symb)\n",
    "        h_symb = make_callable(h_symb)\n",
    "\n",
    "    test_losses = []\n",
    "\n",
    "    for ts in test_set:\n",
    "        symb = get_model(\n",
    "            g=g_symb,\n",
    "            h=h_symb,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            integration_method=method\n",
    "        )\n",
    "\n",
    "        collate_fn = lambda samples_list: samples_list\n",
    "        test_loader = DataLoader(ts, batch_size=len(ts), shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "        test_loss = eval_model(\n",
    "            model=symb,\n",
    "            valid_loader=test_loader,\n",
    "            criterion=torch.nn.L1Loss(),\n",
    "            scaler=scaler,\n",
    "            inverse_scale=inverse_scale,\n",
    "            pred_deriv=False\n",
    "        )\n",
    "\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    return test_losses\n",
    "\n",
    "\n",
    "\n",
    "def get_test_set(dynamics, device='cuda', input_range=(0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    seeds = [12345, 67890, 111213]\n",
    "\n",
    "    graphs = [\n",
    "        nx.barabasi_albert_graph(70, 3, seed=seeds[0]),\n",
    "        nx.watts_strogatz_graph(50, 6, 0.3, seed=seeds[1]),\n",
    "        nx.erdos_renyi_graph(100, 0.05, seed=seeds[2])\n",
    "    ]\n",
    "\n",
    "    test_set = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        snapshots = integrate_test_set(\n",
    "            graph=graph,\n",
    "            dynamics=dynamics,\n",
    "            seed=seeds[i],\n",
    "            device=device,\n",
    "            input_range=input_range,\n",
    "            t_span=t_span,\n",
    "            **integration_kwargs\n",
    "        )\n",
    "        test_set.append(snapshots)\n",
    "\n",
    "    return test_set\n",
    "\n",
    "\n",
    "\n",
    "def integrate_test_set(graph, dynamics, seed=12345, device='cuda', input_range = (0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    # graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "    edge_index = from_networkx(graph).edge_index\n",
    "    edge_index = edge_index.to(torch.device(device))\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    data, t = integrate(\n",
    "        input_range=input_range,\n",
    "        t_span = t_span,\n",
    "        t_eval_steps=1000,\n",
    "        dynamics=dynamics,\n",
    "        device=device,\n",
    "        graph=graph,\n",
    "        rng = rng,\n",
    "        **integration_kwargs\n",
    "    )\n",
    "\n",
    "    snapshot = Data(\n",
    "        x = data[0].unsqueeze(0),\n",
    "        y = data[1:],\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=None,\n",
    "        t_span = t\n",
    "    )\n",
    "\n",
    "    return [snapshot]\n",
    "\n",
    "\n",
    "def build_model_from_file(model_path, message_passing, include_time, method='dopri5', adjoint=False, atol=1e-5, rtol=1e-5):\n",
    "    best_params_file = f\"{model_path}/best_params.json\"\n",
    "    best_state_path = f\"{model_path}/gkan/state_dict.pth\"\n",
    "\n",
    "    with open(best_params_file, 'r') as f:\n",
    "        best_hyperparams = json.load(f)\n",
    "\n",
    "    # g_net\n",
    "    g_net = KAN(\n",
    "        layers_hidden=[2, best_hyperparams['hidden_dim_g_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_g_net'],\n",
    "        spline_order=best_hyperparams['spline_order_g_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_g_net'], best_hyperparams['range_limit_g_net']],\n",
    "        mu_1=best_hyperparams['mu_1_g_net'],\n",
    "        mu_2=best_hyperparams['mu_2_g_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=True,\n",
    "        store_act=True\n",
    "    )\n",
    "\n",
    "    time_dim = 1 if include_time else 0\n",
    "    in_dim_h = 2 if message_passing else 1\n",
    "    in_dim_h += time_dim\n",
    "\n",
    "    # h_net\n",
    "    h_net = KAN(\n",
    "        layers_hidden=[in_dim_h, best_hyperparams['hidden_dim_h_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_h_net'],\n",
    "        spline_order=best_hyperparams['spline_order_h_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_h_net'], best_hyperparams['range_limit_h_net']],\n",
    "        mu_1=best_hyperparams['mu_1_h_net'],\n",
    "        mu_2=best_hyperparams['mu_2_h_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=True,\n",
    "        store_act=True\n",
    "    )\n",
    "\n",
    "    gkan = MPNN(\n",
    "        h_net=h_net,\n",
    "        g_net=g_net,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "\n",
    "    model = GKAN_ODE(\n",
    "        conv=gkan,\n",
    "        model_path='./saved_models_optuna/tmp',\n",
    "        lmbd_g=best_hyperparams['lamb_g_net'],\n",
    "        lmbd_h=best_hyperparams['lamb_h_net'],\n",
    "        integration_method=method,\n",
    "        adjoint=adjoint,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "\n",
    "    model = model.to(torch.device('cuda'))\n",
    "    model.load_state_dict(torch.load(best_state_path, weights_only=False, map_location=torch.device('cuda')))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def valid_symb_model(\n",
    "    config,\n",
    "    model_path_gkan,\n",
    "    device='cuda',\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    black_box_fitting=True,\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000\n",
    "):\n",
    "    \n",
    "    seed = 9999\n",
    "    graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "\n",
    "    # Prepare validation/test set\n",
    "    valid_set = integrate_test_set(\n",
    "        graph=graph,\n",
    "        dynamics=config['name'],\n",
    "        seed=seed,\n",
    "        device=device,\n",
    "        input_range=config['input_range'],\n",
    "        t_span=(0, 1),\n",
    "        **config['integration_kwargs']\n",
    "    )\n",
    "\n",
    "    # Helper to compute validation loss\n",
    "    def evaluate_model(g_symb, h_symb, is_symb=True):\n",
    "        errs = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=[valid_set],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            is_symb=is_symb\n",
    "        )\n",
    "        return errs[0]\n",
    "\n",
    "    # Helper to fit model for current config\n",
    "    def fit_single_model(param1, param2, param3=None):\n",
    "        if black_box_fitting:\n",
    "            print(f\"Fitting black-box model with {param1} and {param2} iterations\")\n",
    "            pysr_model = lambda: get_pysr_model(\n",
    "                model_selection=param1, \n",
    "                n_iterations=param2,\n",
    "                # parallelism=\"serial\",\n",
    "                # random_state = seed,\n",
    "                # deterministic = True\n",
    "            )\n",
    "            _, g_symb, h_symb, _ = fit_black_box_from_kan(\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                device=device,\n",
    "                model_path=model_path_gkan,\n",
    "                pysr_model=pysr_model,\n",
    "                sample_size=sample_size,\n",
    "                theta=-np.inf,\n",
    "                message_passing=False,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Fitting symbolic model with {param1}, theta {param2} and cutting threshold {param3}\")\n",
    "            _, g_symb, h_symb, _ = fit_model(\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                model_path=model_path_gkan,\n",
    "                theta=param2,\n",
    "                message_passing=False,\n",
    "                include_time=False,\n",
    "                sample_size=sample_size,\n",
    "                sort_by=param1,\n",
    "                verbose=False,\n",
    "                cut_threshold=param3\n",
    "            )\n",
    "        return g_symb, h_symb\n",
    "\n",
    "    if black_box_fitting:\n",
    "        param_grid = ([\"score\", \"accuracy\"], [50, 100, 200])\n",
    "        search_space = [(mod, val) for mod in param_grid[0] for val in param_grid[1]]\n",
    "    else:\n",
    "        param_grid = (\n",
    "            [\"score\", \"log_loss\"],       \n",
    "            [0.01, 0.05, 0.1],           \n",
    "            [0.1, 0.01, 0.001]    \n",
    "        )\n",
    "        search_space = list(itertools.product(*param_grid))\n",
    "\n",
    "    valid_losses = []\n",
    "\n",
    "    for params in search_space:\n",
    "        g_symb, h_symb = fit_single_model(*params)\n",
    "        try:\n",
    "            loss = evaluate_model(g_symb, h_symb)\n",
    "        except AssertionError:\n",
    "            loss = 1e8\n",
    "        if black_box_fitting:\n",
    "            valid_losses.append({'model_selection': params[0], 'param': params[1], 'valid_loss': loss})\n",
    "        else:\n",
    "            valid_losses.append({'sort_by': params[0], 'theta': params[1], 'cut_threshold': params[2], 'valid_loss': loss})\n",
    "\n",
    "    # Select best performing configuration\n",
    "    best = min(valid_losses, key=lambda x: x['valid_loss'])\n",
    "\n",
    "    # Final refit with best config\n",
    "    print(f\"Refitting best model with {best}\")\n",
    "    if black_box_fitting:\n",
    "        gkan_symb, symb_g, symb_h, exec_time = fit_black_box_from_kan(\n",
    "            model_path=model_path_gkan,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            device=device,\n",
    "            theta=-np.inf,\n",
    "            pysr_model=lambda: get_pysr_model(\n",
    "                model_selection=best['model_selection'],\n",
    "                n_iterations=best['param'],\n",
    "                # parallelism=\"serial\",\n",
    "                # random_state = seed,\n",
    "                # deterministic = True\n",
    "            ),\n",
    "            sample_size=sample_size,\n",
    "            message_passing=False,\n",
    "            verbose=True,\n",
    "            include_time=False\n",
    "        )\n",
    "    else:\n",
    "        gkan_symb, symb_g, symb_h, exec_time = fit_model(\n",
    "            model_path=model_path_gkan,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            theta=best['theta'],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            sample_size=sample_size,\n",
    "            sort_by=best['sort_by'],\n",
    "            verbose=True,\n",
    "            cut_threshold=best[\"cut_threshold\"]\n",
    "        )\n",
    "\n",
    "    return gkan_symb, symb_g, symb_h, exec_time\n",
    "\n",
    "def post_process_gkan(\n",
    "    config,\n",
    "    model_path,\n",
    "    test_set,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    scaler=None,\n",
    "    inverse_scale=False,\n",
    "    adjoint=True,\n",
    "    eval_model=True,\n",
    "    res_file_name = 'post_process_res_seed_2.json'\n",
    "):\n",
    "\n",
    "    results_dict = {}\n",
    "\n",
    "    def print_symb_error(g_symb, h_symb, txt=\"symbolic formula\", is_symb=True):\n",
    "        try:\n",
    "            test_losses_symb = get_symb_test_error(\n",
    "                g_symb=g_symb,\n",
    "                h_symb=h_symb,\n",
    "                test_set=test_set,\n",
    "                message_passing=message_passing,\n",
    "                include_time=include_time,\n",
    "                atol=atol,\n",
    "                rtol=rtol,\n",
    "                method=method,\n",
    "                scaler=scaler,\n",
    "                inverse_scale=inverse_scale,\n",
    "                is_symb=is_symb\n",
    "            )\n",
    "\n",
    "            ts_mean = np.mean(test_losses_symb)\n",
    "            ts_var = np.var(test_losses_symb)\n",
    "            ts_std = np.std(test_losses_symb)\n",
    "\n",
    "            print(f\"Mean Test loss of {txt}: {ts_mean}\")\n",
    "            print(f\"Var Test loss of {txt}: {ts_var}\")\n",
    "            print(f\"Std Test loss of {txt}: {ts_std}\")\n",
    "\n",
    "            return ts_mean, ts_var, ts_std\n",
    "        except AssertionError:\n",
    "            print(\"Evaluation failed!\")\n",
    "            return np.inf, np.inf, np.inf\n",
    "\n",
    "\n",
    "    print(\"Black-Box fitting \\n\")\n",
    "    bb_symb, bb_g_symb, bb_h_symb, exec_time = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/gkan\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        black_box_fitting=True,\n",
    "        n_g_hidden_layers=n_g_hidden_layers,\n",
    "        n_h_hidden_layers=n_h_hidden_layers,\n",
    "        sample_size = sample_size\n",
    "    )\n",
    "\n",
    "    print(latex(quantise(bb_symb)))\n",
    "    ts_mean_bb, ts_var_bb, ts_std_bb = print_symb_error(g_symb=bb_g_symb, h_symb=bb_h_symb)\n",
    "\n",
    "    results_dict[\"black_box_symb_quant\"] = str(quantise(bb_symb))\n",
    "    results_dict[\"black_box_symb\"] = str(bb_symb)\n",
    "    results_dict[\"black_box_symb_test_MAE\"] = ts_mean_bb\n",
    "    results_dict[\"black_box_symb_test_Var\"] = ts_var_bb\n",
    "    results_dict[\"black_box_symb_test_Std\"] = ts_std_bb\n",
    "    results_dict[\"black_box_exec_time\"] = exec_time\n",
    "\n",
    "    print(\"Spline-wise fitting\\n\")\n",
    "    spline_symb, spl_g_symb, spl_h_symb, exec_time = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/gkan\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        black_box_fitting=False,\n",
    "        n_g_hidden_layers=n_g_hidden_layers,\n",
    "        n_h_hidden_layers=n_h_hidden_layers,\n",
    "        sample_size = sample_size\n",
    "    )\n",
    "    print(latex(quantise(spline_symb)))\n",
    "    ts_mean_sw, ts_var_sw, ts_std_sw = print_symb_error(g_symb=spl_g_symb, h_symb=spl_h_symb)\n",
    "\n",
    "    results_dict[\"spline_wise_symb_quant\"] = str(quantise(spline_symb))\n",
    "    results_dict[\"spline_wise_symb\"] = str(spline_symb)\n",
    "    results_dict[\"spline_wise_symb_test_MAE\"] = ts_mean_sw\n",
    "    results_dict[\"spline_wise_symb_test_Var\"] = ts_var_sw\n",
    "    results_dict[\"spline_wise_symb_test_Std\"] = ts_std_sw\n",
    "    results_dict[\"spline_wise_exec_time\"] = exec_time\n",
    "\n",
    "\n",
    "    if eval_model:\n",
    "        print(\"Evaluate raw model\\n\")\n",
    "        # Loading best model\n",
    "        best_model = build_model_from_file(\n",
    "            model_path=model_path,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            method=method,\n",
    "            adjoint=adjoint,\n",
    "            atol=atol,\n",
    "            rtol=rtol\n",
    "        )\n",
    "\n",
    "        tot_params = sum(p.numel() for p in best_model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of model's parameters: {tot_params}\\n\")\n",
    "        results_dict[\"Number of params\"] = tot_params\n",
    "\n",
    "        best_model = best_model.eval()\n",
    "        ts_mean_model, ts_var_model, ts_std_model = print_symb_error(\n",
    "            g_symb=best_model.conv.model.g_net,\n",
    "            h_symb=best_model.conv.model.h_net,\n",
    "            txt=\"best model\",\n",
    "            is_symb=False\n",
    "        )\n",
    "\n",
    "        results_dict[\"model_test_MAE\"] = ts_mean_model\n",
    "        results_dict[\"model_test_Var\"] = ts_var_model\n",
    "        results_dict[\"model_test_Std\"] = ts_std_model\n",
    "\n",
    "    with open(f\"{model_path}/{res_file_name}\", 'w') as file:\n",
    "        json.dump(results_dict, file, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, node_index = 0, save_path = None, show=True, title = None):\n",
    "    title_ = f'y_true vs y_pred for Node {node_index}' if title is None else title\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_true[:, node_index, :], label='y_true', marker='o')\n",
    "    plt.plot(y_pred[:, node_index, :], label='y_pred', marker='o')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(title_)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save_path is not None:\n",
    "        plt.savefig(f\"{save_path}/{title_}.png\")\n",
    "    plt.clf()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.3504788815528931e-05\n",
      "Var Test loss of symbolic formula: 1.314533673970284e-13\n",
      "Std Test loss of symbolic formula: 3.625649836884809e-07\n"
     ]
    }
   ],
   "source": [
    "kur_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_kuramoto.yml\")\n",
    "\n",
    "KUR = get_test_set(\n",
    "    dynamics=kur_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=kur_config['input_range'],\n",
    "    **kur_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: torch.sin(x[:, 1] - x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: 2.0 + 0.5 * x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=KUR,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.071706852447581e-06\n",
      "Var Test loss of symbolic formula: 8.008373820613663e-14\n",
      "Std Test loss of symbolic formula: 2.829907033917133e-07\n"
     ]
    }
   ],
   "source": [
    "epid_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_epidemics.yml\")\n",
    "\n",
    "EPID = get_test_set(\n",
    "    dynamics=epid_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=epid_config['input_range'],\n",
    "    **epid_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.5*x[:, 1].unsqueeze(-1) * (1 - x[:, 0].unsqueeze(-1))\n",
    "h_symb = lambda x: x[:, 1].unsqueeze(1) - 0.5 * x[:, 0].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=EPID,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 3.735399635237021e-06\n",
      "Var Test loss of symbolic formula: 4.746857081617248e-13\n",
      "Std Test loss of symbolic formula: 6.889743886108719e-07\n"
     ]
    }
   ],
   "source": [
    "pop_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "\n",
    "POP = get_test_set(\n",
    "    dynamics=pop_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=pop_config['input_range'],\n",
    "    **pop_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.2*torch.pow(x[:, 1].unsqueeze(-1), 3)\n",
    "h_symb = lambda x: -0.5 * x[:, 0].unsqueeze(-1) + x[:, 1].unsqueeze(1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=POP,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.2006473374034006e-06\n",
      "Var Test loss of symbolic formula: 7.184599599254429e-14\n",
      "Std Test loss of symbolic formula: 2.6804103415810103e-07\n"
     ]
    }
   ],
   "source": [
    "bio_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical.yml\")\n",
    "\n",
    "BIO = get_test_set(\n",
    "    dynamics=bio_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=bio_config['input_range'],\n",
    "    **bio_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: (-0.5*x[:, 1] * x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: (1.0 - 0.5 * x[:, 0]).unsqueeze(-1)  + x[:, 1].unsqueeze(-1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=BIO,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symb Reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.1\n",
      "0.001993336249142885\n",
      "Fitting symbolic model with score, theta 0.05 and cutting threshold 0.01\n",
      "0.00652295583859086\n",
      "Refitting best model with {'sort_by': 'score', 'theta': 0.05, 'cut_threshold': 0.1, 'valid_loss': 0.001993336249142885}\n",
      "Fitting G_Net...\n",
      "Execution time: 25.214420 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 25.262541 seconds\n"
     ]
    }
   ],
   "source": [
    "gkan_symb, symb_g, symb_h, exec_time = valid_symb_model(\n",
    "    config=bio_config,\n",
    "    model_path_gkan=\"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_12/0/gkan\",\n",
    "    black_box_fitting=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.508494135588087*x_i*x_j) - 0.470279293193828 x_{i} + 0.863921286348416$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.508494135588087*x_i*x_j) - 0.470279293193828*x_i + 0.863921286348416"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkan_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030083206792672474"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errs = get_symb_test_error(\n",
    "    g_symb=symb_g,\n",
    "    h_symb=symb_h,\n",
    "    test_set=BIO,\n",
    "    method=\"dopri5\"\n",
    ")\n",
    "\n",
    "np.mean(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}(-0.489932868169565*x_i*x_j) - 0.500074136830623 x_{i} + 0.999982393881022$"
      ],
      "text/plain": [
       "\\sum_{j}(-0.489932868169565*x_i*x_j) - 0.500074136830623*x_i + 0.999982393881022"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantise(gkan_symb, is_removing=True, quantise_to=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 200, 'valid_loss': 3.5928729630541056e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 378.959482 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 396.496495 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 3.348022073623724e-05\n",
      "Var Test loss of symbolic formula: 3.582176253189077e-12\n",
      "Std Test loss of symbolic formula: 1.8926637982454986e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.1, 'valid_loss': 0.010885930620133877}\n",
      "Fitting G_Net...\n",
      "Execution time: 74.244553 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 75.224952 seconds\n",
      "\\sum_{j}(-0.49*x_i*x_j + 0.01*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.012711185651520887\n",
      "Var Test loss of symbolic formula: 1.29827414785014e-06\n",
      "Std Test loss of symbolic formula: 0.0011394183375082832\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 280\n",
      "\n",
      "Mean Test loss of best model: 3.5243151918014824e-05\n",
      "Var Test loss of best model: 1.9390872521645346e-11\n",
      "Std Test loss of best model: 4.403506843601512e-06\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=30000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=bio_config,\n",
    "        model_path=model_path,\n",
    "        test_set=BIO,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.0003746134461835027}\n",
      "Fitting G_Net...\n",
      "Execution time: 323.229594 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 242.008611 seconds\n",
      "\\sum_{j}(-0.5*sin(x_i - x_j)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.00036657551148285467\n",
      "Var Test loss of symbolic formula: 8.553815375056577e-11\n",
      "Std Test loss of symbolic formula: 9.248683892887991e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.05, 'valid_loss': 0.0020373703446239233}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 6.862384 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 3.786572 seconds\n",
      "\\sum_{j}(-0.5*sin(-1.0*x_i + 1.0*x_j + 3.14)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.0022981326716641584\n",
      "Var Test loss of symbolic formula: 2.0925475252424754e-09\n",
      "Std Test loss of symbolic formula: 4.574437151434562e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 543\n",
      "\n",
      "Mean Test loss of best model: 0.0016123395568380754\n",
      "Var Test loss of best model: 6.192426841147661e-07\n",
      "Std Test loss of best model: 0.0007869197443925054\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.007145709823817015}\n",
      "Fitting G_Net...\n",
      "Execution time: 19.059034 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 23.521774 seconds\n",
      "\\sum_{j}(-0.49*sin(x_i - x_j)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.007131052669137716\n",
      "Var Test loss of symbolic formula: 6.036935300456649e-08\n",
      "Std Test loss of symbolic formula: 0.0002457017562097725\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.03981337323784828}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 5.850058 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.572098 seconds\n",
      "\\sum_{j}(-0.49*sin(1.0*x_i - 1.01*x_j + 0.1)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.03392164781689644\n",
      "Var Test loss of symbolic formula: 4.0513348818336605e-05\n",
      "Std Test loss of symbolic formula: 0.006365009726491909\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 200, 'valid_loss': 0.05628015473484993}\n",
      "Fitting G_Net...\n",
      "Execution time: 33.167968 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 42.545120 seconds\n",
      "\\sum_{j}(-0.4*sin(x_i - x_j)) - 0.2 \\sin{\\left(x_{i} \\right)} + 1.94\n",
      "Mean Test loss of symbolic formula: 0.10963946580886841\n",
      "Var Test loss of symbolic formula: 0.00019089434142775344\n",
      "Std Test loss of symbolic formula: 0.013816451839302066\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.08241403847932816}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 9.635976 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 22.507003 seconds\n",
      "\\sum_{j}(0.01 - 0.43*sin(-0.01*x_i**3 + 0.12*x_i**2 + 0.53*x_i + 5.72*sin(0.17*x_j + 2.53) - 2.83)) + 0.01 x_{i} + 0.03 \\left(\\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 0.66\\right)^{3} - 0.07 \\left(\\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 0.66\\right)^{2} + 0.14 \\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 2.15\n",
      "Mean Test loss of symbolic formula: 0.093520092467467\n",
      "Var Test loss of symbolic formula: 2.8339800094176776e-06\n",
      "Std Test loss of symbolic formula: 0.0016834429035217314\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 1.091734766960144}\n",
      "Fitting G_Net...\n",
      "Execution time: 16.390624 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.564453 seconds\n",
      "\\sum_{j}(-tanh(249.46/(x_i**3*x_j**3))) + e^{3 \\sin{\\left(1.74 x_{i} \\right)}}\n",
      "Mean Test loss of symbolic formula: 1.2062313159306843\n",
      "Var Test loss of symbolic formula: 2.1666894396174835e-06\n",
      "Std Test loss of symbolic formula: 0.001471967879954411\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.05, 'valid_loss': 0.943835973739624}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting G_Net...\n",
      "Execution time: 0.000438 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.622671 seconds\n",
      "\\sum_{j}(0) - 5.15 x_{i} - 0.12 \\left(x_{i} + 0.27\\right)^{3} + 1.42 \\left(x_{i} + 0.27\\right)^{2} - 7.61 \\sin{\\left(0.8 x_{i} - 2.19 \\right)} + 2.75 \\cos{\\left(0.88 x_{i} + 1.23 \\right)} - 13.32 \\cos{\\left(5.35 \\cos{\\left(1.85 x_{i} - 4.54 \\right)} - 2.88 \\right)} + 6.57\n",
      "Mean Test loss of symbolic formula: 1.010321815808614\n",
      "Var Test loss of symbolic formula: 5.027089721289081e-05\n",
      "Std Test loss of symbolic formula: 0.007090197261916682\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=kur_config,\n",
    "        model_path=model_path,\n",
    "        test_set=KUR,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.004705215338617563}\n",
      "Fitting G_Net...\n",
      "Execution time: 142.798720 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 136.536802 seconds\n",
      "\\sum_{j}(-0.43*x_j*tanh(log(x_i))) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.0044106861265997095\n",
      "Var Test loss of symbolic formula: 1.79265202105441e-07\n",
      "Std Test loss of symbolic formula: 0.00042339721551451064\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.05, 'valid_loss': 0.001111256773583591}\n",
      "Fitting G_Net...\n",
      "Execution time: 28.117509 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.241807 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j + 0.5*x_j) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.0011450907525916894\n",
      "Var Test loss of symbolic formula: 2.1243228087464114e-09\n",
      "Std Test loss of symbolic formula: 4.60903765307511e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 264\n",
      "\n",
      "Mean Test loss of best model: 0.00019421373629787317\n",
      "Var Test loss of best model: 9.034108544048775e-11\n",
      "Std Test loss of best model: 9.50479276157496e-06\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.002244098810479045}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.355172 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.227076 seconds\n",
      "\\sum_{j}(x_j*(0.51 - 0.51*x_i)) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.002354982541874051\n",
      "Var Test loss of symbolic formula: 1.0752977480680034e-07\n",
      "Std Test loss of symbolic formula: 0.0003279173292261334\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.1, 'valid_loss': 0.014380019158124924}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 31.594218 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.871257 seconds\n",
      "\\sum_{j}(-0.46*x_i*x_j + 0.47*x_j) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.01322010283668836\n",
      "Var Test loss of symbolic formula: 2.6293119423887207e-06\n",
      "Std Test loss of symbolic formula: 0.0016215153228966788\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 450\n",
      "\n",
      "Mean Test loss of best model: 0.0020562036661431193\n",
      "Var Test loss of best model: 8.05423553676876e-08\n",
      "Std Test loss of best model: 0.0002837998508944069\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.028511973097920418}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.184228 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.947385 seconds\n",
      "\\sum_{j}(-0.18*log(x_i)) - 0.14\n",
      "Mean Test loss of symbolic formula: 0.02964874605337779\n",
      "Var Test loss of symbolic formula: 6.506173588601313e-06\n",
      "Std Test loss of symbolic formula: 0.002550720209784153\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.1, 'valid_loss': 0.03664926439523697}\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.217886 seconds\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.446302 seconds\n",
      "\\sum_{j}(0.34*tanh(0.55*x_j + 0.54*cos(2.73*x_i + 0.1) - 0.99) + 0.29) - 0.13\n",
      "Mean Test loss of symbolic formula: 0.03262868461509546\n",
      "Var Test loss of symbolic formula: 1.766416481109898e-06\n",
      "Std Test loss of symbolic formula: 0.0013290660183414133\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 352\n",
      "\n",
      "Mean Test loss of best model: 0.0261530801653862\n",
      "Var Test loss of best model: 1.459289080037405e-05\n",
      "Std Test loss of best model: 0.003820064240346496\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.07408930361270905}\n",
      "Fitting G_Net...\n",
      "Execution time: 17.210457 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.634566 seconds\n",
      "\\sum_{j}(0.01 - 0.01*x_j) - x_{i} + 0.77\n",
      "Mean Test loss of symbolic formula: 0.07820665091276169\n",
      "Var Test loss of symbolic formula: 1.0264305971507959e-05\n",
      "Std Test loss of symbolic formula: 0.0032037955570710123\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.10667437314987183}\n",
      "Fitting G_Net...\n",
      "Execution time: 12.127377 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.694168 seconds\n",
      "\\sum_{j}(0.0) - 1.09 \\tanh{\\left(88.88 x_{i} - 39.68 \\right)} + 0.17 \\tanh{\\left(78.19 \\sin{\\left(10.47 x_{i} - 5.14 \\right)} - 24.73 \\right)} + 0.9 \\tanh{\\left(18.53 \\tanh{\\left(9.74 x_{i} - 4.92 \\right)} + 25.3 \\right)} + 0.09\n",
      "Mean Test loss of symbolic formula: 0.10957680145899455\n",
      "Var Test loss of symbolic formula: 1.52982685459355e-05\n",
      "Std Test loss of symbolic formula: 0.003911300109418286\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 174\n",
      "\n",
      "Mean Test loss of best model: 0.1770920753479004\n",
      "Var Test loss of best model: 9.097893966740027e-05\n",
      "Std Test loss of best model: 0.00953828808892876\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=epid_config,\n",
    "        model_path=model_path,\n",
    "        test_set=EPID,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 1.849106229201425e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 120.688627 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 122.181040 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 1.736202830215916e-05\n",
      "Var Test loss of symbolic formula: 2.4071344014470957e-12\n",
      "Std Test loss of symbolic formula: 1.5514942479581083e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.1, 'valid_loss': 0.006122897379100323}\n",
      "Fitting G_Net...\n",
      "Execution time: 7.997768 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.128457 seconds\n",
      "\\sum_{j}(0.15*x_j**3 + 0.01*x_j**2 + 0.02*x_j) - 0.29 x_{i} - 0.17 \\tanh{\\left(1.43 x_{i} - 0.08 \\right)} - 0.01\n",
      "Mean Test loss of symbolic formula: 0.00505456468090415\n",
      "Var Test loss of symbolic formula: 6.284438436063126e-07\n",
      "Std Test loss of symbolic formula: 0.0007927445008363745\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 294\n",
      "\n",
      "Mean Test loss of best model: 0.0002619840282325943\n",
      "Var Test loss of best model: 2.153077690853207e-09\n",
      "Std Test loss of best model: 4.6401268203069696e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=pop_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=POP,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 9.614797454560176e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.817188 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 12.326990 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 8.774545131018385e-05\n",
      "Var Test loss of symbolic formula: 1.0301099316333908e-11\n",
      "Std Test loss of symbolic formula: 3.2095325697574573e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.029043128713965416}\n",
      "Fitting G_Net...\n",
      "Execution time: 39.032847 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.293388 seconds\n",
      "\\sum_{j}(0.02*x_i + 0.02*x_j + 0.04*tan(1.09*x_j - 0.03)) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.022732293233275414\n",
      "Var Test loss of symbolic formula: 3.847226371665735e-06\n",
      "Std Test loss of symbolic formula: 0.0019614347737474565\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 200, 'valid_loss': 0.006987582426518202}\n",
      "Fitting G_Net...\n",
      "Execution time: 31.783805 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 32.497264 seconds\n",
      "\\sum_{j}(0.18*x_j**3) - 0.46 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.006857929440836112\n",
      "Var Test loss of symbolic formula: 1.6288278926204385e-08\n",
      "Std Test loss of symbolic formula: 0.0001276255418253117\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.1, 'valid_loss': 0.03565327823162079}\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.319274 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 7.642629 seconds\n",
      "\\sum_{j}(0.08*x_j**3 + 0.01*x_j + (-0.13*x_j - 0.02)*(-0.03*sin(4.06*x_i + 0.04) - 0.2) - 0.01*sin(4.61*x_j - 0.08) - 0.06*cos(1.07*x_i + 0.79) + 0.13) - 1.46 + 1.45 e^{- 0.32 x_{i}}\n",
      "Mean Test loss of symbolic formula: 0.03091899926463763\n",
      "Var Test loss of symbolic formula: 5.5005617849095895e-06\n",
      "Std Test loss of symbolic formula: 0.00234532764979855\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 200, 'valid_loss': 0.013373607769608498}\n",
      "Fitting G_Net...\n",
      "Execution time: 30.462442 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 32.738222 seconds\n",
      "\\sum_{j}(0.17*x_j**3) - 0.49 x_{i} + 0.04\n",
      "Mean Test loss of symbolic formula: 0.019687574977676075\n",
      "Var Test loss of symbolic formula: 1.8448933954055678e-06\n",
      "Std Test loss of symbolic formula: 0.0013582685284602481\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.027769051492214203}\n",
      "Fitting G_Net...\n",
      "Execution time: 40.509048 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.146392 seconds\n",
      "\\sum_{j}(0.1*x_j**3 + 0.02*x_j**2 + 0.01*x_j - (0.03 - 0.06*tanh(27.26*x_i + 5.78))*(0.2*tanh(22.95*x_j - 0.48) - 0.11) - 0.02*(-0.27*sin(11.13*x_i - 2.52) - 0.09)*tan(1.62*x_j - 0.03) - 0.01) - 0.77 e^{0.35 \\sin{\\left(1.8 x_{i} \\right)} - 0.15 \\cos{\\left(1.8 x_{i} \\right)}} - 0.19 \\tanh{\\left(55.42 x_{i}^{3} - 12.05 x_{i}^{2} - 16.17 x_{i} + 7.26 \\right)} + 0.9\n",
      "Mean Test loss of symbolic formula: 0.02136990676323573\n",
      "Var Test loss of symbolic formula: 5.238051046089426e-06\n",
      "Std Test loss of symbolic formula: 0.002288678886626393\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=pop_config,\n",
    "        model_path=model_path,\n",
    "        test_set=POP,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Epid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_7/0/gkan\"\n",
    "\n",
    "pysr_model = lambda : get_pysr_model(\n",
    "    model_selection=\"score\",\n",
    "    n_iterations=200,\n",
    "    # parallelism=\"serial\",\n",
    "    # random_state = 9999,\n",
    "    # deterministic = True\n",
    ")\n",
    "\n",
    "gkan_symb, symb_g, symb_h, _ = fit_black_box_from_kan(\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    device='cuda',\n",
    "    model_path=model_path_gkan,\n",
    "    pysr_model=pysr_model,\n",
    "    sample_size=10000,\n",
    "    theta=-np.inf,\n",
    "    message_passing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682086 x_{i} + 2.464881$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.0039747115*exp(x_j)) + 2.4682086*x_i + 2.464881"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkan_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 7.077224 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.175794 seconds\n"
     ]
    }
   ],
   "source": [
    "symb_spline_wise, symb_g, symb_h, _ = fit_model(\n",
    "    n_h_hidden_layers=2,\n",
    "    n_g_hidden_layers=2,\n",
    "    model_path=model_path_gkan,\n",
    "    theta=0.01,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    sample_size=10000,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.734895858293764*x_j + 0.293098046040671*tan(1.08013667842532*x_i - 0.307758658490417) + 0.918070793094396) - 0.210703732000016 x_{i}^{2} + 0.26532895215655 x_{i} + 0.193819499686228 \\sin{\\left(1.39972138127477 x_{i} + 0.993201792200657 \\right)} - 0.151060103104457 \\sin{\\left(1.69361297349879 x_{i} - 2.19262255466617 \\right)} + 1.43397372117079 \\tanh{\\left(0.911212859558583 x_{i} + 1.12345719382021 \\right)} + 0.581497308844642 \\tanh{\\left(1.89188538790207 x_{i} + 1.08390065558438 \\right)} + 0.724311113723967$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.734895858293764*x_j + 0.293098046040671*tan(1.08013667842532*x_i - 0.307758658490417) + 0.918070793094396) - 0.210703732000016*x_i**2 + 0.26532895215655*x_i + 0.193819499686228*sin(1.39972138127477*x_i + 0.993201792200657) - 0.151060103104457*sin(1.69361297349879*x_i - 2.19262255466617) + 1.43397372117079*tanh(0.911212859558583*x_i + 1.12345719382021) + 0.581497308844642*tanh(1.89188538790207*x_i + 1.08390065558438) + 0.724311113723967"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symb_spline_wise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSS Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tss_test_error(\n",
    "    text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h,\n",
    "    row_means,\n",
    "    test_set,\n",
    "    result_dict,\n",
    "    suffix = '',\n",
    "    method = \"dopri5\"\n",
    "):\n",
    "    g_symb = sp.S(0)\n",
    "    h_symb = sp.S(0)\n",
    "\n",
    "    \n",
    "    for symb_g in text_sympy_mapping_g.keys():\n",
    "        g_symb += row_means[symb_g] * text_sympy_mapping_g[symb_g]\n",
    "    for symb_h in text_sympy_mapping_h.keys():\n",
    "        h_symb += row_means[symb_h] * text_sympy_mapping_h[symb_h]\n",
    "\n",
    "\n",
    "    try:\n",
    "        test_losses = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=test_set,\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=1e-5,\n",
    "            rtol=1e-5,\n",
    "            is_symb=True\n",
    "        )\n",
    "\n",
    "        ts_mean = np.mean(test_losses)\n",
    "        ts_var = np.var(test_losses)\n",
    "        ts_std = np.std(test_losses)\n",
    "\n",
    "        print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "        print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "        print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "        \n",
    "        result_dict[f'tss_test_mae_{suffix}'] = ts_mean\n",
    "        result_dict[f'tss_test_var_{suffix}'] = ts_var\n",
    "        result_dict[f'tss_test_std_{suffix}'] = ts_std\n",
    "        \n",
    "    except AssertionError:\n",
    "        print(\"Evaluation failed !\")\n",
    "        result_dict[f'error_{suffix}'] = 'Evaluation failed !'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.499493\n",
       "constant          1.999953\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.00029352688579820096\n",
      "Var Test loss of symbolic formula: 3.5376970948757734e-10\n",
      "Std Test loss of symbolic formula: 1.8808766825275316e-05\n"
     ]
    }
   ],
   "source": [
    "results_kur = {}\n",
    "\n",
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.496334\n",
       "constant          1.999508\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0022176874335855246\n",
      "Var Test loss of symbolic formula: 2.1959006026397478e-08\n",
      "Std Test loss of symbolic formula: 0.00014818571465022355\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "tanx1             0.124221\n",
       "sinx1jMinusx1i    1.726642\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sinx1jMinusx1i'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'sinx1jMinusx1i'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m text_sympy_mapping_g = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msinx1jMinusx1i\u001b[39m\u001b[33m\"\u001b[39m: sp.sin(x_j - x_i)\n\u001b[32m      3\u001b[39m }\n\u001b[32m      4\u001b[39m text_sympy_mapping_h = {\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfracx1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m/ x_i\n\u001b[32m      6\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mget_tss_test_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_sympy_mapping_g\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_sympy_mapping_g\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_sympy_mapping_h\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_sympy_mapping_h\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_means\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow_means\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mKUR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresult_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults_kur\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m50db\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrk4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mget_tss_test_error\u001b[39m\u001b[34m(text_sympy_mapping_g, text_sympy_mapping_h, row_means, test_set, result_dict, suffix, method)\u001b[39m\n\u001b[32m     11\u001b[39m h_symb = sp.S(\u001b[32m0\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symb_g \u001b[38;5;129;01min\u001b[39;00m text_sympy_mapping_g.keys():\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     g_symb += \u001b[43mrow_means\u001b[49m\u001b[43m[\u001b[49m\u001b[43msymb_g\u001b[49m\u001b[43m]\u001b[49m * text_sympy_mapping_g[symb_g]\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m symb_h \u001b[38;5;129;01min\u001b[39;00m text_sympy_mapping_h.keys():\n\u001b[32m     17\u001b[39m     h_symb += row_means[symb_h] * text_sympy_mapping_h[symb_h]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'sinx1jMinusx1i'"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"fracx1\": 1/ x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='50db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1isinx1j        -0.219394\n",
       "expx1j            0.000837\n",
       "expx1jMinusx1i    0.005539\n",
       "x1iexpx1j        -0.000017\n",
       "x1x1x1           -0.009088\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.1444729765256245\n",
      "Var Test loss of symbolic formula: 0.04497167930929022\n",
      "Std Test loss of symbolic formula: 0.2120652713418447\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1iexpx1j\": x_i * sp.exp(x_j),\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i),\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR,\n",
    "    result_dict=results_kur,\n",
    "    suffix='20db',\n",
    "    method=\"rk4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Kuramoto-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_kur, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "constant         -1.479146\n",
       "expx1jMinusx1i    0.310919\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "results_epid = {}\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.1389921804269155\n",
      "Var Test loss of symbolic formula: 0.0011203295548231197\n",
      "Std Test loss of symbolic formula: 0.03347132436613645\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1x1x1     -1.319998\n",
       "constant    0.645621\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.06229652216037115\n",
      "Var Test loss of symbolic formula: 6.141598915836926e-05\n",
      "Std Test loss of symbolic formula: 0.007836835404573026\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i,\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.049246\n",
       "expx1jMinusx1i    0.101428\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.021874661867817242\n",
      "Var Test loss of symbolic formula: 4.867867802186041e-06\n",
      "Std Test loss of symbolic formula: 0.0022063245006539813\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "fracx1ix1j         0.009380\n",
       "x1ifracx1j         0.009147\n",
       "fracx1j            0.000166\n",
       "fracx1jMinusx1i    0.000093\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.11685330420732498\n",
      "Var Test loss of symbolic formula: 8.636679188082455e-06\n",
      "Std Test loss of symbolic formula: 0.002938822755472411\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1j\": 1 / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID,\n",
    "    result_dict=results_epid,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Epidemics-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_epid, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.588793\n",
       "constant    0.791612\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03011361074944337\n",
      "Var Test loss of symbolic formula: 7.856473251973632e-07\n",
      "Std Test loss of symbolic formula: 0.0008863674887975998\n"
     ]
    }
   ],
   "source": [
    "results_bio = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.702419\n",
       "constant    0.891260\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.033047826339801155\n",
      "Var Test loss of symbolic formula: 1.5884390903935722e-06\n",
      "Std Test loss of symbolic formula: 0.0012603329283937528\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "x1x1     -1.690969\n",
       "x1ix1j    0.935806\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation failed !\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "fracx1ix1j         0.000972\n",
       "x1ifracx1j         0.000006\n",
       "fracx1jMinusx1i    0.000711\n",
       "dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation failed !\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO,\n",
    "    result_dict=results_bio,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Biochemical-1/post_process_res.json\", 'w') as file:\n",
    "    json.dump(results_bio, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.026403\n",
       "x1j         0.181286\n",
       "sinx1j     -0.003445\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.12766799330711365\n",
      "Var Test loss of symbolic formula: 7.629820227054533e-05\n",
      "Std Test loss of symbolic formula: 0.00873488421620718\n"
     ]
    }
   ],
   "source": [
    "results_pop = {}\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.008463\n",
       "x1j         0.049181\n",
       "sinx1j      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0984332486987114\n",
      "Var Test loss of symbolic formula: 9.581733575569906e-06\n",
      "Std Test loss of symbolic formula: 0.0030954375418622013\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='70db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "sinx1j   -0.437936\n",
       "x1j       0.447304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.09804610659678777\n",
      "Var Test loss of symbolic formula: 6.87397651082882e-06\n",
      "Std Test loss of symbolic formula: 0.0026218269414339346\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='50db'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN      0.000000\n",
       "sinx1   -0.395957\n",
       "x1x1     0.306063\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.049917796005805336\n",
      "Var Test loss of symbolic formula: 6.379734967220602e-06\n",
      "Std Test loss of symbolic formula: 0.0025258137237770726\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"sinx1\": sp.sin(x_i),\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP,\n",
    "    result_dict=results_pop,\n",
    "    suffix='20db'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./saved_models_optuna/tss/Population-1/post_process_res.json\", 'w') as file:\n",
    "        json.dump(results_pop, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
