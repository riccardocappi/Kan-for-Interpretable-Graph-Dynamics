{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics\n",
    "\n",
    "Dynamics | $\\partial_{\\tau}x_i=$ |\n",
    "| :--------: | :-------: |\n",
    "Biochemical | $F -B x_i - R \\sum_j A_{ij} x_i x_j$ |\n",
    "Epidemics | $-B x_i + R \\sum_j A_{ij} (1-x_i)x_j$ |\n",
    "Population | $-B x_i^{b} + R \\sum_j A_{ij} x_j^a$ |\n",
    "Synchronization | $\\omega_i + R \\sum_j A_{ij} \\sin(x_j-x_i)$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from experiments.experiments_gkan import ExperimentsGKAN\n",
    "from experiments.experiments_mpnn import ExperimentsMPNN\n",
    "from train_and_eval import eval_model\n",
    "import sympytorch\n",
    "\n",
    "storage = JournalStorage(JournalFileBackend(\"optuna_journal_storage.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_pytorch_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "set_pytorch_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_real_epid_mpnn.yml\")\n",
    "# config['patience'] = 450\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config,\n",
    "#     n_trials=3,\n",
    "#     study_name=\"test_mult_2\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "# # config['t_span'] = [0, 1]\n",
    "# exp = ExperimentsGKAN(\n",
    "#     config=config,\n",
    "#     n_trials=1,\n",
    "#     study_name=\"test_mult_10\",\n",
    "#     snr_db=20\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 30, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_pop = load_config(\"./configs/config_pred_deriv/config_ic1/config_population_mpnn.yml\")\n",
    "# # config_pop[\"t_eval_steps\"] = 1000\n",
    "# # config_pop[\"t_span\"] = [0, 10]\n",
    "\n",
    "# exp = ExperimentsMPNN(\n",
    "#     config=config_pop,\n",
    "#     n_trials=1,\n",
    "#     study_name='test_mult_3'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = exp.training_set.raw_data_sampled[0].detach().cpu().numpy()\n",
    "# plt.plot(data[:, 6, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.training_set.raw_data_sampled.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.epochs = 10\n",
    "# exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.MPNN import MPNN\n",
    "from models.baseline.MPNN_ODE import MPNN_ODE\n",
    "from train_and_eval import eval_model\n",
    "from datasets.SyntheticData import SyntheticData\n",
    "from sympy import symbols, sin, summation, simplify\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from utils.utils import integrate\n",
    "from torch_geometric.data import Data\n",
    "from models.kan.KAN import KAN\n",
    "from models.GKAN_ODE import GKAN_ODE\n",
    "\n",
    "import optuna\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import latex\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_model(g, h, message_passing=True, include_time=False, atol=1e-5, rtol=1e-5, integration_method = 'scipy_solver'):\n",
    "    conv = MPNN(\n",
    "        g_net = g,\n",
    "        h_net = h, \n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "    \n",
    "    symb = MPNN_ODE(\n",
    "        conv=conv,\n",
    "        model_path=\"./saved_models_optuna/tmp_symb\",\n",
    "        adjoint=True,\n",
    "        integration_method=integration_method,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "    \n",
    "    symb = symb.eval()\n",
    "    return symb\n",
    "\n",
    "\n",
    "def make_callable(expr):\n",
    "    free_syms = expr.free_symbols\n",
    "    if not free_syms:\n",
    "        # Expression is constant\n",
    "        const_value = float(expr)\n",
    "        return lambda x: torch.full((x.shape[0], 1), const_value, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    sym_module = sympytorch.SymPyModule(expressions=[expr])\n",
    "    syms = {str(s) for s in free_syms}\n",
    "    if {'x_i', 'x_j'} <= syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0], x_j=x[:, 1])\n",
    "    elif 'x_i' in syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0])\n",
    "    elif 'x_j' in syms:\n",
    "        return lambda x: sym_module(x_j=x[:, 1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected symbols in expression: {free_syms}\")\n",
    "\n",
    "\n",
    "def get_symb_test_error(g_symb, h_symb, test_set, message_passing=False, include_time=False, atol=1e-5, rtol=1e-5, scaler = None, inverse_scale=False, method='scipy_solver', \n",
    "                        is_symb = True):\n",
    "    \n",
    "    if is_symb:\n",
    "        if isinstance(g_symb, int):\n",
    "            g_symb = sp.sympify(g_symb)\n",
    "            \n",
    "        if isinstance(h_symb, int):\n",
    "            h_symb = sp.sympify(h_symb)\n",
    "\n",
    "        g_symb = make_callable(g_symb)\n",
    "        h_symb = make_callable(h_symb)\n",
    "    \n",
    "    test_losses = []\n",
    "    \n",
    "    for ts in test_set:\n",
    "        symb = get_model(\n",
    "            g=g_symb,\n",
    "            h=h_symb,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            integration_method=method\n",
    "        )\n",
    "        \n",
    "        collate_fn = lambda samples_list: samples_list\n",
    "        test_loader = DataLoader(ts, batch_size=len(ts), shuffle=True, collate_fn=collate_fn)\n",
    "        \n",
    "        test_loss = eval_model(\n",
    "            model=symb,\n",
    "            valid_loader=test_loader,\n",
    "            criterion=torch.nn.L1Loss(),\n",
    "            scaler=scaler,\n",
    "            inverse_scale=inverse_scale,\n",
    "            pred_deriv=False\n",
    "        )\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    return test_losses\n",
    "\n",
    "\n",
    "\n",
    "def get_test_set(dynamics, device='cuda', input_range=(0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    seeds = [12345, 67890, 111213]\n",
    "    \n",
    "    graphs = [\n",
    "        nx.barabasi_albert_graph(70, 3, seed=seeds[0]),      \n",
    "        nx.watts_strogatz_graph(50, 6, 0.3, seed=seeds[1]),  \n",
    "        nx.erdos_renyi_graph(100, 0.05, seed=seeds[2])        \n",
    "    ]\n",
    "    \n",
    "    test_set = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        snapshots = integrate_test_set(\n",
    "            graph=graph,\n",
    "            dynamics=dynamics,\n",
    "            seed=seeds[i],\n",
    "            device=device,\n",
    "            input_range=input_range,\n",
    "            t_span=t_span,\n",
    "            **integration_kwargs\n",
    "        )\n",
    "        test_set.append(snapshots)\n",
    "    \n",
    "    return test_set\n",
    "    \n",
    "\n",
    "\n",
    "def integrate_test_set(graph, dynamics, seed=12345, device='cuda', input_range = (0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    # graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "    edge_index = from_networkx(graph).edge_index\n",
    "    edge_index = edge_index.to(torch.device(device))\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    \n",
    "    data, t = integrate(\n",
    "        input_range=input_range,\n",
    "        t_span = t_span,\n",
    "        t_eval_steps=1000,\n",
    "        dynamics=dynamics,\n",
    "        device=device,\n",
    "        graph=graph,\n",
    "        rng = rng,\n",
    "        **integration_kwargs\n",
    "    )\n",
    "    \n",
    "    snapshot = Data(\n",
    "        x = data[0].unsqueeze(0),\n",
    "        y = data[1:],\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=None,\n",
    "        t_span = t\n",
    "    )\n",
    "    \n",
    "    return [snapshot]\n",
    "\n",
    "\n",
    "def build_model_from_file(model_path, message_passing, include_time, method='dopri5', adjoint=False, atol=1e-5, rtol=1e-5):\n",
    "    best_params_file = f\"{model_path}/best_params.json\"\n",
    "    best_state_path = f\"{model_path}/gkan/state_dict.pth\"\n",
    "    \n",
    "    with open(best_params_file, 'r') as f:\n",
    "        best_hyperparams = json.load(f)\n",
    "    \n",
    "    # g_net\n",
    "    g_net = KAN(\n",
    "        layers_hidden=[2, best_hyperparams['hidden_dim_g_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_g_net'],\n",
    "        spline_order=best_hyperparams['spline_order_g_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_g_net'], best_hyperparams['range_limit_g_net']],\n",
    "        mu_1=best_hyperparams['mu_1_g_net'],\n",
    "        mu_2=best_hyperparams['mu_2_g_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=True,\n",
    "        store_act=True\n",
    "    )\n",
    "    \n",
    "    time_dim = 1 if include_time else 0\n",
    "    in_dim_h = 2 if message_passing else 1\n",
    "    in_dim_h += time_dim\n",
    "    \n",
    "    # h_net\n",
    "    h_net = KAN(\n",
    "        layers_hidden=[in_dim_h, best_hyperparams['hidden_dim_h_net'], 1],\n",
    "        grid_size=best_hyperparams['grid_size_h_net'],\n",
    "        spline_order=best_hyperparams['spline_order_h_net'],\n",
    "        grid_range=[-best_hyperparams['range_limit_h_net'], best_hyperparams['range_limit_h_net']],\n",
    "        mu_1=best_hyperparams['mu_1_h_net'],\n",
    "        mu_2=best_hyperparams['mu_2_h_net'],\n",
    "        device='cuda',\n",
    "        compute_mult=True,\n",
    "        store_act=True\n",
    "    )\n",
    "    \n",
    "    gkan = MPNN(\n",
    "        h_net=h_net,\n",
    "        g_net=g_net,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "    \n",
    "    model = GKAN_ODE(\n",
    "        conv=gkan,\n",
    "        model_path='./saved_models_optuna/tmp',\n",
    "        lmbd_g=best_hyperparams['lamb_g_net'],\n",
    "        lmbd_h=best_hyperparams['lamb_h_net'],\n",
    "        integration_method=method,\n",
    "        adjoint=adjoint,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "    \n",
    "    model = model.to(torch.device('cuda'))\n",
    "    model.load_state_dict(torch.load(best_state_path, weights_only=False, map_location=torch.device('cuda')))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def valid_symb_model(\n",
    "    config,\n",
    "    model_path_gkan,\n",
    "    device='cuda',\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    black_box_fitting=True,\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000\n",
    "):\n",
    "    \n",
    "    seed = 9999\n",
    "    graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "\n",
    "    # Prepare validation/test set\n",
    "    valid_set = integrate_test_set(\n",
    "        graph=graph,\n",
    "        dynamics=config['name'],\n",
    "        seed=seed,\n",
    "        device=device,\n",
    "        input_range=config['input_range'],\n",
    "        t_span=(0, 1),\n",
    "        **config['integration_kwargs']\n",
    "    )\n",
    "\n",
    "    # Helper to compute validation loss\n",
    "    def evaluate_model(g_symb, h_symb, is_symb=True):\n",
    "        errs = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=[valid_set],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            is_symb=is_symb\n",
    "        )\n",
    "        return errs[0]\n",
    "\n",
    "    # Helper to fit model for current config\n",
    "    def fit_single_model(param1, param2):\n",
    "        if black_box_fitting:\n",
    "            print(f\"Fitting black-box model with {param1} and {param2} iterations\")\n",
    "            pysr_model = lambda: get_pysr_model(model_selection=param1, n_iterations=param2)\n",
    "            _, g_symb, h_symb = fit_black_box_from_kan(\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                device=device,\n",
    "                model_path=model_path_gkan,\n",
    "                pysr_model=pysr_model,\n",
    "                sample_size=sample_size,\n",
    "                theta=-np.inf,\n",
    "                message_passing=False,\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Fitting symbolic model with {param1} and theta {param2}\")\n",
    "            _, g_symb, h_symb = fit_model(\n",
    "                n_g_hidden_layers=n_g_hidden_layers,\n",
    "                n_h_hidden_layers=n_h_hidden_layers,\n",
    "                model_path=model_path_gkan,\n",
    "                theta=param2,\n",
    "                message_passing=False,\n",
    "                include_time=False,\n",
    "                sample_size=sample_size,\n",
    "                sort_by=param1,\n",
    "                verbose=False\n",
    "            )\n",
    "        return g_symb, h_symb\n",
    "\n",
    "    # Define parameter grid\n",
    "    param_grid = (\n",
    "        ([\"score\", \"accuracy\"], [50, 100, 200]) if black_box_fitting\n",
    "        else ([\"score\", \"log_loss\"], [0.01, 0.05, 0.1])\n",
    "    )\n",
    "\n",
    "    search_space = [(mod, val) for mod in param_grid[0] for val in param_grid[1]]\n",
    "    valid_losses = []\n",
    "\n",
    "    for mod, val in search_space:\n",
    "        g_symb, h_symb = fit_single_model(mod, val)\n",
    "        try:\n",
    "            loss = evaluate_model(g_symb, h_symb)\n",
    "        except AssertionError:\n",
    "            loss = 1e8\n",
    "        valid_losses.append({'model_selection': mod, 'param': val, 'valid_loss': loss})\n",
    "\n",
    "    # Select best performing configuration\n",
    "    best = min(valid_losses, key=lambda x: x['valid_loss'])\n",
    "\n",
    "    # Final refit with best config\n",
    "    print(f\"Refitting best model with {best}\")\n",
    "    if black_box_fitting:\n",
    "        gkan_symb, symb_g, symb_h = fit_black_box_from_kan(\n",
    "            model_path=model_path_gkan,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            device=device,\n",
    "            theta=-np.inf,\n",
    "            pysr_model=lambda: get_pysr_model(\n",
    "                model_selection=best['model_selection'],\n",
    "                n_iterations=best['param']\n",
    "            ),\n",
    "            sample_size=sample_size,\n",
    "            message_passing=False,\n",
    "            verbose=True,\n",
    "            include_time=False\n",
    "        )\n",
    "    else:\n",
    "        gkan_symb, symb_g, symb_h = fit_model(\n",
    "            model_path=model_path_gkan,\n",
    "            n_g_hidden_layers=n_g_hidden_layers,\n",
    "            n_h_hidden_layers=n_h_hidden_layers,\n",
    "            theta=best['param'],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            sample_size=sample_size,\n",
    "            sort_by=best['model_selection'],\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    return gkan_symb, symb_g, symb_h\n",
    "\n",
    "\n",
    "def post_process_gkan(\n",
    "    config,\n",
    "    model_path, \n",
    "    test_set, \n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False, \n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    scaler=None,\n",
    "    inverse_scale=False,\n",
    "    adjoint=True,\n",
    "    eval_model=True\n",
    "):\n",
    "    \n",
    "    def print_symb_error(g_symb, h_symb, txt=\"symbolic formula\", is_symb=True):\n",
    "        try:\n",
    "            test_losses_symb = get_symb_test_error(\n",
    "                g_symb=g_symb,\n",
    "                h_symb=h_symb,\n",
    "                test_set=test_set,\n",
    "                message_passing=message_passing,\n",
    "                include_time=include_time,\n",
    "                atol=atol,\n",
    "                rtol=rtol,\n",
    "                method=method,\n",
    "                scaler=scaler,\n",
    "                inverse_scale=inverse_scale,\n",
    "                is_symb=is_symb\n",
    "            )\n",
    "\n",
    "            ts_mean = np.mean(test_losses_symb)\n",
    "            ts_var = np.var(test_losses_symb)\n",
    "            ts_std = np.std(test_losses_symb)\n",
    "            \n",
    "            print(f\"Mean Test loss of {txt}: {ts_mean}\")\n",
    "            print(f\"Var Test loss of {txt}: {ts_var}\")\n",
    "            print(f\"Std Test loss of {txt}: {ts_std}\")\n",
    "        except AssertionError:\n",
    "            print(\"Evaluation failed!\")\n",
    "        \n",
    "    \n",
    "    print(\"Black-Box fitting \\n\")\n",
    "    bb_symb, bb_g_symb, bb_h_symb = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/gkan\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        black_box_fitting=True,\n",
    "        n_g_hidden_layers=n_g_hidden_layers,\n",
    "        n_h_hidden_layers=n_h_hidden_layers,\n",
    "        sample_size = sample_size\n",
    "    )\n",
    "    \n",
    "    print(latex(quantise(bb_symb)))\n",
    "    print_symb_error(g_symb=bb_g_symb, h_symb=bb_h_symb)\n",
    "    \n",
    "    print(\"Spline-wise fitting\\n\")\n",
    "    spline_symb, spl_g_symb, spl_h_symb = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/gkan\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        black_box_fitting=False,\n",
    "        n_g_hidden_layers=n_g_hidden_layers,\n",
    "        n_h_hidden_layers=n_h_hidden_layers,\n",
    "        sample_size = sample_size\n",
    "    )\n",
    "    print(latex(quantise(spline_symb)))\n",
    "    print_symb_error(g_symb=spl_g_symb, h_symb=spl_h_symb)\n",
    "    \n",
    "    \n",
    "    if eval_model:\n",
    "        print(\"Evaluate raw model\\n\")\n",
    "        # Loading best model\n",
    "        best_model = build_model_from_file(\n",
    "            model_path=model_path,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            method=method,\n",
    "            adjoint=adjoint,\n",
    "            atol=atol,\n",
    "            rtol=rtol\n",
    "        )\n",
    "\n",
    "        tot_params = sum(p.numel() for p in best_model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of model's parameters: {tot_params}\\n\")\n",
    "\n",
    "        best_model = best_model.eval()\n",
    "        print_symb_error(\n",
    "            g_symb=best_model.conv.model.g_net,\n",
    "            h_symb=best_model.conv.model.h_net,\n",
    "            txt=\"best model\",\n",
    "            is_symb=False\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, node_index = 0):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_true[:, node_index, :], label='y_true', marker='o')\n",
    "    plt.plot(y_pred[:, node_index, :], label='y_pred', marker='o')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'y_true vs y_pred for Node {node_index}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.3504788815528931e-05\n",
      "Var Test loss of symbolic formula: 1.314533673970284e-13\n",
      "Std Test loss of symbolic formula: 3.625649836884809e-07\n"
     ]
    }
   ],
   "source": [
    "kur_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_kuramoto.yml\")\n",
    "\n",
    "KUR = get_test_set(\n",
    "    dynamics=kur_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=kur_config['input_range'],\n",
    "    **kur_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: torch.sin(x[:, 1] - x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: 2.0 + 0.5 * x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=KUR,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.071706852447581e-06\n",
      "Var Test loss of symbolic formula: 8.008373820613663e-14\n",
      "Std Test loss of symbolic formula: 2.829907033917133e-07\n"
     ]
    }
   ],
   "source": [
    "epid_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_epidemics.yml\")\n",
    "\n",
    "EPID = get_test_set(\n",
    "    dynamics=epid_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=epid_config['input_range'],\n",
    "    **epid_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.5*x[:, 1].unsqueeze(-1) * (1 - x[:, 0].unsqueeze(-1))\n",
    "h_symb = lambda x: x[:, 1].unsqueeze(1) - 0.5 * x[:, 0].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=EPID,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 3.735399635237021e-06\n",
      "Var Test loss of symbolic formula: 4.746857081617248e-13\n",
      "Std Test loss of symbolic formula: 6.889743886108719e-07\n"
     ]
    }
   ],
   "source": [
    "pop_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "\n",
    "POP = get_test_set(\n",
    "    dynamics=pop_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=pop_config['input_range'],\n",
    "    **pop_config['integration_kwargs']\n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.2*torch.pow(x[:, 1].unsqueeze(-1), 3)\n",
    "h_symb = lambda x: -0.5 * x[:, 0].unsqueeze(-1) + x[:, 1].unsqueeze(1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=POP,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.2006473374034006e-06\n",
      "Var Test loss of symbolic formula: 7.184599599254429e-14\n",
      "Std Test loss of symbolic formula: 2.6804103415810103e-07\n"
     ]
    }
   ],
   "source": [
    "bio_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical.yml\")\n",
    "\n",
    "BIO = get_test_set(\n",
    "    dynamics=bio_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=bio_config['input_range'],\n",
    "    **bio_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: (-0.5*x[:, 1] * x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: (1.0 - 0.5 * x[:, 0]).unsqueeze(-1)  + x[:, 1].unsqueeze(-1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=BIO,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symb Reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 3.549701068550348e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 17.393635 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.248945 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 3.2913121685851365e-05\n",
      "Var Test loss of symbolic formula: 3.9214064673506565e-12\n",
      "Std Test loss of symbolic formula: 1.980254142111728e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.01088594738394022}\n",
      "Fitting G_Net...\n",
      "Execution time: 71.014883 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 72.110480 seconds\n",
      "\\sum_{j}(-0.49*x_i*x_j + 0.01*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.012711200552682081\n",
      "Var Test loss of symbolic formula: 1.2983065129237242e-06\n",
      "Std Test loss of symbolic formula: 0.0011394325398740041\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 280\n",
      "\n",
      "Mean Test loss of best model: 3.524918853751539e-05\n",
      "Var Test loss of best model: 1.9364785946079674e-11\n",
      "Std Test loss of best model: 4.400543823901732e-06\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=30000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.0017313702264800668}\n",
      "Fitting G_Net...\n",
      "Execution time: 9.212349 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.594127 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) + \\log{\\left(2.63 - x_{i} \\right)}\n",
      "Mean Test loss of symbolic formula: 0.00168048485647887\n",
      "Var Test loss of symbolic formula: 3.0966358974741028e-09\n",
      "Std Test loss of symbolic formula: 5.56474248952645e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.0037466883659362793}\n",
      "Pruning node (0,0)\n",
      "Fitting G_Net...\n",
      "Execution time: 13.777086 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.937785 seconds\n",
      "\\sum_{j}(-0.37*x_i*x_j - 0.05*x_i - 0.05*x_j + 0.02) - 0.51 x_{i} + 1.01\n",
      "Mean Test loss of symbolic formula: 0.003954710050796469\n",
      "Var Test loss of symbolic formula: 3.187409687245602e-07\n",
      "Std Test loss of symbolic formula: 0.0005645714912431908\n",
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.005545017309486866}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.254240 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.090978 seconds\n",
      "\\sum_{j}(-0.49*x_i*x_j) - \\sin{\\left(0.55 x_{i} \\right)} + 1.04\n",
      "Mean Test loss of symbolic formula: 0.005419575609266758\n",
      "Var Test loss of symbolic formula: 3.855361907761229e-09\n",
      "Std Test loss of symbolic formula: 6.209156068066922e-05\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.29712235927581787}\n",
      "Fitting G_Net...\n",
      "Execution time: 9.334400 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 6.167516 seconds\n",
      "\\sum_{j}(-0.2*x_i - 0.2) - 0.52 x_{i} + 1.03\n",
      "Mean Test loss of symbolic formula: 0.2887199819087982\n",
      "Var Test loss of symbolic formula: 0.0002621058565228651\n",
      "Std Test loss of symbolic formula: 0.016189683644928492\n",
      "./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.10520247370004654}\n",
      "Fitting G_Net...\n",
      "Execution time: 17.853203 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 14.105056 seconds\n",
      "\\sum_{j}(-0.08*tanh(2.41*x_j)) + \\left(x_{i}^{9} - 0.69\\right)^{2}\n",
      "Mean Test loss of symbolic formula: 0.09759674221277237\n",
      "Var Test loss of symbolic formula: 5.323037408755393e-05\n",
      "Std Test loss of symbolic formula: 0.007295914890372141\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.05459100380539894}\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Fitting G_Net...\n",
      "Execution time: 11.521044 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 6.817762 seconds\n",
      "\\sum_{j}((0.18*x_j - 0.01)*(0.25*cos(1.24*x_i + 0.42) - 1.28) + 0.19*(x_j - 0.06)**2*(0.2*cos(1.24*x_i + 0.42) - 1)**2 - 0.01) - 4.63 x_{i}^{3} + 9.22 x_{i}^{2} - 5.77 x_{i} - 0.08 e^{3.16 \\sin{\\left(4.1 x_{i} - 2.63 \\right)}} + 1.48 \\tanh{\\left(79.61 x_{i}^{3} - 129.38 x_{i}^{2} + 75.37 x_{i} - 25.89 \\right)} + 3.2\n",
      "Mean Test loss of symbolic formula: 0.05477185547351837\n",
      "Var Test loss of symbolic formula: 6.20196114236397e-05\n",
      "Std Test loss of symbolic formula: 0.00787525310219549\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-gkan/biochemical_gkan_ic1_s5_pd_mult_noise_20db_2/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=bio_config,\n",
    "        model_path=model_path,\n",
    "        test_set=BIO,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.00041059116483666003}\n",
      "Fitting G_Net...\n",
      "Execution time: 22.446857 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 24.850279 seconds\n",
      "\\sum_{j}(-0.52*sin(x_i - x_j)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.012538877005378405\n",
      "Var Test loss of symbolic formula: 7.523174971765879e-07\n",
      "Std Test loss of symbolic formula: 0.0008673623793874092\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.0020375282038003206}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 6.449856 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 3.527041 seconds\n",
      "\\sum_{j}(-0.5*sin(-1.0*x_i + 1.0*x_j + 3.14)) + 2.0\n",
      "Mean Test loss of symbolic formula: 0.002298227744176984\n",
      "Var Test loss of symbolic formula: 2.0815095762829216e-09\n",
      "Std Test loss of symbolic formula: 4.56235638270721e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 543\n",
      "\n",
      "Mean Test loss of best model: 0.0016122294279436271\n",
      "Var Test loss of best model: 6.193546818525011e-07\n",
      "Std Test loss of best model: 0.0007869909032844669\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 100, 'valid_loss': 0.007145709823817015}\n",
      "Fitting G_Net...\n",
      "Execution time: 19.059034 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 23.521774 seconds\n",
      "\\sum_{j}(-0.49*sin(x_i - x_j)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.007131052669137716\n",
      "Var Test loss of symbolic formula: 6.036935300456649e-08\n",
      "Std Test loss of symbolic formula: 0.0002457017562097725\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.03981337323784828}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Fitting G_Net...\n",
      "Execution time: 5.850058 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.572098 seconds\n",
      "\\sum_{j}(-0.49*sin(1.0*x_i - 1.01*x_j + 0.1)) + 2.01\n",
      "Mean Test loss of symbolic formula: 0.03392164781689644\n",
      "Var Test loss of symbolic formula: 4.0513348818336605e-05\n",
      "Std Test loss of symbolic formula: 0.006365009726491909\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 200, 'valid_loss': 0.05628015473484993}\n",
      "Fitting G_Net...\n",
      "Execution time: 33.167968 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 42.545120 seconds\n",
      "\\sum_{j}(-0.4*sin(x_i - x_j)) - 0.2 \\sin{\\left(x_{i} \\right)} + 1.94\n",
      "Mean Test loss of symbolic formula: 0.10963946580886841\n",
      "Var Test loss of symbolic formula: 0.00019089434142775344\n",
      "Std Test loss of symbolic formula: 0.013816451839302066\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.08241403847932816}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,4)\n",
      "Fitting G_Net...\n",
      "Execution time: 9.635976 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 22.507003 seconds\n",
      "\\sum_{j}(0.01 - 0.43*sin(-0.01*x_i**3 + 0.12*x_i**2 + 0.53*x_i + 5.72*sin(0.17*x_j + 2.53) - 2.83)) + 0.01 x_{i} + 0.03 \\left(\\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 0.66\\right)^{3} - 0.07 \\left(\\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 0.66\\right)^{2} + 0.14 \\cos{\\left(1.22 x_{i} + 0.38 \\right)} + 2.15\n",
      "Mean Test loss of symbolic formula: 0.093520092467467\n",
      "Var Test loss of symbolic formula: 2.8339800094176776e-06\n",
      "Std Test loss of symbolic formula: 0.0016834429035217314\n",
      "./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 1.091734766960144}\n",
      "Fitting G_Net...\n",
      "Execution time: 16.390624 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.564453 seconds\n",
      "\\sum_{j}(-tanh(249.46/(x_i**3*x_j**3))) + e^{3 \\sin{\\left(1.74 x_{i} \\right)}}\n",
      "Mean Test loss of symbolic formula: 1.2062313159306843\n",
      "Var Test loss of symbolic formula: 2.1666894396174835e-06\n",
      "Std Test loss of symbolic formula: 0.001471967879954411\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.05, 'valid_loss': 0.943835973739624}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting G_Net...\n",
      "Execution time: 0.000438 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.622671 seconds\n",
      "\\sum_{j}(0) - 5.15 x_{i} - 0.12 \\left(x_{i} + 0.27\\right)^{3} + 1.42 \\left(x_{i} + 0.27\\right)^{2} - 7.61 \\sin{\\left(0.8 x_{i} - 2.19 \\right)} + 2.75 \\cos{\\left(0.88 x_{i} + 1.23 \\right)} - 13.32 \\cos{\\left(5.35 \\cos{\\left(1.85 x_{i} - 4.54 \\right)} - 2.88 \\right)} + 6.57\n",
      "Mean Test loss of symbolic formula: 1.010321815808614\n",
      "Var Test loss of symbolic formula: 5.027089721289081e-05\n",
      "Std Test loss of symbolic formula: 0.007090197261916682\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-gkan/kuramoto_gkan_ic1_s5_pd_mult_noise_20db/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=kur_config,\n",
    "        model_path=model_path,\n",
    "        test_set=KUR,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 3.765320434467867e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 10.544345 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.334455 seconds\n",
      "\\sum_{j}(x_j*(0.5 - 0.5*x_i)) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 3.22361441552251e-05\n",
      "Var Test loss of symbolic formula: 2.1891731062645337e-11\n",
      "Std Test loss of symbolic formula: 4.678860017423618e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.0011112447828054428}\n",
      "Fitting G_Net...\n",
      "Execution time: 25.941879 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.931225 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j + 0.5*x_j) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.0011451085253308217\n",
      "Var Test loss of symbolic formula: 2.1207599865899704e-09\n",
      "Std Test loss of symbolic formula: 4.6051709920370716e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 264\n",
      "\n",
      "Mean Test loss of best model: 0.00019420394770956287\n",
      "Var Test loss of best model: 9.010235804097534e-11\n",
      "Std Test loss of best model: 9.492226189939605e-06\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 0.002244098810479045}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.355172 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.227076 seconds\n",
      "\\sum_{j}(x_j*(0.51 - 0.51*x_i)) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.002354982541874051\n",
      "Var Test loss of symbolic formula: 1.0752977480680034e-07\n",
      "Std Test loss of symbolic formula: 0.0003279173292261334\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.1, 'valid_loss': 0.014380019158124924}\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 31.594218 seconds\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 5.871257 seconds\n",
      "\\sum_{j}(-0.46*x_i*x_j + 0.47*x_j) - 0.39 x_{i} - 0.06\n",
      "Mean Test loss of symbolic formula: 0.01322010283668836\n",
      "Var Test loss of symbolic formula: 2.6293119423887207e-06\n",
      "Std Test loss of symbolic formula: 0.0016215153228966788\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 450\n",
      "\n",
      "Mean Test loss of best model: 0.0020562036661431193\n",
      "Var Test loss of best model: 8.05423553676876e-08\n",
      "Std Test loss of best model: 0.0002837998508944069\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.028511973097920418}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.184228 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.947385 seconds\n",
      "\\sum_{j}(-0.18*log(x_i)) - 0.14\n",
      "Mean Test loss of symbolic formula: 0.02964874605337779\n",
      "Var Test loss of symbolic formula: 6.506173588601313e-06\n",
      "Std Test loss of symbolic formula: 0.002550720209784153\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,3)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.1, 'valid_loss': 0.03664926439523697}\n",
      "Pruning node (0,1)\n",
      "Fitting G_Net...\n",
      "Execution time: 26.217886 seconds\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.446302 seconds\n",
      "\\sum_{j}(0.34*tanh(0.55*x_j + 0.54*cos(2.73*x_i + 0.1) - 0.99) + 0.29) - 0.13\n",
      "Mean Test loss of symbolic formula: 0.03262868461509546\n",
      "Var Test loss of symbolic formula: 1.766416481109898e-06\n",
      "Std Test loss of symbolic formula: 0.0013290660183414133\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 352\n",
      "\n",
      "Mean Test loss of best model: 0.0261530801653862\n",
      "Var Test loss of best model: 1.459289080037405e-05\n",
      "Std Test loss of best model: 0.003820064240346496\n",
      "./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 0.07408930361270905}\n",
      "Fitting G_Net...\n",
      "Execution time: 17.210457 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 17.634566 seconds\n",
      "\\sum_{j}(0.01 - 0.01*x_j) - x_{i} + 0.77\n",
      "Mean Test loss of symbolic formula: 0.07820665091276169\n",
      "Var Test loss of symbolic formula: 1.0264305971507959e-05\n",
      "Std Test loss of symbolic formula: 0.0032037955570710123\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.10667437314987183}\n",
      "Fitting G_Net...\n",
      "Execution time: 12.127377 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 9.694168 seconds\n",
      "\\sum_{j}(0.0) - 1.09 \\tanh{\\left(88.88 x_{i} - 39.68 \\right)} + 0.17 \\tanh{\\left(78.19 \\sin{\\left(10.47 x_{i} - 5.14 \\right)} - 24.73 \\right)} + 0.9 \\tanh{\\left(18.53 \\tanh{\\left(9.74 x_{i} - 4.92 \\right)} + 25.3 \\right)} + 0.09\n",
      "Mean Test loss of symbolic formula: 0.10957680145899455\n",
      "Var Test loss of symbolic formula: 1.52982685459355e-05\n",
      "Std Test loss of symbolic formula: 0.003911300109418286\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 174\n",
      "\n",
      "Mean Test loss of best model: 0.1770920753479004\n",
      "Var Test loss of best model: 9.097893966740027e-05\n",
      "Std Test loss of best model: 0.00953828808892876\n"
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-gkan/epidemics_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=epid_config,\n",
    "        model_path=model_path,\n",
    "        test_set=EPID,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 100, 'valid_loss': 1.8369477402302437e-05}\n",
      "Fitting G_Net...\n",
      "Execution time: 18.368421 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 18.789813 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 1.7581651263753884e-05\n",
      "Var Test loss of symbolic formula: 2.584156024652137e-12\n",
      "Std Test loss of symbolic formula: 1.6075310338068553e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "Refitting best model with {'model_selection': 'log_loss', 'param': 0.01, 'valid_loss': 0.006122959777712822}\n",
      "Fitting G_Net...\n",
      "Execution time: 8.088346 seconds\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,4)\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 10.261416 seconds\n",
      "\\sum_{j}(0.15*x_j**3 + 0.01*x_j**2 + 0.02*x_j) - 0.29 x_{i} - 0.17 \\tanh{\\left(1.43 x_{i} - 0.08 \\right)} - 0.01\n",
      "Mean Test loss of symbolic formula: 0.005054490951200326\n",
      "Var Test loss of symbolic formula: 6.284319698214194e-07\n",
      "Std Test loss of symbolic formula: 0.0007927370117645696\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 294\n",
      "\n",
      "Mean Test loss of best model: 0.00026198988295315456\n",
      "Var Test loss of best model: 2.1526992571854367e-09\n",
      "Std Test loss of best model: 4.639719018631879e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_12/0\"\n",
    "\n",
    "post_process_gkan(\n",
    "    config=pop_config,\n",
    "    model_path=model_path_gkan,\n",
    "    test_set=POP,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'score', 'param': 50, 'valid_loss': 100000000.0}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.410990 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 11.822218 seconds\n",
      "\\sum_{j}(0.2*x_j**3) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 8.771742674677323e-05\n",
      "Var Test loss of symbolic formula: 1.0174534376923578e-11\n",
      "Std Test loss of symbolic formula: 3.1897545950940453e-06\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n",
      "Fitting symbolic model with log_loss and theta 0.05\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,5)\n",
      "Fitting symbolic model with log_loss and theta 0.1\n",
      "Pruning node (0,0)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Pruning node (0,5)\n",
      "Refitting best model with {'model_selection': 'score', 'param': 0.01, 'valid_loss': 0.18861649930477142}\n",
      "Fitting G_Net...\n",
      "Execution time: 39.421834 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.342211 seconds\n",
      "\\sum_{j}(0.02*x_i + 0.02*x_j + 0.04*tan(1.09*x_j - 0.03)) - 0.5 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.022732293233275414\n",
      "Var Test loss of symbolic formula: 3.847226371665735e-06\n",
      "Std Test loss of symbolic formula: 0.0019614347737474565\n",
      "./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\n",
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n",
      "Fitting black-box model with score and 100 iterations\n",
      "Fitting black-box model with score and 200 iterations\n",
      "Fitting black-box model with accuracy and 50 iterations\n",
      "Fitting black-box model with accuracy and 100 iterations\n",
      "Fitting black-box model with accuracy and 200 iterations\n",
      "Refitting best model with {'model_selection': 'accuracy', 'param': 50, 'valid_loss': 0.1454584300518036}\n",
      "Fitting G_Net...\n",
      "Execution time: 11.471240 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 12.337064 seconds\n",
      "\\sum_{j}(0.18*x_j**3) - 0.46 x_{i}\n",
      "Mean Test loss of symbolic formula: 0.0068573167858024435\n",
      "Var Test loss of symbolic formula: 1.628855964074743e-08\n",
      "Std Test loss of symbolic formula: 0.00012762664157905053\n",
      "Spline-wise fitting\n",
      "\n",
      "Fitting symbolic model with score and theta 0.01\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.05\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with score and theta 0.1\n",
      "Pruning node (0,2)\n",
      "Pruning node (0,1)\n",
      "Pruning node (0,3)\n",
      "Pruning node (0,4)\n",
      "Fitting symbolic model with log_loss and theta 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_path \u001b[38;5;129;01min\u001b[39;00m model_paths_gkan:\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(model_path)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mpost_process_gkan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpop_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPOP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_g_hidden_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_h_hidden_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_passing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdopri5\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 394\u001b[39m, in \u001b[36mpost_process_gkan\u001b[39m\u001b[34m(config, model_path, test_set, device, n_g_hidden_layers, n_h_hidden_layers, sample_size, message_passing, include_time, atol, rtol, method, scaler, inverse_scale, adjoint, eval_model)\u001b[39m\n\u001b[32m    391\u001b[39m print_symb_error(g_symb=bb_g_symb, h_symb=bb_h_symb)\n\u001b[32m    393\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSpline-wise fitting\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m spline_symb, spl_g_symb, spl_h_symb = \u001b[43mvalid_symb_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path_gkan\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/gkan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43matol\u001b[49m\u001b[43m=\u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblack_box_fitting\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_g_hidden_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_g_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_h_hidden_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_h_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28mprint\u001b[39m(latex(quantise(spline_symb)))\n\u001b[32m    407\u001b[39m print_symb_error(g_symb=spl_g_symb, h_symb=spl_h_symb)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 286\u001b[39m, in \u001b[36mvalid_symb_model\u001b[39m\u001b[34m(config, model_path_gkan, device, atol, rtol, method, black_box_fitting, n_g_hidden_layers, n_h_hidden_layers, sample_size)\u001b[39m\n\u001b[32m    283\u001b[39m valid_losses = []\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m mod, val \u001b[38;5;129;01min\u001b[39;00m search_space:\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     g_symb, h_symb = \u001b[43mfit_single_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    288\u001b[39m         loss = evaluate_model(g_symb, h_symb)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 263\u001b[39m, in \u001b[36mvalid_symb_model.<locals>.fit_single_model\u001b[39m\u001b[34m(param1, param2)\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFitting symbolic model with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam1\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and theta \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m     _, g_symb, h_symb = \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_g_hidden_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_g_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_h_hidden_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_h_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path_gkan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessage_passing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_time\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparam1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m g_symb, h_symb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kan-for-Interpretable-Graph-Dynamics/utils/utils.py:566\u001b[39m, in \u001b[36mfit_model\u001b[39m\u001b[34m(n_h_hidden_layers, n_g_hidden_layers, model_path, theta, message_passing, include_time, seed, sample_size, sort_by, verbose)\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m    564\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting G_Net...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m symb_g = \u001b[43mfit_kan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpruned_acts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpruned_preacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkan_masks_mult\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpruned_masks_mult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43msymb_xs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSymbol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx_i\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSymbol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mx_j\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/g_net\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m symb_g = symb_g[\u001b[32m0\u001b[39m]  \u001b[38;5;66;03m# Univariate functions\u001b[39;00m\n\u001b[32m    579\u001b[39m \u001b[38;5;66;03m# H_Net\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kan-for-Interpretable-Graph-Dynamics/utils/utils.py:526\u001b[39m, in \u001b[36mfit_kan\u001b[39m\u001b[34m(kan_acts, kan_preacts, kan_masks_mult, symb_xs, model_path, seed, sample_size, sort_by, verbose)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    524\u001b[39m     json.dump(all_functions, f)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimplify\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m symbx \u001b[38;5;129;01min\u001b[39;00m symb_xs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/simplify.py:699\u001b[39m, in \u001b[36msimplify\u001b[39m\u001b[34m(expr, ratio, measure, rational, inverse, doit, **kwargs)\u001b[39m\n\u001b[32m    696\u001b[39m     expr = besselsimp(expr)\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expr.has(TrigonometricFunction, HyperbolicFunction):\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     expr = \u001b[43mtrigsimp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expr.has(log):\n\u001b[32m    702\u001b[39m     expr = shorter(expand_log(expr, deep=\u001b[38;5;28;01mTrue\u001b[39;00m), logcombine(expr))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:565\u001b[39m, in \u001b[36mtrigsimp\u001b[39m\u001b[34m(expr, inverse, **opts)\u001b[39m\n\u001b[32m    554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m trigsimp_groebner(new, **opts)\n\u001b[32m    556\u001b[39m trigsimpfunc = {\n\u001b[32m    557\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfu\u001b[39m\u001b[33m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: fu(x, **opts)),\n\u001b[32m    558\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmatching\u001b[39m\u001b[33m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: futrig(x)),\n\u001b[32m   (...)\u001b[39m\u001b[32m    562\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mold\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: trigsimp_old(x, **opts),\n\u001b[32m    563\u001b[39m                }[method]\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m expr_simplified = \u001b[43mtrigsimpfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inverse:\n\u001b[32m    567\u001b[39m     expr_simplified = _trigsimp_inverse(expr_simplified)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:558\u001b[39m, in \u001b[36mtrigsimp.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    553\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m new\n\u001b[32m    554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m trigsimp_groebner(new, **opts)\n\u001b[32m    556\u001b[39m trigsimpfunc = {\n\u001b[32m    557\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfu\u001b[39m\u001b[33m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: fu(x, **opts)),\n\u001b[32m--> \u001b[39m\u001b[32m558\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmatching\u001b[39m\u001b[33m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfutrig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[32m    559\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mgroebner\u001b[39m\u001b[33m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: groebnersimp(x, **opts)),\n\u001b[32m    560\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcombined\u001b[39m\u001b[33m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: futrig(groebnersimp(x,\n\u001b[32m    561\u001b[39m                            polynomial=\u001b[38;5;28;01mTrue\u001b[39;00m, hints=[\u001b[32m2\u001b[39m, tan]))),\n\u001b[32m    562\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mold\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: trigsimp_old(x, **opts),\n\u001b[32m    563\u001b[39m                }[method]\n\u001b[32m    565\u001b[39m expr_simplified = trigsimpfunc(expr)\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inverse:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:1159\u001b[39m, in \u001b[36mfutrig\u001b[39m\u001b[34m(e, hyper, **kwargs)\u001b[39m\n\u001b[32m   1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e\n\u001b[32m   1158\u001b[39m old = e\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m e = \u001b[43mbottom_up\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_futrig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hyper \u001b[38;5;129;01mand\u001b[39;00m e.has(HyperbolicFunction):\n\u001b[32m   1162\u001b[39m     e, f = hyper_as_trig(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/core/traversal.py:233\u001b[39m, in \u001b[36mbottom_up\u001b[39m\u001b[34m(rv, F, atoms, nonbasic)\u001b[39m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m args != rv.args:\n\u001b[32m    232\u001b[39m         rv = rv.func(*args)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     rv = \u001b[43mF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m atoms:\n\u001b[32m    235\u001b[39m     rv = F(rv)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:1226\u001b[39m, in \u001b[36m_futrig\u001b[39m\u001b[34m(e)\u001b[39m\n\u001b[32m   1187\u001b[39m trigs = \u001b[38;5;28;01mlambda\u001b[39;00m x: x.has(TrigonometricFunction)\n\u001b[32m   1189\u001b[39m tree = [identity,\n\u001b[32m   1190\u001b[39m     (\n\u001b[32m   1191\u001b[39m     TR3,  \u001b[38;5;66;03m# canonical angles\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1224\u001b[39m         factor_terms, TR12(x), trigs)],  \u001b[38;5;66;03m# expand tan of sum\u001b[39;00m\n\u001b[32m   1225\u001b[39m     )]\n\u001b[32m-> \u001b[39m\u001b[32m1226\u001b[39m e = \u001b[43mgreedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLops\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m coeff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1229\u001b[39m     e = coeff * e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/strategies/core.py:150\u001b[39m, in \u001b[36mminimize.<locals>.minrule\u001b[39m\u001b[34m(expr)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mminrule\u001b[39m(expr: _S) -> _T:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m([\u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m rules], key=objective)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/strategies/core.py:64\u001b[39m, in \u001b[36mchain.<locals>.chain_rl\u001b[39m\u001b[34m(expr)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchain_rl\u001b[39m(expr: _T) -> _T:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m rules:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         expr = \u001b[43mrule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:1203\u001b[39m, in \u001b[36m_futrig.<locals>.<lambda>\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1186\u001b[39m Lops = \u001b[38;5;28;01mlambda\u001b[39;00m x: (L(x), x.count_ops(), _nodes(x), \u001b[38;5;28mlen\u001b[39m(x.args), x.is_Add)\n\u001b[32m   1187\u001b[39m trigs = \u001b[38;5;28;01mlambda\u001b[39;00m x: x.has(TrigonometricFunction)\n\u001b[32m   1189\u001b[39m tree = [identity,\n\u001b[32m   1190\u001b[39m     (\n\u001b[32m   1191\u001b[39m     TR3,  \u001b[38;5;66;03m# canonical angles\u001b[39;00m\n\u001b[32m   1192\u001b[39m     TR1,  \u001b[38;5;66;03m# sec-csc -> cos-sin\u001b[39;00m\n\u001b[32m   1193\u001b[39m     TR12,  \u001b[38;5;66;03m# expand tan of sum\u001b[39;00m\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(factor, x, trigs),\n\u001b[32m   1195\u001b[39m     TR2,  \u001b[38;5;66;03m# tan-cot -> sin-cos\u001b[39;00m\n\u001b[32m   1196\u001b[39m     [identity, \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(_mexpand, x, trigs)],\n\u001b[32m   1197\u001b[39m     TR2i,  \u001b[38;5;66;03m# sin-cos ratio -> tan\u001b[39;00m\n\u001b[32m   1198\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(\u001b[38;5;28;01mlambda\u001b[39;00m i: factor(i.normal()), x, trigs),\n\u001b[32m   1199\u001b[39m     TR14,  \u001b[38;5;66;03m# factored identities\u001b[39;00m\n\u001b[32m   1200\u001b[39m     TR5,  \u001b[38;5;66;03m# sin-pow -> cos_pow\u001b[39;00m\n\u001b[32m   1201\u001b[39m     TR10,  \u001b[38;5;66;03m# sin-cos of sums -> sin-cos prod\u001b[39;00m\n\u001b[32m   1202\u001b[39m     TR11, _TR11, TR6, \u001b[38;5;66;03m# reduce double angles and rewrite cos pows\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1203\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43m_eapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrigs\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m   1204\u001b[39m     TR14,  \u001b[38;5;66;03m# factored powers of identities\u001b[39;00m\n\u001b[32m   1205\u001b[39m     [identity, \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(_mexpand, x, trigs)],\n\u001b[32m   1206\u001b[39m     TR10i,  \u001b[38;5;66;03m# sin-cos products > sin-cos of sums\u001b[39;00m\n\u001b[32m   1207\u001b[39m     TRmorrie,\n\u001b[32m   1208\u001b[39m     [identity, TR8],  \u001b[38;5;66;03m# sin-cos products -> sin-cos of sums\u001b[39;00m\n\u001b[32m   1209\u001b[39m     [identity, \u001b[38;5;28;01mlambda\u001b[39;00m x: TR2i(TR2(x))],  \u001b[38;5;66;03m# tan -> sin-cos -> tan\u001b[39;00m\n\u001b[32m   1210\u001b[39m     [\n\u001b[32m   1211\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(expand_mul, TR5(x), trigs),\n\u001b[32m   1212\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(\n\u001b[32m   1213\u001b[39m             expand_mul, TR15(x), trigs)], \u001b[38;5;66;03m# pos/neg powers of sin\u001b[39;00m\n\u001b[32m   1214\u001b[39m     [\n\u001b[32m   1215\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x:  _eapply(expand_mul, TR6(x), trigs),\n\u001b[32m   1216\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m x:  _eapply(\n\u001b[32m   1217\u001b[39m             expand_mul, TR16(x), trigs)], \u001b[38;5;66;03m# pos/neg powers of cos\u001b[39;00m\n\u001b[32m   1218\u001b[39m     TR111,  \u001b[38;5;66;03m# tan, sin, cos to neg power -> cot, csc, sec\u001b[39;00m\n\u001b[32m   1219\u001b[39m     [identity, TR2i],  \u001b[38;5;66;03m# sin-cos ratio to tan\u001b[39;00m\n\u001b[32m   1220\u001b[39m     [identity, \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(\n\u001b[32m   1221\u001b[39m         expand_mul, TR22(x), trigs)],  \u001b[38;5;66;03m# tan-cot to sec-csc\u001b[39;00m\n\u001b[32m   1222\u001b[39m     TR1, TR2, TR2i,\n\u001b[32m   1223\u001b[39m     [identity, \u001b[38;5;28;01mlambda\u001b[39;00m x: _eapply(\n\u001b[32m   1224\u001b[39m         factor_terms, TR12(x), trigs)],  \u001b[38;5;66;03m# expand tan of sum\u001b[39;00m\n\u001b[32m   1225\u001b[39m     )]\n\u001b[32m   1226\u001b[39m e = greedy(tree, objective=Lops)(e)\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m coeff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/simplify/trigsimp.py:1250\u001b[39m, in \u001b[36m_eapply\u001b[39m\u001b[34m(func, e, cond)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m e\n\u001b[32m   1249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_Expr(e) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e.args:\n\u001b[32m-> \u001b[39m\u001b[32m1250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m e.func(*[\n\u001b[32m   1252\u001b[39m     _eapply(func, ei) \u001b[38;5;28;01mif\u001b[39;00m (cond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m cond(ei)) \u001b[38;5;28;01melse\u001b[39;00m ei\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ei \u001b[38;5;129;01min\u001b[39;00m e.args])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polytools.py:6577\u001b[39m, in \u001b[36mfactor\u001b[39m\u001b[34m(f, deep, *gens, **args)\u001b[39m\n\u001b[32m   6574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f.xreplace(partials)\n\u001b[32m   6576\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6577\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generic_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfactor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   6578\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PolynomialError:\n\u001b[32m   6579\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.is_commutative:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polytools.py:6258\u001b[39m, in \u001b[36m_generic_factor\u001b[39m\u001b[34m(expr, gens, args, method)\u001b[39m\n\u001b[32m   6256\u001b[39m opt = options.build_options(gens, args)\n\u001b[32m   6257\u001b[39m opt[\u001b[33m'\u001b[39m\u001b[33mfraction\u001b[39m\u001b[33m'\u001b[39m] = fraction\n\u001b[32m-> \u001b[39m\u001b[32m6258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_symbolic_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msympify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polytools.py:6198\u001b[39m, in \u001b[36m_symbolic_factor\u001b[39m\u001b[34m(expr, opt, method)\u001b[39m\n\u001b[32m   6196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(expr,\u001b[33m'\u001b[39m\u001b[33m_eval_factor\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   6197\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m expr._eval_factor()\n\u001b[32m-> \u001b[39m\u001b[32m6198\u001b[39m     coeff, factors = \u001b[43m_symbolic_factor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtogether\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfraction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfraction\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _keep_coeff(coeff, _factors_product(factors))\n\u001b[32m   6200\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(expr, \u001b[33m'\u001b[39m\u001b[33margs\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polytools.py:6163\u001b[39m, in \u001b[36m_symbolic_factor_list\u001b[39m\u001b[34m(expr, opt, method)\u001b[39m\n\u001b[32m   6160\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6161\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(poly, method + \u001b[33m'\u001b[39m\u001b[33m_list\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m6163\u001b[39m     _coeff, _factors = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6164\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _coeff \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m S.One:\n\u001b[32m   6165\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m exp.is_Integer:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polytools.py:3378\u001b[39m, in \u001b[36mPoly.factor_list\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m   3376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(f.rep, \u001b[33m'\u001b[39m\u001b[33mfactor_list\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   3377\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3378\u001b[39m         coeff, factors = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfactor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3379\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m DomainError:\n\u001b[32m   3380\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m f.degree() == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/polyclasses.py:1637\u001b[39m, in \u001b[36mDMP_Python.factor_list\u001b[39m\u001b[34m(f)\u001b[39m\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfactor_list\u001b[39m(f):\n\u001b[32m   1636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns a list of irreducible factors of ``f``. \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1637\u001b[39m     coeff, factors = \u001b[43mdmp_factor_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m coeff, [ (f.per(g), k) \u001b[38;5;28;01mfor\u001b[39;00m g, k \u001b[38;5;129;01min\u001b[39;00m factors ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/factortools.py:1569\u001b[39m, in \u001b[36mdmp_factor_list\u001b[39m\u001b[34m(f, u, K0)\u001b[39m\n\u001b[32m   1567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m K.is_ZZ:\n\u001b[32m   1568\u001b[39m     levels, f, v = dmp_exclude(f, u, K)\n\u001b[32m-> \u001b[39m\u001b[32m1569\u001b[39m     coeff, factors = \u001b[43mdmp_zz_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1571\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, (f, k) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(factors):\n\u001b[32m   1572\u001b[39m         factors[i] = (dmp_include(f, levels, v, K), k)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/factortools.py:1189\u001b[39m, in \u001b[36mdmp_zz_factor\u001b[39m\u001b[34m(f, u, K)\u001b[39m\n\u001b[32m   1187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dmp_degree(g, u) > \u001b[32m0\u001b[39m:\n\u001b[32m   1188\u001b[39m     g = dmp_sqf_part(g, u, K)\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     H = \u001b[43mdmp_zz_wang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1190\u001b[39m     factors = dmp_trial_division(f, H, u, K)\n\u001b[32m   1192\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m g, k \u001b[38;5;129;01min\u001b[39;00m dmp_zz_factor(G, u - \u001b[32m1\u001b[39m, K)[\u001b[32m1\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/polys/factortools.py:1028\u001b[39m, in \u001b[36mdmp_zz_wang\u001b[39m\u001b[34m(f, u, K, mod, seed)\u001b[39m\n\u001b[32m   1025\u001b[39m ct, T = dmp_zz_factor(dmp_LC(f, K), u - \u001b[32m1\u001b[39m, K)\n\u001b[32m   1027\u001b[39m b = dmp_zz_mignotte_bound(f, u, K)\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m p = K(\u001b[43mnextprime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m u == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/ntheory/generate.py:702\u001b[39m, in \u001b[36mnextprime\u001b[39m\u001b[34m(n, ith)\u001b[39m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m n\n\u001b[32m    701\u001b[39m n += \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misprime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    703\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m n\n\u001b[32m    704\u001b[39m n += \u001b[32m4\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/ntheory/primetest.py:764\u001b[39m, in \u001b[36misprime\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m    727\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mr(n, [\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m11\u001b[39m, \u001b[32m13\u001b[39m, \u001b[32m17\u001b[39m, \u001b[32m19\u001b[39m, \u001b[32m23\u001b[39m, \u001b[32m29\u001b[39m, \u001b[32m31\u001b[39m, \u001b[32m37\u001b[39m, \u001b[32m41\u001b[39m])\n\u001b[32m    729\u001b[39m \u001b[38;5;66;03m# We could do this instead at any point:\u001b[39;00m\n\u001b[32m    730\u001b[39m \u001b[38;5;66;03m#if n < 18446744073709551616:\u001b[39;00m\n\u001b[32m    731\u001b[39m \u001b[38;5;66;03m#   return mr(n, [2]) and is_extra_strong_lucas_prp(n)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    762\u001b[39m \n\u001b[32m    763\u001b[39m \u001b[38;5;66;03m# Classic BPSW from page 1401 of the paper.  See alternate ideas below.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_strong_bpsw_prp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/external/ntheory.py:637\u001b[39m, in \u001b[36mis_strong_bpsw_prp\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m n == \u001b[32m2\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_is_strong_prp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m _is_strong_selfridge_prp(n)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/myenv/lib/python3.12/site-packages/sympy/external/ntheory.py:329\u001b[39m, in \u001b[36m_is_strong_prp\u001b[39m\u001b[34m(n, a)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_is_strong_prp\u001b[39m(n, a):\n\u001b[32m    328\u001b[39m     s = bit_scan1(n - \u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     a = \u001b[38;5;28;43mpow\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[43m>>\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m a == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m a == n - \u001b[32m1\u001b[39m:\n\u001b[32m    331\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_paths_gkan = [\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    # \"./saved_models_optuna/model-population-gkan/population_gkan_ic1_s5_pd_mult_noise_20db_2/0\",\n",
    "]\n",
    "\n",
    "for model_path in model_paths_gkan:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=pop_config,\n",
    "        model_path=model_path,\n",
    "        test_set=POP,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\",\n",
    "        eval_model=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Epid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 32.812989 seconds\n",
      "Fitting H_Net...\n",
      "Execution time: 17.956217 seconds\n"
     ]
    }
   ],
   "source": [
    "model_path_gkan = \"./saved_models_optuna/model-real-epid-gkan/real_epid_gkan_4/0/gkan\"\n",
    "\n",
    "pysr_model = lambda : get_pysr_model(\n",
    "    model_selection=\"score\",\n",
    "    n_iterations=200\n",
    ")\n",
    "\n",
    "gkan_symb, symb_g, symb_h = fit_black_box_from_kan(\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    device='cuda',\n",
    "    model_path=model_path_gkan,\n",
    "    pysr_model=pysr_model,\n",
    "    sample_size=10000,\n",
    "    theta=-np.inf,\n",
    "    message_passing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( log(12.5043577686824*x_i + 13.5111551375654)) + 2.4884284 \\sin{\\left(x_{i} \\right)} + 2.112076$"
      ],
      "text/plain": [
       "\\sum_{j}( log(12.5043577686824*x_i + 13.5111551375654)) + 2.4884284*sin(x_i) + 2.112076"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkan_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 10.827934 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 4.955698 seconds\n"
     ]
    }
   ],
   "source": [
    "symb_spline_wise, symb_g, symb_h = fit_model(\n",
    "    n_h_hidden_layers=2,\n",
    "    n_g_hidden_layers=2,\n",
    "    model_path=model_path_gkan,\n",
    "    theta=0.1,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    sample_size=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSS Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tss_test_error(\n",
    "    text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h,\n",
    "    row_means,\n",
    "    test_set\n",
    "):\n",
    "    g_symb = sp.S(0)\n",
    "    h_symb = sp.S(0)\n",
    "            \n",
    "    for symb_g in text_sympy_mapping_g.keys():\n",
    "        g_symb += row_means[symb_g] * text_sympy_mapping_g[symb_g]\n",
    "    for symb_h in text_sympy_mapping_h.keys():\n",
    "        h_symb += row_means[symb_h] * text_sympy_mapping_h[symb_h]\n",
    "    \n",
    "    g_symb = make_callable(g_symb)\n",
    "    h_symb = make_callable(h_symb)\n",
    "    \n",
    "    test_losses = get_symb_test_error(\n",
    "        g_symb=g_symb,\n",
    "        h_symb=h_symb,\n",
    "        test_set=test_set,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        method='dopri5',\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5\n",
    "    )\n",
    "    \n",
    "    ts_mean = np.mean(test_losses)\n",
    "    ts_var = np.var(test_losses)\n",
    "    ts_std = np.std(test_losses)\n",
    "\n",
    "    print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "    print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "    print(f\"Std Test loss of symbolic formula: {ts_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0002912786342979719\n",
      "Var Test loss of symbolic formula: 4.206261141125669e-10\n",
      "Std Test loss of symbolic formula: 2.0509171463337248e-05\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "sinx1jMinusx1i    0.500084\n",
       "constant          1.999299\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.00035186927804412943\n",
      "Var Test loss of symbolic formula: 3.4495474563401334e-14\n",
      "Std Test loss of symbolic formula: 1.85729573744736e-07\n"
     ]
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.6032914121945699\n",
      "Var Test loss of symbolic formula: 0.0009892931714156185\n",
      "Std Test loss of symbolic formula: 0.03145303119598521\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"sinx1jMinusx1i\": sp.sin(x_j - x_i)\n",
    "}\n",
    "text_sympy_mapping_h = {\n",
    "    \"fracx1\": 1/ x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "x1iexpx1j          0.000338\n",
       "fracx1jMinusx1i    0.026852\n",
       "fracx1ix1j        -0.035464\n",
       "x1ifracx1j        -0.020929\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./saved_models_optuna/tss/Kuramoto-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "text_sympy_mapping_g = {\n",
    "    \"x1iexpx1j\": x_i * sp.exp(x_j),\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i),\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=KUR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "constant         -1.479146\n",
       "expx1jMinusx1i    0.310919\n",
       "dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.13932317246993384\n",
      "Var Test loss of symbolic formula: 0.0011257805640565567\n",
      "Std Test loss of symbolic formula: 0.03355265360677985\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1x1x1     -1.319998\n",
       "constant    0.645621\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.06238254035512606\n",
      "Var Test loss of symbolic formula: 6.161101675210123e-05\n",
      "Std Test loss of symbolic formula: 0.007849268548858628\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i,\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN               0.000000\n",
       "x1x1x1           -1.049246\n",
       "expx1jMinusx1i    0.101428\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.021900850037733715\n",
      "Var Test loss of symbolic formula: 4.893136437053426e-06\n",
      "Std Test loss of symbolic formula: 0.0022120434980021134\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"expx1jMinusx1i\": sp.exp(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1x1\": x_i * x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "fracx1ix1j         0.009380\n",
       "x1ifracx1j         0.009147\n",
       "fracx1j            0.000166\n",
       "fracx1jMinusx1i    0.000093\n",
       "dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Epidemics-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.11705934256315231\n",
      "Var Test loss of symbolic formula: 8.681066367199897e-06\n",
      "Std Test loss of symbolic formula: 0.002946364941279321\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1j\": 1 / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=EPID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.629935\n",
       "constant    0.805864\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.030168694754441578\n",
      "Var Test loss of symbolic formula: 7.935192549003557e-07\n",
      "Std Test loss of symbolic formula: 0.0008907969773749547\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "x1ix1j     -0.702419\n",
       "constant    0.891260\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.03311053911844889\n",
      "Var Test loss of symbolic formula: 1.6136963490022263e-06\n",
      "Std Test loss of symbolic formula: 0.0012703134845392402\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "x1x1     -1.690969\n",
       "x1ix1j    0.935806\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"x1ix1j\": x_i * x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN                0.000000\n",
       "fracx1ix1j         0.000972\n",
       "x1ifracx1j         0.000006\n",
       "fracx1jMinusx1i    0.000711\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Biochemical-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"fracx1ix1j\": 1/(x_i * x_j),\n",
    "    \"x1ifracx1j\": x_i / x_j,\n",
    "    \"fracx1jMinusx1i\": 1/(x_j - x_i)\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=BIO\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.026403\n",
       "x1j         0.181286\n",
       "sinx1j     -0.003445\n",
       "dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.127986046175162\n",
      "Var Test loss of symbolic formula: 7.68135815102871e-05\n",
      "Std Test loss of symbolic formula: 0.008764335771197217\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 70 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN         0.000000\n",
       "constant   -0.008463\n",
       "x1j         0.049181\n",
       "sinx1j      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_70_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0986446018020312\n",
      "Var Test loss of symbolic formula: 9.624285289105355e-06\n",
      "Std Test loss of symbolic formula: 0.0031023032232690207\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"constant\": sp.S(1.0)\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN       0.000000\n",
       "sinx1j   -0.437936\n",
       "x1j       0.447304\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_50_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.09825751930475235\n",
      "Var Test loss of symbolic formula: 6.906377144659063e-06\n",
      "Std Test loss of symbolic formula: 0.002627998695711066\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {\n",
    "    \"sinx1j\": sp.sin(x_j),\n",
    "    \"x1j\": x_j\n",
    "}\n",
    "\n",
    "text_sympy_mapping_h = {}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20 DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "NaN      0.000000\n",
       "sinx1   -0.395957\n",
       "x1x1     0.306063\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "df = pd.read_csv(\"./saved_models_optuna/tss/Population-1/results_dim=0_20_db.csv\", header=None)\n",
    "df.set_index(0, inplace=True)\n",
    "row_means = df.mean(axis=1)\n",
    "\n",
    "row_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.05001158267259598\n",
      "Var Test loss of symbolic formula: 6.406370715870506e-06\n",
      "Std Test loss of symbolic formula: 0.0025310809382298517\n"
     ]
    }
   ],
   "source": [
    "text_sympy_mapping_g = {}\n",
    "\n",
    "text_sympy_mapping_h = {\n",
    "    \"sinx1\": sp.sin(x_i),\n",
    "    \"x1x1\": x_i * x_i\n",
    "}\n",
    "\n",
    "get_tss_test_error(\n",
    "    text_sympy_mapping_g=text_sympy_mapping_g,\n",
    "    text_sympy_mapping_h=text_sympy_mapping_h,\n",
    "    row_means=row_means,\n",
    "    test_set=POP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Epid plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the dataset...\n"
     ]
    }
   ],
   "source": [
    "from datasets.RealEpidemics import RealEpidemics\n",
    "\n",
    "real_epid_data = RealEpidemics(\n",
    "    root = './data_real_epid',\n",
    "    name = 'RealEpid',\n",
    "    predict_deriv=False,\n",
    "    history=1,\n",
    "    horizon=44\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_i, x_j = sp.symbols('x_i x_j')\n",
    "\n",
    "g_symb = 7.130 / (1 + sp.exp(- (x_j - x_i)))\n",
    "h_symb = 0.074 * x_i\n",
    "\n",
    "g_symb = make_callable(g_symb)\n",
    "h_symb = make_callable(h_symb)\n",
    "\n",
    "symb_model = get_model(\n",
    "    g = g_symb,\n",
    "    h = h_symb,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    integration_method='dopri5'\n",
    ")\n",
    "\n",
    "y_true = real_epid_data[0].y.detach().cpu().numpy()\n",
    "y_pred = symb_model(real_epid_data[0]).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    "    node_index=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
