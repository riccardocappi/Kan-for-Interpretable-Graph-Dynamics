{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected IPython. Loading juliacall extension. See https://juliapy.github.io/PythonCall.jl/stable/compat/#IPython\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import *\n",
    "import optuna\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "from experiments.experiments_gkan import ExperimentsGKAN\n",
    "from experiments.experiments_mpnn import ExperimentsMPNN\n",
    "import sympytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def set_pytorch_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "set_pytorch_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils.MPNN import MPNN\n",
    "from models.baseline.MPNN_ODE import MPNN_ODE\n",
    "from train_and_eval import eval_model\n",
    "from datasets.SyntheticData import SyntheticData\n",
    "from sympy import symbols, sin, summation, simplify\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import from_networkx\n",
    "from utils.utils import integrate\n",
    "from torch_geometric.data import Data\n",
    "from experiments.experiments_mpnn import activations\n",
    "from models.utils.MLP import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import latex\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_model(g, h, message_passing=True, include_time=False, atol=1e-5, rtol=1e-5, integration_method = 'scipy_solver'):\n",
    "    conv = MPNN(\n",
    "        g_net = g,\n",
    "        h_net = h, \n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "    \n",
    "    symb = MPNN_ODE(\n",
    "        conv=conv,\n",
    "        model_path=\"./saved_models_optuna/tmp_symb\",\n",
    "        adjoint=True,\n",
    "        integration_method=integration_method,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "    \n",
    "    symb = symb.eval()\n",
    "    return symb\n",
    "\n",
    "\n",
    "def make_callable(expr):\n",
    "    free_syms = expr.free_symbols\n",
    "    if not free_syms:\n",
    "        # Expression is constant\n",
    "        const_value = float(expr)\n",
    "        return lambda x: torch.full((x.shape[0], 1), const_value, dtype=x.dtype, device=x.device)\n",
    "\n",
    "    sym_module = sympytorch.SymPyModule(expressions=[expr])\n",
    "    syms = {str(s) for s in free_syms}\n",
    "    if {'x_i', 'x_j'} <= syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0], x_j=x[:, 1])\n",
    "    elif 'x_i' in syms:\n",
    "        return lambda x: sym_module(x_i=x[:, 0])\n",
    "    elif 'x_j' in syms:\n",
    "        return lambda x: sym_module(x_j=x[:, 1])\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected symbols in expression: {free_syms}\")\n",
    "\n",
    "\n",
    "def get_symb_test_error(g_symb, h_symb, test_set, message_passing=False, include_time=False, atol=1e-5, rtol=1e-5, scaler = None, inverse_scale=False, method='scipy_solver',\n",
    "                        is_symb=True):\n",
    "    \n",
    "    if is_symb:\n",
    "        if isinstance(g_symb, int):\n",
    "            g_symb = sp.sympify(g_symb)\n",
    "            \n",
    "        if isinstance(h_symb, int):\n",
    "            h_symb = sp.sympify(h_symb)\n",
    "\n",
    "        g_symb = make_callable(g_symb)\n",
    "        h_symb = make_callable(h_symb)\n",
    "        \n",
    "    test_losses = []\n",
    "    \n",
    "    for ts in test_set:\n",
    "        symb = get_model(\n",
    "            g=g_symb,\n",
    "            h=h_symb,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            integration_method=method\n",
    "        )\n",
    "        \n",
    "        collate_fn = lambda samples_list: samples_list\n",
    "        test_loader = DataLoader(ts, batch_size=len(ts), shuffle=True, collate_fn=collate_fn)\n",
    "        \n",
    "        test_loss = eval_model(\n",
    "            model=symb,\n",
    "            valid_loader=test_loader,\n",
    "            criterion=torch.nn.L1Loss(),\n",
    "            scaler=scaler,\n",
    "            inverse_scale=inverse_scale,\n",
    "            pred_deriv=False\n",
    "        )\n",
    "        \n",
    "        test_losses.append(test_loss)\n",
    "    \n",
    "    return test_losses\n",
    "\n",
    "\n",
    "\n",
    "def get_test_set(dynamics, device='cuda', input_range=(0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    seeds = [12345, 67890, 111213]\n",
    "    \n",
    "    graphs = [\n",
    "        nx.barabasi_albert_graph(70, 3, seed=seeds[0]),      \n",
    "        nx.watts_strogatz_graph(50, 6, 0.3, seed=seeds[1]),  \n",
    "        nx.erdos_renyi_graph(100, 0.05, seed=seeds[2])        \n",
    "    ]\n",
    "    \n",
    "    test_set = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        snapshots = integrate_test_set(\n",
    "            graph=graph,\n",
    "            dynamics=dynamics,\n",
    "            seed=seeds[i],\n",
    "            device=device,\n",
    "            input_range=input_range,\n",
    "            t_span=t_span,\n",
    "            **integration_kwargs\n",
    "        )\n",
    "        test_set.append(snapshots)\n",
    "    \n",
    "    return test_set\n",
    "    \n",
    "\n",
    "\n",
    "def integrate_test_set(graph, dynamics, seed=12345, device='cuda', input_range = (0, 1), t_span = (0, 1), **integration_kwargs):\n",
    "    # graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "    edge_index = from_networkx(graph).edge_index\n",
    "    edge_index = edge_index.to(torch.device(device))\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    \n",
    "    data, t = integrate(\n",
    "        input_range=input_range,\n",
    "        t_span = t_span,\n",
    "        t_eval_steps=300,\n",
    "        dynamics=dynamics,\n",
    "        device=device,\n",
    "        graph=graph,\n",
    "        rng = rng,\n",
    "        **integration_kwargs\n",
    "    )\n",
    "    \n",
    "    snapshot = Data(\n",
    "        x = data[0].unsqueeze(0),\n",
    "        y = data[1:],\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=None,\n",
    "        t_span = t\n",
    "    )\n",
    "    \n",
    "    return [snapshot]\n",
    "\n",
    "\n",
    "def build_model_from_file(model_path, message_passing=False, include_time=False, method='dopri5', adjoint=True, atol=1e-5, rtol=1e-5):\n",
    "    best_params_file = f\"{model_path}/best_params.json\"\n",
    "    best_state_path = f\"{model_path}/mpnn/state_dict.pth\"\n",
    "    with open(best_params_file, 'r') as f:\n",
    "        best_hyperparams = json.load(f)\n",
    "    \n",
    "    in_dim = 1\n",
    "    \n",
    "    hidden_layers = [best_hyperparams[\"hidden_dims_g_net\"] for _ in range(best_hyperparams[\"n_hidden_layers_g_net\"])]\n",
    "    hidden_layers = [2*in_dim] + hidden_layers + [in_dim]    \n",
    "    # g_net\n",
    "    g_net = MLP(\n",
    "        hidden_layers=hidden_layers,\n",
    "        af = activations[best_hyperparams['af_g_net']],\n",
    "        dropout_rate=best_hyperparams['drop_p_g_net'],\n",
    "    )\n",
    "    \n",
    "    time_dim = 1 if include_time else 0\n",
    "    in_dim_h = 2 if message_passing else 1\n",
    "    in_dim_h += time_dim\n",
    "    hidden_layers = [best_hyperparams[\"hidden_dims_h_net\"] for _ in range(best_hyperparams[\"n_hidden_layers_h_net\"])]\n",
    "    hidden_layers = [in_dim_h] + hidden_layers + [in_dim] \n",
    "    \n",
    "    \n",
    "    # h_net\n",
    "    h_net = MLP(\n",
    "        hidden_layers=hidden_layers,\n",
    "        af = activations[best_hyperparams['af_h_net']],\n",
    "        dropout_rate=best_hyperparams['drop_p_h_net'],\n",
    "    )\n",
    "    \n",
    "    mpnn = MPNN(\n",
    "        h_net=h_net,\n",
    "        g_net=g_net,\n",
    "        message_passing=message_passing,\n",
    "        include_time=include_time\n",
    "    )\n",
    "    \n",
    "    model = MPNN_ODE(\n",
    "        conv=mpnn,\n",
    "        model_path='./saved_models_optuna/tmp',\n",
    "        integration_method=method,\n",
    "        adjoint=adjoint,\n",
    "        atol=atol,\n",
    "        rtol=rtol\n",
    "    )\n",
    "    \n",
    "    model = model.to(torch.device('cuda'))\n",
    "    model.load_state_dict(torch.load(best_state_path, weights_only=False, map_location=torch.device('cuda')))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def valid_symb_model(\n",
    "    config,\n",
    "    model_path_gkan,\n",
    "    device='cuda',\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    sample_size=10000\n",
    "):\n",
    "    seed = 9999\n",
    "    graph = nx.barabasi_albert_graph(100, 3, seed=seed)\n",
    "\n",
    "    # Prepare validation/test set\n",
    "    valid_set = integrate_test_set(\n",
    "        graph=graph,\n",
    "        dynamics=config['name'],\n",
    "        seed=seed,\n",
    "        device=device,\n",
    "        input_range=config['input_range'],\n",
    "        t_span=(0, 1),\n",
    "        **config['integration_kwargs']\n",
    "    )\n",
    "\n",
    "    # Helper to compute validation loss\n",
    "    def evaluate_model(g_symb, h_symb, is_symb=True):\n",
    "        errs = get_symb_test_error(\n",
    "            g_symb=g_symb,\n",
    "            h_symb=h_symb,\n",
    "            test_set=[valid_set],\n",
    "            message_passing=False,\n",
    "            include_time=False,\n",
    "            method=method,\n",
    "            atol=atol,\n",
    "            rtol=rtol,\n",
    "            is_symb=is_symb\n",
    "        )\n",
    "        return errs[0]\n",
    "\n",
    "    # Helper to fit model for current config\n",
    "    def fit_single_model(param1, param2):\n",
    "        print(f\"Fitting black-box model with {param1} and {param2} iterations\")\n",
    "        pysr_model = lambda: get_pysr_model(model_selection=param1, n_iterations=param2)\n",
    "        _, g_symb, h_symb = fit_mpnn(\n",
    "            device=device,\n",
    "            model_path=model_path_gkan,\n",
    "            pysr_model=pysr_model,\n",
    "            sample_size=sample_size,\n",
    "            message_passing=False,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        return g_symb, h_symb\n",
    "\n",
    "    param_grid = ([\"score\", \"accuracy\"], [50, 100, 200])\n",
    "    search_space = [(mod, val) for mod in param_grid[0] for val in param_grid[1]]\n",
    "    valid_losses = []\n",
    "    \n",
    "    for mod, val in search_space:\n",
    "        g_symb, h_symb = fit_single_model(mod, val)\n",
    "        try:\n",
    "            loss = evaluate_model(g_symb, h_symb, is_symb=True)\n",
    "        except AssertionError:\n",
    "            loss = 1e8\n",
    "        valid_losses.append({'model_selection': mod, 'param': val, 'valid_loss': loss})\n",
    "    \n",
    "    best = min(valid_losses, key=lambda x: x['valid_loss'])    \n",
    "    \n",
    "    print(f\"Refitting best model with {best}\")\n",
    "    \n",
    "    gkan_symb, symb_g, symb_h = fit_mpnn(\n",
    "        model_path=model_path_gkan,\n",
    "        device=device,\n",
    "        pysr_model=lambda: get_pysr_model(\n",
    "            model_selection=best['model_selection'],\n",
    "            n_iterations=best['param']\n",
    "        ),\n",
    "        sample_size=sample_size,\n",
    "        message_passing=False,\n",
    "        verbose=True,\n",
    "        include_time=False\n",
    "    )\n",
    "    \n",
    "    return gkan_symb, symb_g, symb_h\n",
    "\n",
    "\n",
    "def post_process_gkan(\n",
    "    config,\n",
    "    model_path, \n",
    "    test_set, \n",
    "    device='cuda',\n",
    "    sample_size=10000,\n",
    "    message_passing=False, \n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method='dopri5',\n",
    "    scaler=None,\n",
    "    inverse_scale=False,\n",
    "    adjoint=True,\n",
    "    eval_model=True\n",
    "):\n",
    "    \n",
    "    def print_symb_error(g_symb, h_symb, txt=\"symbolic formula\", is_symb=True):\n",
    "        try:\n",
    "            test_losses_symb = get_symb_test_error(\n",
    "                g_symb=g_symb,\n",
    "                h_symb=h_symb,\n",
    "                test_set=test_set,\n",
    "                message_passing=message_passing,\n",
    "                include_time=include_time,\n",
    "                atol=atol,\n",
    "                rtol=rtol,\n",
    "                method=method,\n",
    "                scaler=scaler,\n",
    "                inverse_scale=inverse_scale,\n",
    "                is_symb=is_symb\n",
    "            )\n",
    "\n",
    "            ts_mean = np.mean(test_losses_symb)\n",
    "            ts_var = np.var(test_losses_symb)\n",
    "            ts_std = np.std(test_losses_symb)\n",
    "            \n",
    "            print(f\"Mean Test loss of {txt}: {ts_mean}\")\n",
    "            print(f\"Var Test loss of {txt}: {ts_var}\")\n",
    "            print(f\"Std Test loss of {txt}: {ts_std}\")\n",
    "        except AssertionError:\n",
    "            print(\"Evaluation failed!\")\n",
    "        \n",
    "    \n",
    "    print(\"Black-Box fitting \\n\")\n",
    "    bb_symb, bb_g_symb, bb_h_symb = valid_symb_model(\n",
    "        config=config,\n",
    "        model_path_gkan=f\"{model_path}/mpnn\",\n",
    "        device=device,\n",
    "        atol=atol,\n",
    "        rtol=rtol,\n",
    "        method=method,\n",
    "        sample_size = sample_size\n",
    "    )\n",
    "    \n",
    "    print(latex(quantise(bb_symb)))\n",
    "    print_symb_error(g_symb=bb_g_symb, h_symb=bb_h_symb)\n",
    "    \n",
    "    if eval_model:\n",
    "        print(\"Evaluate raw model\\n\")\n",
    "        # Loading best model\n",
    "        best_model = build_model_from_file(\n",
    "            model_path=model_path,\n",
    "            message_passing=message_passing,\n",
    "            include_time=include_time,\n",
    "            method=method,\n",
    "            adjoint=adjoint,\n",
    "            atol=atol,\n",
    "            rtol=rtol\n",
    "        )\n",
    "\n",
    "        tot_params = sum(p.numel() for p in best_model.parameters() if p.requires_grad)\n",
    "        print(f\"Number of model's parameters: {tot_params}\\n\")\n",
    "\n",
    "        best_model = best_model.eval()\n",
    "        print_symb_error(\n",
    "            g_symb=best_model.conv.model.g_net,\n",
    "            h_symb=best_model.conv.model.h_net,\n",
    "            txt=\"best model\",\n",
    "            is_symb=False\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "def plot_predictions(y_true, y_pred, node_index = 0):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(y_true[:, node_index, :], label='y_true', marker='o')\n",
    "    plt.plot(y_pred[:, node_index, :], label='y_pred', marker='o')\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title(f'y_true vs y_pred for Node {node_index}')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LB Losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/scipy/integrate/_ivp/ivp.py:621: UserWarning: The following arguments have no effect for a chosen solver: `min_step`.\n",
      "  solver = method(fun, t0, y0, tf, vectorized=vectorized, **options)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.352664670169664e-05\n",
      "Var Test loss of symbolic formula: 1.3517513389612395e-13\n",
      "Std Test loss of symbolic formula: 3.676617112185112e-07\n"
     ]
    }
   ],
   "source": [
    "kur_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_kuramoto.yml\")\n",
    "\n",
    "KUR = get_test_set(\n",
    "    dynamics=kur_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=kur_config['input_range'],\n",
    "    **kur_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: torch.sin(x[:, 1] - x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: 2.0 + 0.5 * x[:, 1].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=KUR,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.0729370387707604e-06\n",
      "Var Test loss of symbolic formula: 8.017524161241833e-14\n",
      "Std Test loss of symbolic formula: 2.831523293430911e-07\n"
     ]
    }
   ],
   "source": [
    "epid_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_epidemics.yml\")\n",
    "\n",
    "EPID = get_test_set(\n",
    "    dynamics=epid_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=epid_config['input_range'],\n",
    "    **epid_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.5*x[:, 1].unsqueeze(-1) * (1 - x[:, 0].unsqueeze(-1))\n",
    "h_symb = lambda x: x[:, 1].unsqueeze(1) - 0.5 * x[:, 0].unsqueeze(-1)\n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=EPID,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 1.2020226639227378e-06\n",
      "Var Test loss of symbolic formula: 7.199001650861301e-14\n",
      "Std Test loss of symbolic formula: 2.683095535172257e-07\n"
     ]
    }
   ],
   "source": [
    "bio_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_biochemical.yml\")\n",
    "\n",
    "BIO = get_test_set(\n",
    "    dynamics=bio_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=bio_config['input_range'],\n",
    "    **bio_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: (-0.5*x[:, 1] * x[:, 0]).unsqueeze(-1)\n",
    "h_symb = lambda x: (1.0 - 0.5 * x[:, 0]).unsqueeze(-1)  + x[:, 1].unsqueeze(-1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=BIO,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 3.740968168131076e-06\n",
      "Var Test loss of symbolic formula: 4.763240197448409e-13\n",
      "Std Test loss of symbolic formula: 6.901623140572375e-07\n"
     ]
    }
   ],
   "source": [
    "pop_config = load_config(\"./configs/config_pred_deriv/config_ic1/config_population.yml\")\n",
    "\n",
    "POP = get_test_set(\n",
    "    dynamics=pop_config['name'],\n",
    "    device='cuda',\n",
    "    input_range=pop_config['input_range'],\n",
    "    **pop_config['integration_kwargs']    \n",
    ")\n",
    "\n",
    "g_symb = lambda x: 0.2*torch.pow(x[:, 1].unsqueeze(-1), 3)\n",
    "h_symb = lambda x: -0.5 * x[:, 0].unsqueeze(-1) + x[:, 1].unsqueeze(1) \n",
    "\n",
    "test_losses = get_symb_test_error(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    test_set=POP,\n",
    "    message_passing=True,\n",
    "    include_time=False,\n",
    "    is_symb=False\n",
    ")\n",
    "\n",
    "ts_mean = np.mean(test_losses)\n",
    "ts_var = np.var(test_losses)\n",
    "ts_std = np.std(test_losses)\n",
    "\n",
    "print(f\"Mean Test loss of symbolic formula: {ts_mean}\")\n",
    "print(f\"Var Test loss of symbolic formula: {ts_var}\")\n",
    "print(f\"Std Test loss of symbolic formula: {ts_std}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symb Reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biochemical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Box fitting \n",
      "\n",
      "Fitting black-box model with score and 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n",
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with score and 100 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n",
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with score and 200 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n",
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with accuracy and 50 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n",
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with accuracy and 100 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n",
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting black-box model with accuracy and 200 iterations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n",
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refitting best model with {'model_selection': 'accuracy', 'param': 200, 'valid_loss': 0.0003564267826732248}\n",
      "Fitting G_Net...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 58.542379 seconds\n",
      "\n",
      "Fitting H_Net...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricca/miniconda3/envs/myenv/lib/python3.12/site-packages/pysr/sr.py:2241: UserWarning: Note: you are running with more than 10,000 datapoints. You should consider turning on batching (https://ai.damtp.cam.ac.uk/pysr/options/#batching). You should also reconsider if you need that many datapoints. Unless you have a large amount of noise (in which case you should smooth your dataset first), generally < 10,000 datapoints is enough to find a functional form with symbolic regression. More datapoints will lower the search speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 65.160213 seconds\n",
      "\\sum_{j}(-0.5*x_i*x_j) - 0.5 x_{i} + 1.0\n",
      "Mean Test loss of symbolic formula: 0.00037766526414391893\n",
      "Var Test loss of symbolic formula: 9.346062457169214e-10\n",
      "Std Test loss of symbolic formula: 3.057133045382424e-05\n",
      "Evaluate raw model\n",
      "\n",
      "Number of model's parameters: 2122\n",
      "\n",
      "Mean Test loss of best model: 0.0003843946421208481\n",
      "Var Test loss of best model: 2.1111668090452654e-10\n",
      "Std Test loss of best model: 1.4529854813607964e-05\n"
     ]
    }
   ],
   "source": [
    "model_path_mpnn = './saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_12/0'\n",
    "\n",
    "post_process_gkan(\n",
    "    config=bio_config,\n",
    "    model_path=model_path_mpnn,\n",
    "    test_set=BIO,\n",
    "    device='cuda',\n",
    "    sample_size=30000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_noise_70db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 25.996592 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 39.974760 seconds\n",
      "\\sum_{j}( -0.49620143*x_i*x_j) + log(2.6315304 - x_i)\n",
      "Mean Test loss of symbolic formula: 0.0024368255399167538\n",
      "Var Test loss of symbolic formula: 9.127601068019119e-09\n",
      "Std Test loss of symbolic formula: 9.55384795149008e-05\n",
      "\n",
      "Number of model's parameters: 4538\n",
      "\n",
      "Mean Test loss of best model: 0.0022547676150376597\n",
      "Var Test loss of best model: 1.5554461835884236e-07\n",
      "Std Test loss of best model: 0.00039439145320207224\n",
      "\n",
      "./saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_noise_50db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 41.890366 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 48.142198 seconds\n",
      "\\sum_{j}( -0.498295*x_i*x_j) + log(2.6874051 - x_i)\n",
      "Mean Test loss of symbolic formula: 0.007588010126103957\n",
      "Var Test loss of symbolic formula: 1.5788738040883606e-07\n",
      "Std Test loss of symbolic formula: 0.0003973504503694894\n",
      "\n",
      "Number of model's parameters: 5538\n",
      "\n",
      "Mean Test loss of best model: 0.007018518944581349\n",
      "Var Test loss of best model: 9.900987065077624e-07\n",
      "Std Test loss of best model: 0.0009950370377567674\n",
      "\n",
      "./saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_noise_20db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 47.357512 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 32.373036 seconds\n",
      "\\sum_{j}( -0.24372226*tanh(18.2510706809839*x_j**3)) - 0.00014315384*tanh(exp(x_i)) + 0.53761023\n",
      "Mean Test loss of symbolic formula: 0.2023063749074936\n",
      "Var Test loss of symbolic formula: 0.0001081438493613085\n",
      "Std Test loss of symbolic formula: 0.010399223497997746\n",
      "\n",
      "Number of model's parameters: 4738\n",
      "\n",
      "Mean Test loss of best model: 0.2536923885345459\n",
      "Var Test loss of best model: 0.00017845275121667706\n",
      "Std Test loss of best model: 0.013358620857583953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "    \"./saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-biochemical-mpnn/biochemical_mpnn_ic1_s5_pd_mult_noise_20db_2/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=bio_config,\n",
    "        model_path=model_path,\n",
    "        test_set=BIO,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuramoto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 50.888444 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 64.615102 seconds\n"
     ]
    }
   ],
   "source": [
    "model_path_mpnn = './saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_12/0/mpnn'\n",
    "\n",
    "post_process_gkan(\n",
    "    config=kur_config,\n",
    "    model_path=model_path_mpnn,\n",
    "    test_set=KUR,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( -0.49719262*sin(x_i - x_j)) + 2.0009475$"
      ],
      "text/plain": [
       "\\sum_{j}( -0.49719262*sin(x_i - x_j)) + 2.0009475"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0017371306894347072\n",
      "Var Test loss of symbolic formula: 1.5203610106152902e-08\n",
      "Std Test loss of symbolic formula: 0.00012330292010391685\n",
      "\n",
      "Number of model's parameters: 3514\n",
      "\n",
      "Mean Test loss of best model: 0.004582143854349852\n",
      "Var Test loss of best model: 5.06081607860315e-07\n",
      "Std Test loss of best model: 0.0007113941297623385\n"
     ]
    }
   ],
   "source": [
    "g_symb = make_callable(symb_g)\n",
    "h_symb = make_callable(symb_h)\n",
    "\n",
    "post_process_mpnn(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    model_path='./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_12/0',\n",
    "    test_set=KUR,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    method='dopri5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_noise_70db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 40.920610 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 41.355458 seconds\n",
      "\\sum_{j}( -0.49086905*sin(x_i - x_j)) - 0.0451186*log(x_i) + 2.0498369\n",
      "Mean Test loss of symbolic formula: 0.013569213449954987\n",
      "Var Test loss of symbolic formula: 5.832581282833963e-07\n",
      "Std Test loss of symbolic formula: 0.0007637133809770498\n",
      "\n",
      "Number of model's parameters: 4610\n",
      "\n",
      "Mean Test loss of best model: 0.023420780897140503\n",
      "Var Test loss of best model: 1.0944403551089537e-06\n",
      "Std Test loss of best model: 0.0010461550339739105\n",
      "\n",
      "./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_noise_50db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 55.952102 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 53.932303 seconds\n",
      "\\sum_{j}( -0.426789709570883*sin(x_i - x_j)) - tanh(0.642491551396722*x_i) + 2.9945853\n",
      "Mean Test loss of symbolic formula: 0.06799725939830144\n",
      "Var Test loss of symbolic formula: 2.5912615007925604e-06\n",
      "Std Test loss of symbolic formula: 0.0016097395754570243\n",
      "\n",
      "Number of model's parameters: 1986\n",
      "\n",
      "Mean Test loss of best model: 0.11503128210703532\n",
      "Var Test loss of best model: 1.7551835922089176e-05\n",
      "Std Test loss of best model: 0.004189491129252952\n",
      "\n",
      "./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_noise_20db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 55.792543 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 40.330102 seconds\n",
      "\\sum_{j}( sin(x_i - 1.88451219307657*x_j)) + 36.3610882962013*exp(-x_i)\n",
      "Mean Test loss of symbolic formula: 0.7687700192133585\n",
      "Var Test loss of symbolic formula: 0.011220215771720476\n",
      "Std Test loss of symbolic formula: 0.10592551992659972\n",
      "\n",
      "Number of model's parameters: 4570\n",
      "\n",
      "Mean Test loss of best model: 1.1644896268844604\n",
      "Var Test loss of best model: 0.013443227512775971\n",
      "Std Test loss of best model: 0.11594493310522876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "    \"./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-kuramoto-mpnn/kuramoto_mpnn_ic1_s5_pd_mult_noise_20db_2/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths:\n",
    "    print(model_path)\n",
    "    \n",
    "    post_process_gkan(\n",
    "        config=kur_config,\n",
    "        model_path=model_path,\n",
    "        test_set=KUR,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 34.950284 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 45.802129 seconds\n"
     ]
    }
   ],
   "source": [
    "model_path_mpnn = './saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_12/0/mpnn'\n",
    "\n",
    "post_process_gkan(\n",
    "    config=epid_config,\n",
    "    model_path=model_path_mpnn,\n",
    "    test_set=EPID,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( 0.497620998411843*x_j*(1 - x_i)) - 0.49904963 x_{i}$"
      ],
      "text/plain": [
       "\\sum_{j}( 0.497620998411843*x_j*(1 - x_i)) - 0.49904963*x_i"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0007281222497113049\n",
      "Var Test loss of symbolic formula: 1.3702430421754467e-09\n",
      "Std Test loss of symbolic formula: 3.7016794055880184e-05\n",
      "\n",
      "Number of model's parameters: 5090\n",
      "\n",
      "Mean Test loss of best model: 0.0007212451115871469\n",
      "Var Test loss of best model: 1.276419140150629e-08\n",
      "Std Test loss of best model: 0.00011297872101199539\n"
     ]
    }
   ],
   "source": [
    "g_symb = make_callable(symb_g)\n",
    "h_symb = make_callable(symb_h)\n",
    "\n",
    "post_process_mpnn(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    model_path='./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_12/0',\n",
    "    test_set=EPID,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    method='dopri5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_noise_70db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 48.721982 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 25.528166 seconds\n",
      "\\sum_{j}( -0.42436177*x_j*tanh(log(x_i))) - 0.4830658*x_i\n",
      "Mean Test loss of symbolic formula: 0.003271587969114383\n",
      "Var Test loss of symbolic formula: 9.808489644241618e-08\n",
      "Std Test loss of symbolic formula: 0.0003131850833651184\n",
      "\n",
      "Number of model's parameters: 1874\n",
      "\n",
      "Mean Test loss of best model: 0.0016968537432452042\n",
      "Var Test loss of best model: 9.960029821211603e-08\n",
      "Std Test loss of best model: 0.00031559514922146066\n",
      "\n",
      "./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_noise_50db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 34.356169 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 34.873182 seconds\n",
      "\\sum_{j}( -0.16320519*log(x_i)) - 0.18819985*log(x_i + 1) - 0.03794544\n",
      "Mean Test loss of symbolic formula: 0.029455676053961117\n",
      "Var Test loss of symbolic formula: 4.508785524012639e-06\n",
      "Std Test loss of symbolic formula: 0.0021233901017035563\n",
      "\n",
      "Number of model's parameters: 482\n",
      "\n",
      "Mean Test loss of best model: 0.027961941435933113\n",
      "Var Test loss of best model: 7.665686009796871e-06\n",
      "Std Test loss of best model: 0.0027686975294887073\n",
      "\n",
      "./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_noise_20db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 51.845371 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 50.958509 seconds\n",
      "\\sum_{j}( 0.2670945 - 0.4352944*x_j) + 0.5936278/tanh(exp(x_i))\n",
      "Mean Test loss of symbolic formula: 0.2330750972032547\n",
      "Var Test loss of symbolic formula: 0.0007100412544178702\n",
      "Std Test loss of symbolic formula: 0.02664659930306061\n",
      "\n",
      "Number of model's parameters: 258\n",
      "\n",
      "Mean Test loss of best model: 0.3809460202852885\n",
      "Var Test loss of best model: 0.0005972551886955162\n",
      "Std Test loss of best model: 0.024438804976829702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "    \"./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-epidemics-mpnn/epidemics_mpnn_ic1_s5_pd_mult_noise_20db_2/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=epid_config,\n",
    "        model_path=model_path,\n",
    "        test_set=EPID,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IC=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 30.405960 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 31.830704 seconds\n"
     ]
    }
   ],
   "source": [
    "model_path_mpnn = './saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_12/0/mpnn'\n",
    "\n",
    "post_process_gkan(\n",
    "    config=pop_config,\n",
    "    model_path=model_path_mpnn,\n",
    "    test_set=POP,\n",
    "    device='cuda',\n",
    "    n_g_hidden_layers=2,\n",
    "    n_h_hidden_layers=2,\n",
    "    sample_size=10000,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    atol=1e-5,\n",
    "    rtol=1e-5,\n",
    "    method=\"dopri5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( 0.197325724628776*x_j**3) - 0.49980032 x_{i}$"
      ],
      "text/plain": [
       "\\sum_{j}( 0.197325724628776*x_j**3) - 0.49980032*x_i"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Test loss of symbolic formula: 0.0004971495169835786\n",
      "Var Test loss of symbolic formula: 3.2746913584435925e-09\n",
      "Std Test loss of symbolic formula: 5.7224919033962755e-05\n",
      "\n",
      "Number of model's parameters: 1954\n",
      "\n",
      "Mean Test loss of best model: 0.0007960639389542242\n",
      "Var Test loss of best model: 2.637341526114986e-08\n",
      "Std Test loss of best model: 0.00016239893860844613\n"
     ]
    }
   ],
   "source": [
    "g_symb = make_callable(symb_g)\n",
    "h_symb = make_callable(symb_h)\n",
    "\n",
    "post_process_mpnn(\n",
    "    g_symb=g_symb,\n",
    "    h_symb=h_symb,\n",
    "    model_path='./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_12/0',\n",
    "    test_set=POP,\n",
    "    message_passing=False,\n",
    "    include_time=False,\n",
    "    method='dopri5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_noise_70db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 30.319365 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 40.819434 seconds\n",
      "\\sum_{j}( 0.194854706628157*x_j**3) - 0.4946516*x_i\n",
      "Mean Test loss of symbolic formula: 0.0010907843243330717\n",
      "Var Test loss of symbolic formula: 3.782299146516503e-09\n",
      "Std Test loss of symbolic formula: 6.150039956387685e-05\n",
      "\n",
      "Number of model's parameters: 1282\n",
      "\n",
      "Mean Test loss of best model: 0.003493684188773235\n",
      "Var Test loss of best model: 6.654545324157585e-07\n",
      "Std Test loss of best model: 0.0008157539656144851\n",
      "\n",
      "./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_noise_50db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 45.731880 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 36.505551 seconds\n",
      "\\sum_{j}( x_j - sin(x_j)) - 0.47065166*x_i\n",
      "Mean Test loss of symbolic formula: 0.007451973079393308\n",
      "Var Test loss of symbolic formula: 4.718381211589019e-07\n",
      "Std Test loss of symbolic formula: 0.0006869047395082537\n",
      "\n",
      "Number of model's parameters: 3698\n",
      "\n",
      "Mean Test loss of best model: 0.010338600414494673\n",
      "Var Test loss of best model: 1.2192353752324491e-06\n",
      "Std Test loss of best model: 0.0011041899180994404\n",
      "\n",
      "./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_noise_20db_2/0\n",
      "\n",
      "Fitting G_Net...\n",
      "Execution time: 26.734180 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 41.027883 seconds\n",
      "\\sum_{j}( -0.0030675712*exp(x_i)) - tanh(x_i - 0.31313428)**3\n",
      "Mean Test loss of symbolic formula: 0.05362745746970177\n",
      "Var Test loss of symbolic formula: 2.0829537614823015e-06\n",
      "Std Test loss of symbolic formula: 0.0014432441794382201\n",
      "\n",
      "Number of model's parameters: 4058\n",
      "\n",
      "Mean Test loss of best model: 0.05902289723356565\n",
      "Var Test loss of best model: 4.220315874088455e-06\n",
      "Std Test loss of best model: 0.0020543407395289745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_paths = [\n",
    "    \"./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_noise_70db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_noise_50db_2/0\",\n",
    "    \"./saved_models_optuna/model-population-mpnn/population_mpnn_ic1_s5_pd_mult_noise_20db_2/0\"\n",
    "]\n",
    "\n",
    "for model_path in model_paths:\n",
    "    print(model_path)\n",
    "    post_process_gkan(\n",
    "        config=pop_config,\n",
    "        model_path=model_path,\n",
    "        test_set=POP,\n",
    "        device='cuda',\n",
    "        n_g_hidden_layers=2,\n",
    "        n_h_hidden_layers=2,\n",
    "        sample_size=10000,\n",
    "        message_passing=False,\n",
    "        include_time=False,\n",
    "        atol=1e-5,\n",
    "        rtol=1e-5,\n",
    "        method=\"dopri5\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Epid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting G_Net...\n",
      "Execution time: 54.190959 seconds\n",
      "\n",
      "Fitting H_Net...\n",
      "Execution time: 19.637314 seconds\n"
     ]
    }
   ],
   "source": [
    "model_path_mpnn = './saved_models_optuna/model-real-epid-mpnn/real_epid_mpnn/0/mpnn'\n",
    "\n",
    "pysr_model = lambda : get_pysr_model(\n",
    "    model_selection=\"score\",\n",
    "    n_iterations=200\n",
    ")\n",
    "\n",
    "mpnn_symb, symb_g, symb_h = fit_mpnn(\n",
    "    model_path=model_path_mpnn,\n",
    "    pysr_model=pysr_model,\n",
    "    sample_size=10000,\n",
    "    message_passing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\sum_{j}( 8.12635*log(x_i + 1)) + \\log{\\left(4.951334 x_{i} + 1 \\right)}^{2}$"
      ],
      "text/plain": [
       "\\sum_{j}( 8.12635*log(x_i + 1)) + log(4.951334*x_i + 1)**2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnn_symb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
